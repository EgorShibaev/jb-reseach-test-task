{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9836205790531583,
  "eval_steps": 1000,
  "global_step": 23000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 4.283369541168213,
      "learning_rate": 2.4989308471966816e-05,
      "loss": 6.0171,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.041409492492676,
      "learning_rate": 2.4978616943933627e-05,
      "loss": 5.874,
      "step": 20
    },
    {
      "epoch": 0.0,
      "grad_norm": 8.756505012512207,
      "learning_rate": 2.496792541590044e-05,
      "loss": 4.5124,
      "step": 30
    },
    {
      "epoch": 0.0,
      "grad_norm": 10.37299633026123,
      "learning_rate": 2.4957233887867253e-05,
      "loss": 3.3191,
      "step": 40
    },
    {
      "epoch": 0.0,
      "grad_norm": 6.769416809082031,
      "learning_rate": 2.4946542359834067e-05,
      "loss": 1.6433,
      "step": 50
    },
    {
      "epoch": 0.0,
      "grad_norm": 2.020068883895874,
      "learning_rate": 2.4935850831800882e-05,
      "loss": 0.8673,
      "step": 60
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.3792477548122406,
      "learning_rate": 2.4925159303767697e-05,
      "loss": 0.564,
      "step": 70
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.26093828678131104,
      "learning_rate": 2.491446777573451e-05,
      "loss": 0.4343,
      "step": 80
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2622821629047394,
      "learning_rate": 2.4903776247701322e-05,
      "loss": 0.4931,
      "step": 90
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.25282078981399536,
      "learning_rate": 2.4893084719668137e-05,
      "loss": 0.5392,
      "step": 100
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.2876644432544708,
      "learning_rate": 2.488239319163495e-05,
      "loss": 0.3213,
      "step": 110
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2620067000389099,
      "learning_rate": 2.4871701663601763e-05,
      "loss": 0.4202,
      "step": 120
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.26703763008117676,
      "learning_rate": 2.4861010135568577e-05,
      "loss": 0.455,
      "step": 130
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3132458031177521,
      "learning_rate": 2.485031860753539e-05,
      "loss": 0.4924,
      "step": 140
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25393322110176086,
      "learning_rate": 2.4839627079502203e-05,
      "loss": 0.5583,
      "step": 150
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2753949761390686,
      "learning_rate": 2.4828935551469018e-05,
      "loss": 0.4786,
      "step": 160
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.34124282002449036,
      "learning_rate": 2.481824402343583e-05,
      "loss": 0.5619,
      "step": 170
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2946188747882843,
      "learning_rate": 2.4807552495402643e-05,
      "loss": 0.4434,
      "step": 180
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3988865613937378,
      "learning_rate": 2.4796860967369455e-05,
      "loss": 0.4877,
      "step": 190
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3177030384540558,
      "learning_rate": 2.478616943933627e-05,
      "loss": 0.4356,
      "step": 200
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.35938259959220886,
      "learning_rate": 2.4775477911303084e-05,
      "loss": 0.3852,
      "step": 210
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.3292272090911865,
      "learning_rate": 2.47647863832699e-05,
      "loss": 0.5182,
      "step": 220
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4153771698474884,
      "learning_rate": 2.4754094855236713e-05,
      "loss": 0.3962,
      "step": 230
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.23636041581630707,
      "learning_rate": 2.4743403327203528e-05,
      "loss": 0.4925,
      "step": 240
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.35868173837661743,
      "learning_rate": 2.473271179917034e-05,
      "loss": 0.4644,
      "step": 250
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.35173436999320984,
      "learning_rate": 2.4722020271137153e-05,
      "loss": 0.4581,
      "step": 260
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.19350001215934753,
      "learning_rate": 2.4711328743103965e-05,
      "loss": 0.3861,
      "step": 270
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.32259491086006165,
      "learning_rate": 2.470063721507078e-05,
      "loss": 0.3996,
      "step": 280
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.22342105209827423,
      "learning_rate": 2.4689945687037594e-05,
      "loss": 0.431,
      "step": 290
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4200735092163086,
      "learning_rate": 2.4679254159004405e-05,
      "loss": 0.4854,
      "step": 300
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.43462035059928894,
      "learning_rate": 2.466856263097122e-05,
      "loss": 0.4837,
      "step": 310
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.37000924348831177,
      "learning_rate": 2.465787110293803e-05,
      "loss": 0.3298,
      "step": 320
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.4921272099018097,
      "learning_rate": 2.4647179574904845e-05,
      "loss": 0.4449,
      "step": 330
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.34428688883781433,
      "learning_rate": 2.463648804687166e-05,
      "loss": 0.3933,
      "step": 340
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.2553406059741974,
      "learning_rate": 2.4625796518838475e-05,
      "loss": 0.4254,
      "step": 350
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.4037332236766815,
      "learning_rate": 2.461510499080529e-05,
      "loss": 0.3089,
      "step": 360
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.33969879150390625,
      "learning_rate": 2.46044134627721e-05,
      "loss": 0.3494,
      "step": 370
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6664883494377136,
      "learning_rate": 2.4593721934738915e-05,
      "loss": 0.3588,
      "step": 380
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.404500275850296,
      "learning_rate": 2.458303040670573e-05,
      "loss": 0.4102,
      "step": 390
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.303220272064209,
      "learning_rate": 2.457233887867254e-05,
      "loss": 0.3686,
      "step": 400
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48259037733078003,
      "learning_rate": 2.4561647350639355e-05,
      "loss": 0.3533,
      "step": 410
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.35320180654525757,
      "learning_rate": 2.4550955822606167e-05,
      "loss": 0.3385,
      "step": 420
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5814857482910156,
      "learning_rate": 2.454026429457298e-05,
      "loss": 0.3897,
      "step": 430
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5291694402694702,
      "learning_rate": 2.4529572766539796e-05,
      "loss": 0.3674,
      "step": 440
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5720027685165405,
      "learning_rate": 2.4518881238506607e-05,
      "loss": 0.4465,
      "step": 450
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6005526185035706,
      "learning_rate": 2.450818971047342e-05,
      "loss": 0.3794,
      "step": 460
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5455032587051392,
      "learning_rate": 2.4497498182440236e-05,
      "loss": 0.4789,
      "step": 470
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.3899567723274231,
      "learning_rate": 2.448680665440705e-05,
      "loss": 0.3332,
      "step": 480
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6058476567268372,
      "learning_rate": 2.4476115126373865e-05,
      "loss": 0.4652,
      "step": 490
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.705206036567688,
      "learning_rate": 2.4465423598340676e-05,
      "loss": 0.42,
      "step": 500
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6410499215126038,
      "learning_rate": 2.445473207030749e-05,
      "loss": 0.4222,
      "step": 510
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5591650009155273,
      "learning_rate": 2.4444040542274302e-05,
      "loss": 0.429,
      "step": 520
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5923608541488647,
      "learning_rate": 2.4433349014241117e-05,
      "loss": 0.4293,
      "step": 530
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6983782649040222,
      "learning_rate": 2.442265748620793e-05,
      "loss": 0.4317,
      "step": 540
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.5150381922721863,
      "learning_rate": 2.4411965958174743e-05,
      "loss": 0.2647,
      "step": 550
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8138293027877808,
      "learning_rate": 2.4401274430141557e-05,
      "loss": 0.3909,
      "step": 560
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.48278817534446716,
      "learning_rate": 2.439058290210837e-05,
      "loss": 0.4189,
      "step": 570
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.6345526576042175,
      "learning_rate": 2.4379891374075183e-05,
      "loss": 0.3642,
      "step": 580
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6709932684898376,
      "learning_rate": 2.4369199846041998e-05,
      "loss": 0.4227,
      "step": 590
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.2046036273241043,
      "learning_rate": 2.435850831800881e-05,
      "loss": 0.4081,
      "step": 600
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6730893850326538,
      "learning_rate": 2.4347816789975623e-05,
      "loss": 0.4206,
      "step": 610
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.5794538855552673,
      "learning_rate": 2.4337125261942438e-05,
      "loss": 0.4273,
      "step": 620
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.934357225894928,
      "learning_rate": 2.4326433733909253e-05,
      "loss": 0.4602,
      "step": 630
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7122575640678406,
      "learning_rate": 2.4315742205876067e-05,
      "loss": 0.3522,
      "step": 640
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6341760158538818,
      "learning_rate": 2.430505067784288e-05,
      "loss": 0.3807,
      "step": 650
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.798591136932373,
      "learning_rate": 2.4294359149809693e-05,
      "loss": 0.3986,
      "step": 660
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4431147277355194,
      "learning_rate": 2.4283667621776504e-05,
      "loss": 0.3486,
      "step": 670
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6202368140220642,
      "learning_rate": 2.427297609374332e-05,
      "loss": 0.4028,
      "step": 680
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7559589147567749,
      "learning_rate": 2.4262284565710133e-05,
      "loss": 0.3191,
      "step": 690
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.4834883213043213,
      "learning_rate": 2.4251593037676945e-05,
      "loss": 0.3906,
      "step": 700
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6016494035720825,
      "learning_rate": 2.424090150964376e-05,
      "loss": 0.3125,
      "step": 710
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7936636805534363,
      "learning_rate": 2.4230209981610574e-05,
      "loss": 0.4327,
      "step": 720
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8464905023574829,
      "learning_rate": 2.4219518453577385e-05,
      "loss": 0.3933,
      "step": 730
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.24774858355522156,
      "learning_rate": 2.42088269255442e-05,
      "loss": 0.3456,
      "step": 740
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7405263781547546,
      "learning_rate": 2.4198135397511014e-05,
      "loss": 0.3992,
      "step": 750
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6416881084442139,
      "learning_rate": 2.418744386947783e-05,
      "loss": 0.3671,
      "step": 760
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7014325261116028,
      "learning_rate": 2.4176752341444643e-05,
      "loss": 0.3891,
      "step": 770
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8879611492156982,
      "learning_rate": 2.4166060813411455e-05,
      "loss": 0.3533,
      "step": 780
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7607041597366333,
      "learning_rate": 2.415536928537827e-05,
      "loss": 0.4254,
      "step": 790
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9057533740997314,
      "learning_rate": 2.414467775734508e-05,
      "loss": 0.4092,
      "step": 800
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.6634603142738342,
      "learning_rate": 2.4133986229311895e-05,
      "loss": 0.3927,
      "step": 810
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.702584445476532,
      "learning_rate": 2.412329470127871e-05,
      "loss": 0.3953,
      "step": 820
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9726583957672119,
      "learning_rate": 2.411260317324552e-05,
      "loss": 0.3976,
      "step": 830
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7561722993850708,
      "learning_rate": 2.4101911645212335e-05,
      "loss": 0.4232,
      "step": 840
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.734917163848877,
      "learning_rate": 2.4091220117179146e-05,
      "loss": 0.4325,
      "step": 850
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7119856476783752,
      "learning_rate": 2.408052858914596e-05,
      "loss": 0.4297,
      "step": 860
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6624504327774048,
      "learning_rate": 2.4069837061112776e-05,
      "loss": 0.4033,
      "step": 870
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7183849215507507,
      "learning_rate": 2.4059145533079587e-05,
      "loss": 0.3071,
      "step": 880
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8305907845497131,
      "learning_rate": 2.40484540050464e-05,
      "loss": 0.3159,
      "step": 890
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.38009628653526306,
      "learning_rate": 2.4037762477013216e-05,
      "loss": 0.3464,
      "step": 900
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7399830222129822,
      "learning_rate": 2.402707094898003e-05,
      "loss": 0.3824,
      "step": 910
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.41674184799194336,
      "learning_rate": 2.4016379420946845e-05,
      "loss": 0.2713,
      "step": 920
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6811133623123169,
      "learning_rate": 2.4005687892913656e-05,
      "loss": 0.3271,
      "step": 930
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8154619932174683,
      "learning_rate": 2.399499636488047e-05,
      "loss": 0.2961,
      "step": 940
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6530654430389404,
      "learning_rate": 2.3984304836847282e-05,
      "loss": 0.3214,
      "step": 950
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12784837186336517,
      "learning_rate": 2.3973613308814097e-05,
      "loss": 0.2753,
      "step": 960
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9631415009498596,
      "learning_rate": 2.396292178078091e-05,
      "loss": 0.4197,
      "step": 970
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9133046865463257,
      "learning_rate": 2.3952230252747723e-05,
      "loss": 0.4318,
      "step": 980
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.712119996547699,
      "learning_rate": 2.3941538724714537e-05,
      "loss": 0.3082,
      "step": 990
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.008527398109436,
      "learning_rate": 2.393084719668135e-05,
      "loss": 0.3937,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.36042407155036926,
      "eval_runtime": 718.8095,
      "eval_samples_per_second": 3.652,
      "eval_steps_per_second": 3.652,
      "step": 1000
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.927306056022644,
      "learning_rate": 2.3920155668648163e-05,
      "loss": 0.2474,
      "step": 1010
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.5815604329109192,
      "learning_rate": 2.3909464140614978e-05,
      "loss": 0.2826,
      "step": 1020
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8007299304008484,
      "learning_rate": 2.3898772612581792e-05,
      "loss": 0.3942,
      "step": 1030
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8056127429008484,
      "learning_rate": 2.3888081084548607e-05,
      "loss": 0.4054,
      "step": 1040
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9664798378944397,
      "learning_rate": 2.3877389556515418e-05,
      "loss": 0.3442,
      "step": 1050
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7297388911247253,
      "learning_rate": 2.3866698028482233e-05,
      "loss": 0.3399,
      "step": 1060
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7588034868240356,
      "learning_rate": 2.3856006500449047e-05,
      "loss": 0.4448,
      "step": 1070
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9445714950561523,
      "learning_rate": 2.384531497241586e-05,
      "loss": 0.3925,
      "step": 1080
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7435286045074463,
      "learning_rate": 2.3834623444382673e-05,
      "loss": 0.3234,
      "step": 1090
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.35357028245925903,
      "learning_rate": 2.3823931916349484e-05,
      "loss": 0.321,
      "step": 1100
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7644023299217224,
      "learning_rate": 2.38132403883163e-05,
      "loss": 0.2738,
      "step": 1110
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8857635259628296,
      "learning_rate": 2.3802548860283113e-05,
      "loss": 0.3292,
      "step": 1120
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8030074834823608,
      "learning_rate": 2.3791857332249925e-05,
      "loss": 0.3625,
      "step": 1130
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8199532628059387,
      "learning_rate": 2.378116580421674e-05,
      "loss": 0.3009,
      "step": 1140
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7376713156700134,
      "learning_rate": 2.377047427618355e-05,
      "loss": 0.3071,
      "step": 1150
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7042562365531921,
      "learning_rate": 2.3759782748150365e-05,
      "loss": 0.3687,
      "step": 1160
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5751402378082275,
      "learning_rate": 2.374909122011718e-05,
      "loss": 0.3572,
      "step": 1170
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6217952966690063,
      "learning_rate": 2.3738399692083994e-05,
      "loss": 0.3584,
      "step": 1180
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.10141921043396,
      "learning_rate": 2.372770816405081e-05,
      "loss": 0.237,
      "step": 1190
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.3484857380390167,
      "learning_rate": 2.3717016636017623e-05,
      "loss": 0.2953,
      "step": 1200
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7359136939048767,
      "learning_rate": 2.3706325107984434e-05,
      "loss": 0.3813,
      "step": 1210
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5417470932006836,
      "learning_rate": 2.369563357995125e-05,
      "loss": 0.4183,
      "step": 1220
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6047256588935852,
      "learning_rate": 2.368494205191806e-05,
      "loss": 0.3238,
      "step": 1230
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8606366515159607,
      "learning_rate": 2.3674250523884875e-05,
      "loss": 0.4108,
      "step": 1240
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6904796957969666,
      "learning_rate": 2.366355899585169e-05,
      "loss": 0.3526,
      "step": 1250
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6495785117149353,
      "learning_rate": 2.36528674678185e-05,
      "loss": 0.2896,
      "step": 1260
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.4494771361351013,
      "learning_rate": 2.3642175939785315e-05,
      "loss": 0.3188,
      "step": 1270
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.5011165738105774,
      "learning_rate": 2.3631484411752126e-05,
      "loss": 0.378,
      "step": 1280
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8932379484176636,
      "learning_rate": 2.362079288371894e-05,
      "loss": 0.3259,
      "step": 1290
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.3914368748664856,
      "learning_rate": 2.3610101355685756e-05,
      "loss": 0.2769,
      "step": 1300
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0389817953109741,
      "learning_rate": 2.359940982765257e-05,
      "loss": 0.3967,
      "step": 1310
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6643913984298706,
      "learning_rate": 2.3588718299619385e-05,
      "loss": 0.2824,
      "step": 1320
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9956361651420593,
      "learning_rate": 2.3578026771586196e-05,
      "loss": 0.3573,
      "step": 1330
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9661386013031006,
      "learning_rate": 2.356733524355301e-05,
      "loss": 0.334,
      "step": 1340
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9591192007064819,
      "learning_rate": 2.3556643715519825e-05,
      "loss": 0.3475,
      "step": 1350
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0780630111694336,
      "learning_rate": 2.3545952187486636e-05,
      "loss": 0.4596,
      "step": 1360
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.5887548923492432,
      "learning_rate": 2.353526065945345e-05,
      "loss": 0.3605,
      "step": 1370
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.6804258823394775,
      "learning_rate": 2.3524569131420262e-05,
      "loss": 0.3398,
      "step": 1380
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9222400784492493,
      "learning_rate": 2.3513877603387077e-05,
      "loss": 0.2627,
      "step": 1390
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9515188932418823,
      "learning_rate": 2.350318607535389e-05,
      "loss": 0.3001,
      "step": 1400
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9504662156105042,
      "learning_rate": 2.3492494547320703e-05,
      "loss": 0.3733,
      "step": 1410
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9460530281066895,
      "learning_rate": 2.3481803019287517e-05,
      "loss": 0.2249,
      "step": 1420
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7259336113929749,
      "learning_rate": 2.3471111491254332e-05,
      "loss": 0.3789,
      "step": 1430
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8326765298843384,
      "learning_rate": 2.3460419963221146e-05,
      "loss": 0.288,
      "step": 1440
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8133969306945801,
      "learning_rate": 2.344972843518796e-05,
      "loss": 0.3385,
      "step": 1450
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7630476951599121,
      "learning_rate": 2.3439036907154772e-05,
      "loss": 0.2935,
      "step": 1460
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7895341515541077,
      "learning_rate": 2.3428345379121587e-05,
      "loss": 0.3171,
      "step": 1470
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8210263252258301,
      "learning_rate": 2.3417653851088398e-05,
      "loss": 0.2877,
      "step": 1480
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9449761509895325,
      "learning_rate": 2.3406962323055212e-05,
      "loss": 0.3688,
      "step": 1490
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9570742249488831,
      "learning_rate": 2.3396270795022027e-05,
      "loss": 0.2909,
      "step": 1500
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7447078227996826,
      "learning_rate": 2.3385579266988838e-05,
      "loss": 0.339,
      "step": 1510
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7319509983062744,
      "learning_rate": 2.3374887738955653e-05,
      "loss": 0.3297,
      "step": 1520
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0022181272506714,
      "learning_rate": 2.3364196210922464e-05,
      "loss": 0.2618,
      "step": 1530
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9136804342269897,
      "learning_rate": 2.335350468288928e-05,
      "loss": 0.3978,
      "step": 1540
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7910670638084412,
      "learning_rate": 2.3342813154856093e-05,
      "loss": 0.3913,
      "step": 1550
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.3267776668071747,
      "learning_rate": 2.3332121626822904e-05,
      "loss": 0.3909,
      "step": 1560
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.4663121998310089,
      "learning_rate": 2.332143009878972e-05,
      "loss": 0.2613,
      "step": 1570
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.5961316823959351,
      "learning_rate": 2.3310738570756534e-05,
      "loss": 0.3102,
      "step": 1580
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9738638401031494,
      "learning_rate": 2.3300047042723348e-05,
      "loss": 0.3896,
      "step": 1590
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0181139707565308,
      "learning_rate": 2.3289355514690163e-05,
      "loss": 0.3959,
      "step": 1600
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8929203152656555,
      "learning_rate": 2.3278663986656974e-05,
      "loss": 0.3242,
      "step": 1610
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7834758162498474,
      "learning_rate": 2.326797245862379e-05,
      "loss": 0.5026,
      "step": 1620
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8776779770851135,
      "learning_rate": 2.32572809305906e-05,
      "loss": 0.3356,
      "step": 1630
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8473733067512512,
      "learning_rate": 2.3246589402557414e-05,
      "loss": 0.3794,
      "step": 1640
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8667003512382507,
      "learning_rate": 2.323589787452423e-05,
      "loss": 0.346,
      "step": 1650
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7203194499015808,
      "learning_rate": 2.322520634649104e-05,
      "loss": 0.3562,
      "step": 1660
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9129335880279541,
      "learning_rate": 2.3214514818457855e-05,
      "loss": 0.356,
      "step": 1670
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1471304893493652,
      "learning_rate": 2.320382329042467e-05,
      "loss": 0.3721,
      "step": 1680
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8752875328063965,
      "learning_rate": 2.319313176239148e-05,
      "loss": 0.3175,
      "step": 1690
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9312922358512878,
      "learning_rate": 2.3182440234358295e-05,
      "loss": 0.318,
      "step": 1700
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0216584205627441,
      "learning_rate": 2.317174870632511e-05,
      "loss": 0.2566,
      "step": 1710
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.40679293870925903,
      "learning_rate": 2.3161057178291924e-05,
      "loss": 0.3823,
      "step": 1720
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.1640121936798096,
      "learning_rate": 2.315036565025874e-05,
      "loss": 0.3508,
      "step": 1730
    },
    {
      "epoch": 0.07,
      "grad_norm": 4.358254909515381,
      "learning_rate": 2.313967412222555e-05,
      "loss": 0.2685,
      "step": 1740
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.27199530601501465,
      "learning_rate": 2.3128982594192365e-05,
      "loss": 0.2755,
      "step": 1750
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9708918333053589,
      "learning_rate": 2.3118291066159176e-05,
      "loss": 0.3725,
      "step": 1760
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.84004145860672,
      "learning_rate": 2.310759953812599e-05,
      "loss": 0.2714,
      "step": 1770
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7931066751480103,
      "learning_rate": 2.3096908010092805e-05,
      "loss": 0.2759,
      "step": 1780
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3728145360946655,
      "learning_rate": 2.3086216482059616e-05,
      "loss": 0.3597,
      "step": 1790
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8875147104263306,
      "learning_rate": 2.307552495402643e-05,
      "loss": 0.3319,
      "step": 1800
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8339320421218872,
      "learning_rate": 2.3064833425993242e-05,
      "loss": 0.3314,
      "step": 1810
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4352474510669708,
      "learning_rate": 2.3054141897960057e-05,
      "loss": 0.3113,
      "step": 1820
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8022836446762085,
      "learning_rate": 2.304345036992687e-05,
      "loss": 0.3129,
      "step": 1830
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9391277432441711,
      "learning_rate": 2.3032758841893682e-05,
      "loss": 0.306,
      "step": 1840
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.30056989192962646,
      "learning_rate": 2.3022067313860497e-05,
      "loss": 0.3592,
      "step": 1850
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7545475959777832,
      "learning_rate": 2.301137578582731e-05,
      "loss": 0.3263,
      "step": 1860
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0248088836669922,
      "learning_rate": 2.3000684257794126e-05,
      "loss": 0.2096,
      "step": 1870
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0550298690795898,
      "learning_rate": 2.298999272976094e-05,
      "loss": 0.3445,
      "step": 1880
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8738150000572205,
      "learning_rate": 2.2979301201727752e-05,
      "loss": 0.3254,
      "step": 1890
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4975763261318207,
      "learning_rate": 2.2968609673694567e-05,
      "loss": 0.3219,
      "step": 1900
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9714367389678955,
      "learning_rate": 2.2957918145661378e-05,
      "loss": 0.3537,
      "step": 1910
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1249133348464966,
      "learning_rate": 2.2947226617628192e-05,
      "loss": 0.3404,
      "step": 1920
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.31775832176208496,
      "learning_rate": 2.2936535089595007e-05,
      "loss": 0.2599,
      "step": 1930
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8138387799263,
      "learning_rate": 2.2925843561561818e-05,
      "loss": 0.2961,
      "step": 1940
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9542232751846313,
      "learning_rate": 2.2915152033528633e-05,
      "loss": 0.271,
      "step": 1950
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0178625583648682,
      "learning_rate": 2.2904460505495444e-05,
      "loss": 0.3632,
      "step": 1960
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1419577598571777,
      "learning_rate": 2.289376897746226e-05,
      "loss": 0.3299,
      "step": 1970
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.984300434589386,
      "learning_rate": 2.2883077449429073e-05,
      "loss": 0.3184,
      "step": 1980
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0836584568023682,
      "learning_rate": 2.2872385921395888e-05,
      "loss": 0.3433,
      "step": 1990
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.866640031337738,
      "learning_rate": 2.2861694393362702e-05,
      "loss": 0.3555,
      "step": 2000
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.33373939990997314,
      "eval_runtime": 720.8053,
      "eval_samples_per_second": 3.642,
      "eval_steps_per_second": 3.642,
      "step": 2000
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9246068000793457,
      "learning_rate": 2.2851002865329514e-05,
      "loss": 0.2854,
      "step": 2010
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0727142095565796,
      "learning_rate": 2.2840311337296328e-05,
      "loss": 0.3466,
      "step": 2020
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8971059918403625,
      "learning_rate": 2.2829619809263143e-05,
      "loss": 0.4021,
      "step": 2030
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5225797891616821,
      "learning_rate": 2.2818928281229954e-05,
      "loss": 0.289,
      "step": 2040
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0246294736862183,
      "learning_rate": 2.280823675319677e-05,
      "loss": 0.3063,
      "step": 2050
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.6561627984046936,
      "learning_rate": 2.279754522516358e-05,
      "loss": 0.3493,
      "step": 2060
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5845369696617126,
      "learning_rate": 2.2786853697130394e-05,
      "loss": 0.319,
      "step": 2070
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9536325931549072,
      "learning_rate": 2.277616216909721e-05,
      "loss": 0.3683,
      "step": 2080
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4864407181739807,
      "learning_rate": 2.276547064106402e-05,
      "loss": 0.282,
      "step": 2090
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8333408236503601,
      "learning_rate": 2.2754779113030835e-05,
      "loss": 0.3632,
      "step": 2100
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5557483434677124,
      "learning_rate": 2.2744087584997646e-05,
      "loss": 0.3536,
      "step": 2110
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.4063877463340759,
      "learning_rate": 2.273339605696446e-05,
      "loss": 0.325,
      "step": 2120
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.244401454925537,
      "learning_rate": 2.2722704528931275e-05,
      "loss": 0.261,
      "step": 2130
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1607177257537842,
      "learning_rate": 2.271201300089809e-05,
      "loss": 0.3747,
      "step": 2140
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.5819778442382812,
      "learning_rate": 2.2701321472864904e-05,
      "loss": 0.3464,
      "step": 2150
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.106063961982727,
      "learning_rate": 2.269062994483172e-05,
      "loss": 0.3672,
      "step": 2160
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2370871305465698,
      "learning_rate": 2.267993841679853e-05,
      "loss": 0.4163,
      "step": 2170
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.312975287437439,
      "learning_rate": 2.2669246888765345e-05,
      "loss": 0.379,
      "step": 2180
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8917655944824219,
      "learning_rate": 2.2658555360732156e-05,
      "loss": 0.3392,
      "step": 2190
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9699645042419434,
      "learning_rate": 2.264786383269897e-05,
      "loss": 0.3018,
      "step": 2200
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0452829599380493,
      "learning_rate": 2.2637172304665785e-05,
      "loss": 0.305,
      "step": 2210
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8118643164634705,
      "learning_rate": 2.2626480776632596e-05,
      "loss": 0.4074,
      "step": 2220
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8539342284202576,
      "learning_rate": 2.261578924859941e-05,
      "loss": 0.3382,
      "step": 2230
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0817277431488037,
      "learning_rate": 2.2605097720566222e-05,
      "loss": 0.3773,
      "step": 2240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7213032245635986,
      "learning_rate": 2.2594406192533037e-05,
      "loss": 0.2277,
      "step": 2250
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0338199138641357,
      "learning_rate": 2.258371466449985e-05,
      "loss": 0.3415,
      "step": 2260
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1894829273223877,
      "learning_rate": 2.2573023136466666e-05,
      "loss": 0.4454,
      "step": 2270
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.3873710036277771,
      "learning_rate": 2.256233160843348e-05,
      "loss": 0.2498,
      "step": 2280
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.7522381544113159,
      "learning_rate": 2.255164008040029e-05,
      "loss": 0.324,
      "step": 2290
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.49549639225006104,
      "learning_rate": 2.2540948552367106e-05,
      "loss": 0.247,
      "step": 2300
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1641122102737427,
      "learning_rate": 2.253025702433392e-05,
      "loss": 0.3235,
      "step": 2310
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.2691251039505005,
      "learning_rate": 2.2519565496300732e-05,
      "loss": 0.2655,
      "step": 2320
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0745981931686401,
      "learning_rate": 2.2508873968267547e-05,
      "loss": 0.261,
      "step": 2330
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1579962968826294,
      "learning_rate": 2.2498182440234358e-05,
      "loss": 0.3219,
      "step": 2340
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6940112113952637,
      "learning_rate": 2.2487490912201172e-05,
      "loss": 0.2722,
      "step": 2350
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.077188491821289,
      "learning_rate": 2.2476799384167987e-05,
      "loss": 0.3706,
      "step": 2360
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.6902355551719666,
      "learning_rate": 2.2466107856134798e-05,
      "loss": 0.2763,
      "step": 2370
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.111864686012268,
      "learning_rate": 2.2455416328101613e-05,
      "loss": 0.3788,
      "step": 2380
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0409412384033203,
      "learning_rate": 2.2444724800068427e-05,
      "loss": 0.2755,
      "step": 2390
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.733882486820221,
      "learning_rate": 2.2434033272035242e-05,
      "loss": 0.3188,
      "step": 2400
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9836728572845459,
      "learning_rate": 2.2423341744002057e-05,
      "loss": 0.3191,
      "step": 2410
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8856268525123596,
      "learning_rate": 2.2412650215968868e-05,
      "loss": 0.232,
      "step": 2420
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.900994598865509,
      "learning_rate": 2.2401958687935682e-05,
      "loss": 0.3238,
      "step": 2430
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.922763466835022,
      "learning_rate": 2.2391267159902493e-05,
      "loss": 0.3264,
      "step": 2440
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9267632961273193,
      "learning_rate": 2.2380575631869308e-05,
      "loss": 0.3208,
      "step": 2450
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9306864738464355,
      "learning_rate": 2.2369884103836123e-05,
      "loss": 0.3862,
      "step": 2460
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.107602596282959,
      "learning_rate": 2.2359192575802934e-05,
      "loss": 0.3225,
      "step": 2470
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3144488334655762,
      "learning_rate": 2.234850104776975e-05,
      "loss": 0.3134,
      "step": 2480
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1633327007293701,
      "learning_rate": 2.233780951973656e-05,
      "loss": 0.3509,
      "step": 2490
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.648109495639801,
      "learning_rate": 2.2327117991703374e-05,
      "loss": 0.2448,
      "step": 2500
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8785316944122314,
      "learning_rate": 2.231642646367019e-05,
      "loss": 0.2764,
      "step": 2510
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0162265300750732,
      "learning_rate": 2.2305734935637e-05,
      "loss": 0.2552,
      "step": 2520
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0535343885421753,
      "learning_rate": 2.2295043407603815e-05,
      "loss": 0.3232,
      "step": 2530
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1303402185440063,
      "learning_rate": 2.228435187957063e-05,
      "loss": 0.3034,
      "step": 2540
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1200170516967773,
      "learning_rate": 2.2273660351537444e-05,
      "loss": 0.2336,
      "step": 2550
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0110682249069214,
      "learning_rate": 2.226296882350426e-05,
      "loss": 0.3344,
      "step": 2560
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0271488428115845,
      "learning_rate": 2.225227729547107e-05,
      "loss": 0.3223,
      "step": 2570
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.49648141860961914,
      "learning_rate": 2.2241585767437884e-05,
      "loss": 0.2713,
      "step": 2580
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.129867672920227,
      "learning_rate": 2.2230894239404695e-05,
      "loss": 0.3707,
      "step": 2590
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8337346315383911,
      "learning_rate": 2.222020271137151e-05,
      "loss": 0.2665,
      "step": 2600
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.6465426087379456,
      "learning_rate": 2.2209511183338325e-05,
      "loss": 0.3439,
      "step": 2610
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5727571845054626,
      "learning_rate": 2.2198819655305136e-05,
      "loss": 0.2716,
      "step": 2620
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9871963858604431,
      "learning_rate": 2.218812812727195e-05,
      "loss": 0.2605,
      "step": 2630
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7530547380447388,
      "learning_rate": 2.2177436599238765e-05,
      "loss": 0.3162,
      "step": 2640
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.30302390456199646,
      "learning_rate": 2.2166745071205576e-05,
      "loss": 0.2123,
      "step": 2650
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.5804474949836731,
      "learning_rate": 2.215605354317239e-05,
      "loss": 0.2602,
      "step": 2660
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9616485834121704,
      "learning_rate": 2.2145362015139205e-05,
      "loss": 0.262,
      "step": 2670
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1116328239440918,
      "learning_rate": 2.213467048710602e-05,
      "loss": 0.3235,
      "step": 2680
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0219712257385254,
      "learning_rate": 2.2123978959072835e-05,
      "loss": 0.3925,
      "step": 2690
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8360095024108887,
      "learning_rate": 2.2113287431039646e-05,
      "loss": 0.3247,
      "step": 2700
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0867754220962524,
      "learning_rate": 2.210259590300646e-05,
      "loss": 0.2882,
      "step": 2710
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.3949908018112183,
      "learning_rate": 2.209190437497327e-05,
      "loss": 0.287,
      "step": 2720
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8209933638572693,
      "learning_rate": 2.2081212846940086e-05,
      "loss": 0.2942,
      "step": 2730
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.2094792127609253,
      "learning_rate": 2.20705213189069e-05,
      "loss": 0.2725,
      "step": 2740
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9677472710609436,
      "learning_rate": 2.2059829790873712e-05,
      "loss": 0.3992,
      "step": 2750
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0066564083099365,
      "learning_rate": 2.2049138262840526e-05,
      "loss": 0.3475,
      "step": 2760
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9621434807777405,
      "learning_rate": 2.2038446734807338e-05,
      "loss": 0.3297,
      "step": 2770
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9474324584007263,
      "learning_rate": 2.2027755206774152e-05,
      "loss": 0.2851,
      "step": 2780
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.33993449807167053,
      "learning_rate": 2.2017063678740967e-05,
      "loss": 0.2753,
      "step": 2790
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.1991026401519775,
      "learning_rate": 2.2006372150707778e-05,
      "loss": 0.3431,
      "step": 2800
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.109472632408142,
      "learning_rate": 2.1995680622674593e-05,
      "loss": 0.3492,
      "step": 2810
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.3630969524383545,
      "learning_rate": 2.1984989094641407e-05,
      "loss": 0.3684,
      "step": 2820
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9947324395179749,
      "learning_rate": 2.1974297566608222e-05,
      "loss": 0.26,
      "step": 2830
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.2014803886413574,
      "learning_rate": 2.1963606038575036e-05,
      "loss": 0.3368,
      "step": 2840
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.5074065923690796,
      "learning_rate": 2.1952914510541848e-05,
      "loss": 0.3044,
      "step": 2850
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.08986496925354,
      "learning_rate": 2.1942222982508662e-05,
      "loss": 0.3579,
      "step": 2860
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.269213080406189,
      "learning_rate": 2.1931531454475473e-05,
      "loss": 0.4079,
      "step": 2870
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9724671840667725,
      "learning_rate": 2.1920839926442288e-05,
      "loss": 0.3798,
      "step": 2880
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9321862459182739,
      "learning_rate": 2.1910148398409103e-05,
      "loss": 0.3744,
      "step": 2890
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1219912767410278,
      "learning_rate": 2.1899456870375914e-05,
      "loss": 0.3181,
      "step": 2900
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8492580056190491,
      "learning_rate": 2.188876534234273e-05,
      "loss": 0.2835,
      "step": 2910
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6737942695617676,
      "learning_rate": 2.187807381430954e-05,
      "loss": 0.3216,
      "step": 2920
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.7080919742584229,
      "learning_rate": 2.1867382286276354e-05,
      "loss": 0.3045,
      "step": 2930
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.286787509918213,
      "learning_rate": 2.185669075824317e-05,
      "loss": 0.3553,
      "step": 2940
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.3799184262752533,
      "learning_rate": 2.1845999230209983e-05,
      "loss": 0.2956,
      "step": 2950
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1729706525802612,
      "learning_rate": 2.1835307702176798e-05,
      "loss": 0.2987,
      "step": 2960
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.851215660572052,
      "learning_rate": 2.182461617414361e-05,
      "loss": 0.284,
      "step": 2970
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8899217247962952,
      "learning_rate": 2.1813924646110424e-05,
      "loss": 0.3213,
      "step": 2980
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1111973524093628,
      "learning_rate": 2.180323311807724e-05,
      "loss": 0.2703,
      "step": 2990
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.930895984172821,
      "learning_rate": 2.179254159004405e-05,
      "loss": 0.3554,
      "step": 3000
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.3203226923942566,
      "eval_runtime": 722.5109,
      "eval_samples_per_second": 3.633,
      "eval_steps_per_second": 3.633,
      "step": 3000
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1487023830413818,
      "learning_rate": 2.1781850062010864e-05,
      "loss": 0.3685,
      "step": 3010
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4044318199157715,
      "learning_rate": 2.1771158533977675e-05,
      "loss": 0.3593,
      "step": 3020
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1250697374343872,
      "learning_rate": 2.176046700594449e-05,
      "loss": 0.2995,
      "step": 3030
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3434969186782837,
      "learning_rate": 2.1749775477911305e-05,
      "loss": 0.4028,
      "step": 3040
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.992434024810791,
      "learning_rate": 2.1739083949878116e-05,
      "loss": 0.2904,
      "step": 3050
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9395939707756042,
      "learning_rate": 2.172839242184493e-05,
      "loss": 0.3307,
      "step": 3060
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0531412363052368,
      "learning_rate": 2.1717700893811745e-05,
      "loss": 0.3452,
      "step": 3070
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0200468301773071,
      "learning_rate": 2.170700936577856e-05,
      "loss": 0.3227,
      "step": 3080
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2012169361114502,
      "learning_rate": 2.1696317837745374e-05,
      "loss": 0.2956,
      "step": 3090
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9566363096237183,
      "learning_rate": 2.1685626309712185e-05,
      "loss": 0.3191,
      "step": 3100
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8522941470146179,
      "learning_rate": 2.1674934781679e-05,
      "loss": 0.3137,
      "step": 3110
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.071242332458496,
      "learning_rate": 2.1664243253645814e-05,
      "loss": 0.3401,
      "step": 3120
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1647921800613403,
      "learning_rate": 2.1653551725612626e-05,
      "loss": 0.2943,
      "step": 3130
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9367180466651917,
      "learning_rate": 2.164286019757944e-05,
      "loss": 0.3599,
      "step": 3140
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.4033669233322144,
      "learning_rate": 2.163216866954625e-05,
      "loss": 0.2637,
      "step": 3150
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.86847984790802,
      "learning_rate": 2.1621477141513066e-05,
      "loss": 0.3665,
      "step": 3160
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8073408007621765,
      "learning_rate": 2.161078561347988e-05,
      "loss": 0.2242,
      "step": 3170
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7387523055076599,
      "learning_rate": 2.1600094085446692e-05,
      "loss": 0.3315,
      "step": 3180
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7625737190246582,
      "learning_rate": 2.1589402557413506e-05,
      "loss": 0.3336,
      "step": 3190
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3299769163131714,
      "learning_rate": 2.1578711029380318e-05,
      "loss": 0.2675,
      "step": 3200
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9683966636657715,
      "learning_rate": 2.1568019501347132e-05,
      "loss": 0.2639,
      "step": 3210
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.5727170705795288,
      "learning_rate": 2.1557327973313947e-05,
      "loss": 0.2833,
      "step": 3220
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.36829888820648193,
      "learning_rate": 2.154663644528076e-05,
      "loss": 0.2568,
      "step": 3230
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.6878564953804016,
      "learning_rate": 2.1535944917247576e-05,
      "loss": 0.2783,
      "step": 3240
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0568971633911133,
      "learning_rate": 2.1525253389214387e-05,
      "loss": 0.2558,
      "step": 3250
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0555416345596313,
      "learning_rate": 2.1514561861181202e-05,
      "loss": 0.3306,
      "step": 3260
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0821449756622314,
      "learning_rate": 2.1503870333148016e-05,
      "loss": 0.3479,
      "step": 3270
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.7750262022018433,
      "learning_rate": 2.1493178805114828e-05,
      "loss": 0.2873,
      "step": 3280
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0390007495880127,
      "learning_rate": 2.1482487277081642e-05,
      "loss": 0.3246,
      "step": 3290
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2681663036346436,
      "learning_rate": 2.1471795749048453e-05,
      "loss": 0.3952,
      "step": 3300
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2361962795257568,
      "learning_rate": 2.1461104221015268e-05,
      "loss": 0.3113,
      "step": 3310
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.151481032371521,
      "learning_rate": 2.1450412692982083e-05,
      "loss": 0.2849,
      "step": 3320
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8981135487556458,
      "learning_rate": 2.1439721164948894e-05,
      "loss": 0.2852,
      "step": 3330
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.809291422367096,
      "learning_rate": 2.142902963691571e-05,
      "loss": 0.341,
      "step": 3340
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0910565853118896,
      "learning_rate": 2.1418338108882523e-05,
      "loss": 0.3649,
      "step": 3350
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.090779423713684,
      "learning_rate": 2.1407646580849338e-05,
      "loss": 0.3082,
      "step": 3360
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.7859266996383667,
      "learning_rate": 2.1396955052816152e-05,
      "loss": 0.2426,
      "step": 3370
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.8276863098144531,
      "learning_rate": 2.1386263524782963e-05,
      "loss": 0.1971,
      "step": 3380
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1109334230422974,
      "learning_rate": 2.1375571996749778e-05,
      "loss": 0.3107,
      "step": 3390
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1543177366256714,
      "learning_rate": 2.136488046871659e-05,
      "loss": 0.2567,
      "step": 3400
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0285531282424927,
      "learning_rate": 2.1354188940683404e-05,
      "loss": 0.3094,
      "step": 3410
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0598313808441162,
      "learning_rate": 2.1343497412650218e-05,
      "loss": 0.272,
      "step": 3420
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1727360486984253,
      "learning_rate": 2.133280588461703e-05,
      "loss": 0.3053,
      "step": 3430
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.3635445833206177,
      "learning_rate": 2.1322114356583844e-05,
      "loss": 0.3895,
      "step": 3440
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2394986152648926,
      "learning_rate": 2.1311422828550655e-05,
      "loss": 0.3813,
      "step": 3450
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.4412892162799835,
      "learning_rate": 2.130073130051747e-05,
      "loss": 0.1813,
      "step": 3460
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9909949898719788,
      "learning_rate": 2.1290039772484284e-05,
      "loss": 0.3067,
      "step": 3470
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8964346051216125,
      "learning_rate": 2.1279348244451096e-05,
      "loss": 0.2713,
      "step": 3480
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.007857084274292,
      "learning_rate": 2.126865671641791e-05,
      "loss": 0.2563,
      "step": 3490
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9558524489402771,
      "learning_rate": 2.1257965188384725e-05,
      "loss": 0.2663,
      "step": 3500
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.410352498292923,
      "learning_rate": 2.124727366035154e-05,
      "loss": 0.3198,
      "step": 3510
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2190335988998413,
      "learning_rate": 2.1236582132318354e-05,
      "loss": 0.3055,
      "step": 3520
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.430944800376892,
      "learning_rate": 2.1225890604285165e-05,
      "loss": 0.2845,
      "step": 3530
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2605501413345337,
      "learning_rate": 2.121519907625198e-05,
      "loss": 0.332,
      "step": 3540
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.6193896532058716,
      "learning_rate": 2.1204507548218794e-05,
      "loss": 0.3057,
      "step": 3550
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9603585004806519,
      "learning_rate": 2.1193816020185606e-05,
      "loss": 0.3937,
      "step": 3560
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7851771116256714,
      "learning_rate": 2.118312449215242e-05,
      "loss": 0.2715,
      "step": 3570
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.5524033308029175,
      "learning_rate": 2.117243296411923e-05,
      "loss": 0.2858,
      "step": 3580
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8615962266921997,
      "learning_rate": 2.1161741436086046e-05,
      "loss": 0.3147,
      "step": 3590
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0431971549987793,
      "learning_rate": 2.115104990805286e-05,
      "loss": 0.2807,
      "step": 3600
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0650449991226196,
      "learning_rate": 2.1140358380019672e-05,
      "loss": 0.3291,
      "step": 3610
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1711903810501099,
      "learning_rate": 2.1129666851986486e-05,
      "loss": 0.2949,
      "step": 3620
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5877020955085754,
      "learning_rate": 2.11189753239533e-05,
      "loss": 0.2552,
      "step": 3630
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5146597027778625,
      "learning_rate": 2.1108283795920116e-05,
      "loss": 0.294,
      "step": 3640
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1999356746673584,
      "learning_rate": 2.109759226788693e-05,
      "loss": 0.301,
      "step": 3650
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1548274755477905,
      "learning_rate": 2.108690073985374e-05,
      "loss": 0.2305,
      "step": 3660
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2709600925445557,
      "learning_rate": 2.1076209211820556e-05,
      "loss": 0.3426,
      "step": 3670
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4445936679840088,
      "learning_rate": 2.1065517683787367e-05,
      "loss": 0.3205,
      "step": 3680
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1994367837905884,
      "learning_rate": 2.1054826155754182e-05,
      "loss": 0.2681,
      "step": 3690
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5024582743644714,
      "learning_rate": 2.1044134627720996e-05,
      "loss": 0.312,
      "step": 3700
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.619957685470581,
      "learning_rate": 2.1033443099687808e-05,
      "loss": 0.356,
      "step": 3710
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0954867601394653,
      "learning_rate": 2.1022751571654622e-05,
      "loss": 0.3283,
      "step": 3720
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1520864963531494,
      "learning_rate": 2.1012060043621433e-05,
      "loss": 0.2973,
      "step": 3730
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.237810730934143,
      "learning_rate": 2.1001368515588248e-05,
      "loss": 0.2492,
      "step": 3740
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.387987494468689,
      "learning_rate": 2.0990676987555062e-05,
      "loss": 0.2386,
      "step": 3750
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0417282581329346,
      "learning_rate": 2.0979985459521874e-05,
      "loss": 0.3615,
      "step": 3760
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0167856216430664,
      "learning_rate": 2.0969293931488688e-05,
      "loss": 0.2046,
      "step": 3770
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1659715175628662,
      "learning_rate": 2.0958602403455503e-05,
      "loss": 0.2696,
      "step": 3780
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0878981351852417,
      "learning_rate": 2.0947910875422317e-05,
      "loss": 0.293,
      "step": 3790
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9832034707069397,
      "learning_rate": 2.0937219347389132e-05,
      "loss": 0.3028,
      "step": 3800
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1484949588775635,
      "learning_rate": 2.0926527819355943e-05,
      "loss": 0.2768,
      "step": 3810
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.2541416585445404,
      "learning_rate": 2.0915836291322758e-05,
      "loss": 0.2514,
      "step": 3820
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6606419682502747,
      "learning_rate": 2.090514476328957e-05,
      "loss": 0.3315,
      "step": 3830
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0451574325561523,
      "learning_rate": 2.0894453235256384e-05,
      "loss": 0.3317,
      "step": 3840
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9351722002029419,
      "learning_rate": 2.0883761707223198e-05,
      "loss": 0.2959,
      "step": 3850
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1545625925064087,
      "learning_rate": 2.087307017919001e-05,
      "loss": 0.3882,
      "step": 3860
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.6144118905067444,
      "learning_rate": 2.0862378651156824e-05,
      "loss": 0.3103,
      "step": 3870
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5297567844390869,
      "learning_rate": 2.0851687123123635e-05,
      "loss": 0.2548,
      "step": 3880
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5286832451820374,
      "learning_rate": 2.084099559509045e-05,
      "loss": 0.3044,
      "step": 3890
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.3229750394821167,
      "learning_rate": 2.0830304067057264e-05,
      "loss": 0.3371,
      "step": 3900
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0644327402114868,
      "learning_rate": 2.081961253902408e-05,
      "loss": 0.2614,
      "step": 3910
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0992379188537598,
      "learning_rate": 2.0808921010990894e-05,
      "loss": 0.2546,
      "step": 3920
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.3290925025939941,
      "learning_rate": 2.0798229482957705e-05,
      "loss": 0.3219,
      "step": 3930
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.21808086335659027,
      "learning_rate": 2.078753795492452e-05,
      "loss": 0.2729,
      "step": 3940
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.4496859312057495,
      "learning_rate": 2.0776846426891334e-05,
      "loss": 0.304,
      "step": 3950
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8486469388008118,
      "learning_rate": 2.0766154898858145e-05,
      "loss": 0.2931,
      "step": 3960
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.118323802947998,
      "learning_rate": 2.075546337082496e-05,
      "loss": 0.2812,
      "step": 3970
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0480552911758423,
      "learning_rate": 2.074477184279177e-05,
      "loss": 0.2611,
      "step": 3980
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.368151307106018,
      "learning_rate": 2.0734080314758586e-05,
      "loss": 0.3,
      "step": 3990
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9952684044837952,
      "learning_rate": 2.07233887867254e-05,
      "loss": 0.2894,
      "step": 4000
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.3127952814102173,
      "eval_runtime": 723.3242,
      "eval_samples_per_second": 3.629,
      "eval_steps_per_second": 3.629,
      "step": 4000
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1382941007614136,
      "learning_rate": 2.071269725869221e-05,
      "loss": 0.1981,
      "step": 4010
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.4641785621643066,
      "learning_rate": 2.0702005730659026e-05,
      "loss": 0.3633,
      "step": 4020
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8730885982513428,
      "learning_rate": 2.069131420262584e-05,
      "loss": 0.2784,
      "step": 4030
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0427101850509644,
      "learning_rate": 2.0680622674592655e-05,
      "loss": 0.3653,
      "step": 4040
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.4559810161590576,
      "learning_rate": 2.066993114655947e-05,
      "loss": 0.2872,
      "step": 4050
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.3760574162006378,
      "learning_rate": 2.065923961852628e-05,
      "loss": 0.4095,
      "step": 4060
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.6949877738952637,
      "learning_rate": 2.0648548090493095e-05,
      "loss": 0.3073,
      "step": 4070
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8893729448318481,
      "learning_rate": 2.063785656245991e-05,
      "loss": 0.3352,
      "step": 4080
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5374353528022766,
      "learning_rate": 2.062716503442672e-05,
      "loss": 0.2623,
      "step": 4090
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0696921348571777,
      "learning_rate": 2.0616473506393536e-05,
      "loss": 0.3229,
      "step": 4100
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.521406352519989,
      "learning_rate": 2.0605781978360347e-05,
      "loss": 0.2359,
      "step": 4110
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1710532903671265,
      "learning_rate": 2.059509045032716e-05,
      "loss": 0.3286,
      "step": 4120
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2772259712219238,
      "learning_rate": 2.0584398922293976e-05,
      "loss": 0.3136,
      "step": 4130
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7402060031890869,
      "learning_rate": 2.0573707394260787e-05,
      "loss": 0.2698,
      "step": 4140
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.376385897397995,
      "learning_rate": 2.0563015866227602e-05,
      "loss": 0.26,
      "step": 4150
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.7297555804252625,
      "learning_rate": 2.0552324338194413e-05,
      "loss": 0.3438,
      "step": 4160
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1252520084381104,
      "learning_rate": 2.0541632810161228e-05,
      "loss": 0.2821,
      "step": 4170
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0706534385681152,
      "learning_rate": 2.0530941282128042e-05,
      "loss": 0.3131,
      "step": 4180
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1439309120178223,
      "learning_rate": 2.0520249754094857e-05,
      "loss": 0.2974,
      "step": 4190
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.3066531419754028,
      "learning_rate": 2.050955822606167e-05,
      "loss": 0.2998,
      "step": 4200
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0421055555343628,
      "learning_rate": 2.0498866698028483e-05,
      "loss": 0.3256,
      "step": 4210
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.186745524406433,
      "learning_rate": 2.0488175169995297e-05,
      "loss": 0.302,
      "step": 4220
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.7779459953308105,
      "learning_rate": 2.0477483641962112e-05,
      "loss": 0.3366,
      "step": 4230
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.5206199884414673,
      "learning_rate": 2.0466792113928923e-05,
      "loss": 0.2411,
      "step": 4240
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.461562991142273,
      "learning_rate": 2.0456100585895738e-05,
      "loss": 0.3234,
      "step": 4250
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.3112460374832153,
      "learning_rate": 2.044540905786255e-05,
      "loss": 0.3134,
      "step": 4260
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2747981548309326,
      "learning_rate": 2.0434717529829364e-05,
      "loss": 0.2215,
      "step": 4270
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.264789342880249,
      "learning_rate": 2.0424026001796178e-05,
      "loss": 0.3012,
      "step": 4280
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.43165117502212524,
      "learning_rate": 2.041333447376299e-05,
      "loss": 0.323,
      "step": 4290
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2418227195739746,
      "learning_rate": 2.0402642945729804e-05,
      "loss": 0.3362,
      "step": 4300
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6596988439559937,
      "learning_rate": 2.039195141769662e-05,
      "loss": 0.2987,
      "step": 4310
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1565017700195312,
      "learning_rate": 2.0381259889663433e-05,
      "loss": 0.2795,
      "step": 4320
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8861738443374634,
      "learning_rate": 2.0370568361630248e-05,
      "loss": 0.3432,
      "step": 4330
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4405277967453003,
      "learning_rate": 2.035987683359706e-05,
      "loss": 0.3222,
      "step": 4340
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7616497874259949,
      "learning_rate": 2.0349185305563874e-05,
      "loss": 0.2489,
      "step": 4350
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.3873732089996338,
      "learning_rate": 2.0338493777530685e-05,
      "loss": 0.3014,
      "step": 4360
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1119498014450073,
      "learning_rate": 2.03278022494975e-05,
      "loss": 0.3828,
      "step": 4370
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1201521158218384,
      "learning_rate": 2.0317110721464314e-05,
      "loss": 0.332,
      "step": 4380
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7721912264823914,
      "learning_rate": 2.0306419193431125e-05,
      "loss": 0.2648,
      "step": 4390
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2497705221176147,
      "learning_rate": 2.029572766539794e-05,
      "loss": 0.2596,
      "step": 4400
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.677043080329895,
      "learning_rate": 2.028503613736475e-05,
      "loss": 0.2189,
      "step": 4410
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1522125005722046,
      "learning_rate": 2.0274344609331565e-05,
      "loss": 0.3072,
      "step": 4420
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2558295726776123,
      "learning_rate": 2.026365308129838e-05,
      "loss": 0.2964,
      "step": 4430
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8044283390045166,
      "learning_rate": 2.025296155326519e-05,
      "loss": 0.2385,
      "step": 4440
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2773600816726685,
      "learning_rate": 2.0242270025232006e-05,
      "loss": 0.3105,
      "step": 4450
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.329385757446289,
      "learning_rate": 2.023157849719882e-05,
      "loss": 0.2865,
      "step": 4460
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7836750149726868,
      "learning_rate": 2.0220886969165635e-05,
      "loss": 0.2616,
      "step": 4470
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.7587913274765015,
      "learning_rate": 2.021019544113245e-05,
      "loss": 0.2998,
      "step": 4480
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9657146334648132,
      "learning_rate": 2.019950391309926e-05,
      "loss": 0.3231,
      "step": 4490
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.088356375694275,
      "learning_rate": 2.0188812385066075e-05,
      "loss": 0.3206,
      "step": 4500
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.01960289478302,
      "learning_rate": 2.017812085703289e-05,
      "loss": 0.3051,
      "step": 4510
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.8140921592712402,
      "learning_rate": 2.01674293289997e-05,
      "loss": 0.2574,
      "step": 4520
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0834296941757202,
      "learning_rate": 2.0156737800966516e-05,
      "loss": 0.3608,
      "step": 4530
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.6107457876205444,
      "learning_rate": 2.0146046272933327e-05,
      "loss": 0.3173,
      "step": 4540
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1324665546417236,
      "learning_rate": 2.013535474490014e-05,
      "loss": 0.4263,
      "step": 4550
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0928187370300293,
      "learning_rate": 2.0124663216866956e-05,
      "loss": 0.3276,
      "step": 4560
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3283113241195679,
      "learning_rate": 2.0113971688833767e-05,
      "loss": 0.3487,
      "step": 4570
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0885199308395386,
      "learning_rate": 2.0103280160800582e-05,
      "loss": 0.2334,
      "step": 4580
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1939131021499634,
      "learning_rate": 2.0092588632767397e-05,
      "loss": 0.2478,
      "step": 4590
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.4323517084121704,
      "learning_rate": 2.008189710473421e-05,
      "loss": 0.3252,
      "step": 4600
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.9053210020065308,
      "learning_rate": 2.0071205576701026e-05,
      "loss": 0.3028,
      "step": 4610
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.298052430152893,
      "learning_rate": 2.0060514048667837e-05,
      "loss": 0.3004,
      "step": 4620
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2500734329223633,
      "learning_rate": 2.004982252063465e-05,
      "loss": 0.3205,
      "step": 4630
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0518344640731812,
      "learning_rate": 2.0039130992601463e-05,
      "loss": 0.2951,
      "step": 4640
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1909081935882568,
      "learning_rate": 2.0028439464568277e-05,
      "loss": 0.3347,
      "step": 4650
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8963867425918579,
      "learning_rate": 2.0017747936535092e-05,
      "loss": 0.3538,
      "step": 4660
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2669432163238525,
      "learning_rate": 2.0007056408501903e-05,
      "loss": 0.2619,
      "step": 4670
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.7715762853622437,
      "learning_rate": 1.9996364880468718e-05,
      "loss": 0.3291,
      "step": 4680
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3351911306381226,
      "learning_rate": 1.998567335243553e-05,
      "loss": 0.3402,
      "step": 4690
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1037739515304565,
      "learning_rate": 1.9974981824402344e-05,
      "loss": 0.3232,
      "step": 4700
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8867942094802856,
      "learning_rate": 1.9964290296369158e-05,
      "loss": 0.3632,
      "step": 4710
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1255791187286377,
      "learning_rate": 1.995359876833597e-05,
      "loss": 0.2679,
      "step": 4720
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6816499829292297,
      "learning_rate": 1.9942907240302784e-05,
      "loss": 0.3185,
      "step": 4730
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3926844596862793,
      "learning_rate": 1.99322157122696e-05,
      "loss": 0.3378,
      "step": 4740
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1154032945632935,
      "learning_rate": 1.9921524184236413e-05,
      "loss": 0.27,
      "step": 4750
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.3359464406967163,
      "learning_rate": 1.9910832656203228e-05,
      "loss": 0.3701,
      "step": 4760
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2562724351882935,
      "learning_rate": 1.990014112817004e-05,
      "loss": 0.2951,
      "step": 4770
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1615766286849976,
      "learning_rate": 1.9889449600136853e-05,
      "loss": 0.2879,
      "step": 4780
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.00746750831604,
      "learning_rate": 1.9878758072103665e-05,
      "loss": 0.3611,
      "step": 4790
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6179136633872986,
      "learning_rate": 1.986806654407048e-05,
      "loss": 0.2498,
      "step": 4800
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2411425113677979,
      "learning_rate": 1.9857375016037294e-05,
      "loss": 0.3826,
      "step": 4810
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.430348515510559,
      "learning_rate": 1.9846683488004105e-05,
      "loss": 0.3603,
      "step": 4820
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0885651111602783,
      "learning_rate": 1.983599195997092e-05,
      "loss": 0.3004,
      "step": 4830
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.198792576789856,
      "learning_rate": 1.982530043193773e-05,
      "loss": 0.2628,
      "step": 4840
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0446385145187378,
      "learning_rate": 1.9814608903904545e-05,
      "loss": 0.3568,
      "step": 4850
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.6703230142593384,
      "learning_rate": 1.980391737587136e-05,
      "loss": 0.325,
      "step": 4860
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.340468406677246,
      "learning_rate": 1.9793225847838175e-05,
      "loss": 0.3254,
      "step": 4870
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0612176656723022,
      "learning_rate": 1.978253431980499e-05,
      "loss": 0.2605,
      "step": 4880
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.167839765548706,
      "learning_rate": 1.97718427917718e-05,
      "loss": 0.28,
      "step": 4890
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2486696243286133,
      "learning_rate": 1.9761151263738615e-05,
      "loss": 0.3897,
      "step": 4900
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.5726110935211182,
      "learning_rate": 1.975045973570543e-05,
      "loss": 0.2609,
      "step": 4910
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7656068801879883,
      "learning_rate": 1.973976820767224e-05,
      "loss": 0.3128,
      "step": 4920
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.225264310836792,
      "learning_rate": 1.9729076679639055e-05,
      "loss": 0.3077,
      "step": 4930
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9744266271591187,
      "learning_rate": 1.9718385151605867e-05,
      "loss": 0.3566,
      "step": 4940
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2865498065948486,
      "learning_rate": 1.970769362357268e-05,
      "loss": 0.3324,
      "step": 4950
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.17145907878875732,
      "learning_rate": 1.9697002095539496e-05,
      "loss": 0.2481,
      "step": 4960
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0960190296173096,
      "learning_rate": 1.9686310567506307e-05,
      "loss": 0.2689,
      "step": 4970
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.130388855934143,
      "learning_rate": 1.967561903947312e-05,
      "loss": 0.275,
      "step": 4980
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8301142454147339,
      "learning_rate": 1.9664927511439936e-05,
      "loss": 0.2471,
      "step": 4990
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1345012187957764,
      "learning_rate": 1.965423598340675e-05,
      "loss": 0.2909,
      "step": 5000
    },
    {
      "epoch": 0.21,
      "eval_loss": 0.3072613477706909,
      "eval_runtime": 725.0471,
      "eval_samples_per_second": 3.62,
      "eval_steps_per_second": 3.62,
      "step": 5000
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1536011695861816,
      "learning_rate": 1.9643544455373565e-05,
      "loss": 0.2836,
      "step": 5010
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.389247179031372,
      "learning_rate": 1.9632852927340377e-05,
      "loss": 0.3274,
      "step": 5020
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0984277725219727,
      "learning_rate": 1.962216139930719e-05,
      "loss": 0.2793,
      "step": 5030
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3279978036880493,
      "learning_rate": 1.9611469871274006e-05,
      "loss": 0.2302,
      "step": 5040
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3925982713699341,
      "learning_rate": 1.9600778343240817e-05,
      "loss": 0.2716,
      "step": 5050
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1520143747329712,
      "learning_rate": 1.959008681520763e-05,
      "loss": 0.23,
      "step": 5060
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3625941276550293,
      "learning_rate": 1.9579395287174443e-05,
      "loss": 0.397,
      "step": 5070
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0890222787857056,
      "learning_rate": 1.9568703759141257e-05,
      "loss": 0.2384,
      "step": 5080
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7929850816726685,
      "learning_rate": 1.9558012231108072e-05,
      "loss": 0.2729,
      "step": 5090
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0995712280273438,
      "learning_rate": 1.9547320703074883e-05,
      "loss": 0.2961,
      "step": 5100
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.30510812997817993,
      "learning_rate": 1.9536629175041698e-05,
      "loss": 0.2201,
      "step": 5110
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.33593085408210754,
      "learning_rate": 1.952593764700851e-05,
      "loss": 0.3298,
      "step": 5120
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2185556888580322,
      "learning_rate": 1.9515246118975323e-05,
      "loss": 0.3005,
      "step": 5130
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8405360579490662,
      "learning_rate": 1.9504554590942138e-05,
      "loss": 0.313,
      "step": 5140
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.239105463027954,
      "learning_rate": 1.9493863062908953e-05,
      "loss": 0.3481,
      "step": 5150
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1027538776397705,
      "learning_rate": 1.9483171534875767e-05,
      "loss": 0.3003,
      "step": 5160
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.477444052696228,
      "learning_rate": 1.947248000684258e-05,
      "loss": 0.3313,
      "step": 5170
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2323241233825684,
      "learning_rate": 1.9461788478809393e-05,
      "loss": 0.2613,
      "step": 5180
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1331428289413452,
      "learning_rate": 1.9451096950776208e-05,
      "loss": 0.2888,
      "step": 5190
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.6061805486679077,
      "learning_rate": 1.944040542274302e-05,
      "loss": 0.2834,
      "step": 5200
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.801047146320343,
      "learning_rate": 1.9429713894709833e-05,
      "loss": 0.2279,
      "step": 5210
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0280537605285645,
      "learning_rate": 1.9419022366676645e-05,
      "loss": 0.2705,
      "step": 5220
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.251869797706604,
      "learning_rate": 1.940833083864346e-05,
      "loss": 0.2609,
      "step": 5230
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.273989200592041,
      "learning_rate": 1.9397639310610274e-05,
      "loss": 0.3026,
      "step": 5240
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1715749502182007,
      "learning_rate": 1.9386947782577085e-05,
      "loss": 0.2579,
      "step": 5250
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.412103295326233,
      "learning_rate": 1.93762562545439e-05,
      "loss": 0.3198,
      "step": 5260
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6066886186599731,
      "learning_rate": 1.9365564726510714e-05,
      "loss": 0.301,
      "step": 5270
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4814457893371582,
      "learning_rate": 1.935487319847753e-05,
      "loss": 0.2746,
      "step": 5280
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8559428453445435,
      "learning_rate": 1.9344181670444343e-05,
      "loss": 0.2587,
      "step": 5290
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5059822201728821,
      "learning_rate": 1.9333490142411155e-05,
      "loss": 0.2714,
      "step": 5300
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.4774174988269806,
      "learning_rate": 1.932279861437797e-05,
      "loss": 0.2532,
      "step": 5310
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0156337022781372,
      "learning_rate": 1.931210708634478e-05,
      "loss": 0.3276,
      "step": 5320
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0064799785614014,
      "learning_rate": 1.9301415558311595e-05,
      "loss": 0.2171,
      "step": 5330
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9822036027908325,
      "learning_rate": 1.929072403027841e-05,
      "loss": 0.2168,
      "step": 5340
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.5433586835861206,
      "learning_rate": 1.928003250224522e-05,
      "loss": 0.3293,
      "step": 5350
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6783176064491272,
      "learning_rate": 1.9269340974212035e-05,
      "loss": 0.248,
      "step": 5360
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3322105407714844,
      "learning_rate": 1.9258649446178846e-05,
      "loss": 0.2664,
      "step": 5370
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.456961989402771,
      "learning_rate": 1.924795791814566e-05,
      "loss": 0.2665,
      "step": 5380
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.398911714553833,
      "learning_rate": 1.9237266390112476e-05,
      "loss": 0.2372,
      "step": 5390
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1563224792480469,
      "learning_rate": 1.9226574862079287e-05,
      "loss": 0.3136,
      "step": 5400
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2520121335983276,
      "learning_rate": 1.92158833340461e-05,
      "loss": 0.2951,
      "step": 5410
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1794841289520264,
      "learning_rate": 1.9205191806012916e-05,
      "loss": 0.3537,
      "step": 5420
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2364100217819214,
      "learning_rate": 1.919450027797973e-05,
      "loss": 0.3657,
      "step": 5430
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3844813108444214,
      "learning_rate": 1.9183808749946545e-05,
      "loss": 0.302,
      "step": 5440
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0487618446350098,
      "learning_rate": 1.9173117221913356e-05,
      "loss": 0.3522,
      "step": 5450
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1796090602874756,
      "learning_rate": 1.916242569388017e-05,
      "loss": 0.2753,
      "step": 5460
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2015384435653687,
      "learning_rate": 1.9151734165846986e-05,
      "loss": 0.3201,
      "step": 5470
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6176548600196838,
      "learning_rate": 1.9141042637813797e-05,
      "loss": 0.2937,
      "step": 5480
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.6207749843597412,
      "learning_rate": 1.913035110978061e-05,
      "loss": 0.3022,
      "step": 5490
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.268563151359558,
      "learning_rate": 1.9119659581747423e-05,
      "loss": 0.2753,
      "step": 5500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.990628719329834,
      "learning_rate": 1.9108968053714237e-05,
      "loss": 0.3484,
      "step": 5510
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2069787979125977,
      "learning_rate": 1.9098276525681052e-05,
      "loss": 0.3001,
      "step": 5520
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9724637269973755,
      "learning_rate": 1.9087584997647863e-05,
      "loss": 0.3823,
      "step": 5530
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8623877763748169,
      "learning_rate": 1.9076893469614678e-05,
      "loss": 0.3263,
      "step": 5540
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.5527317523956299,
      "learning_rate": 1.9066201941581492e-05,
      "loss": 0.3105,
      "step": 5550
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1793394088745117,
      "learning_rate": 1.9055510413548307e-05,
      "loss": 0.3031,
      "step": 5560
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.205196499824524,
      "learning_rate": 1.904481888551512e-05,
      "loss": 0.2733,
      "step": 5570
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3134843111038208,
      "learning_rate": 1.9034127357481933e-05,
      "loss": 0.3494,
      "step": 5580
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3968132734298706,
      "learning_rate": 1.9023435829448747e-05,
      "loss": 0.2787,
      "step": 5590
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3752007484436035,
      "learning_rate": 1.901274430141556e-05,
      "loss": 0.3555,
      "step": 5600
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0404419898986816,
      "learning_rate": 1.9002052773382373e-05,
      "loss": 0.3464,
      "step": 5610
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1277282238006592,
      "learning_rate": 1.8991361245349188e-05,
      "loss": 0.253,
      "step": 5620
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0849897861480713,
      "learning_rate": 1.8980669717316e-05,
      "loss": 0.3022,
      "step": 5630
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2659505605697632,
      "learning_rate": 1.8969978189282813e-05,
      "loss": 0.2598,
      "step": 5640
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.6837096214294434,
      "learning_rate": 1.8959286661249625e-05,
      "loss": 0.2682,
      "step": 5650
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4668673872947693,
      "learning_rate": 1.894859513321644e-05,
      "loss": 0.2911,
      "step": 5660
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4409867525100708,
      "learning_rate": 1.8937903605183254e-05,
      "loss": 0.3396,
      "step": 5670
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2861586809158325,
      "learning_rate": 1.8927212077150068e-05,
      "loss": 0.3361,
      "step": 5680
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.5334752798080444,
      "learning_rate": 1.8916520549116883e-05,
      "loss": 0.3347,
      "step": 5690
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3263671398162842,
      "learning_rate": 1.8905829021083694e-05,
      "loss": 0.3003,
      "step": 5700
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.45888063311576843,
      "learning_rate": 1.889513749305051e-05,
      "loss": 0.2678,
      "step": 5710
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0937354564666748,
      "learning_rate": 1.8884445965017323e-05,
      "loss": 0.2929,
      "step": 5720
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9240270256996155,
      "learning_rate": 1.8873754436984134e-05,
      "loss": 0.2667,
      "step": 5730
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0118671655654907,
      "learning_rate": 1.886306290895095e-05,
      "loss": 0.3543,
      "step": 5740
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1297886371612549,
      "learning_rate": 1.885237138091776e-05,
      "loss": 0.3588,
      "step": 5750
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.33853763341903687,
      "learning_rate": 1.8841679852884575e-05,
      "loss": 0.3256,
      "step": 5760
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8570641279220581,
      "learning_rate": 1.883098832485139e-05,
      "loss": 0.3186,
      "step": 5770
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6373566389083862,
      "learning_rate": 1.88202967968182e-05,
      "loss": 0.2868,
      "step": 5780
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5667852163314819,
      "learning_rate": 1.8809605268785015e-05,
      "loss": 0.2713,
      "step": 5790
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.395073413848877,
      "learning_rate": 1.8798913740751826e-05,
      "loss": 0.3762,
      "step": 5800
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.270781397819519,
      "learning_rate": 1.878822221271864e-05,
      "loss": 0.2623,
      "step": 5810
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.3256182074546814,
      "learning_rate": 1.8777530684685456e-05,
      "loss": 0.2493,
      "step": 5820
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5818234086036682,
      "learning_rate": 1.876683915665227e-05,
      "loss": 0.2978,
      "step": 5830
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8485942482948303,
      "learning_rate": 1.8756147628619085e-05,
      "loss": 0.2382,
      "step": 5840
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.054247498512268,
      "learning_rate": 1.8745456100585896e-05,
      "loss": 0.3396,
      "step": 5850
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8847238421440125,
      "learning_rate": 1.873476457255271e-05,
      "loss": 0.2916,
      "step": 5860
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.325534701347351,
      "learning_rate": 1.8724073044519525e-05,
      "loss": 0.3173,
      "step": 5870
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.42102423310279846,
      "learning_rate": 1.8713381516486336e-05,
      "loss": 0.2627,
      "step": 5880
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3662292957305908,
      "learning_rate": 1.870268998845315e-05,
      "loss": 0.3008,
      "step": 5890
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0972932577133179,
      "learning_rate": 1.8691998460419966e-05,
      "loss": 0.3063,
      "step": 5900
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.583664059638977,
      "learning_rate": 1.8681306932386777e-05,
      "loss": 0.2859,
      "step": 5910
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.359060525894165,
      "learning_rate": 1.867061540435359e-05,
      "loss": 0.2627,
      "step": 5920
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.5846332907676697,
      "learning_rate": 1.8659923876320403e-05,
      "loss": 0.2155,
      "step": 5930
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.3068549633026123,
      "learning_rate": 1.8649232348287217e-05,
      "loss": 0.2228,
      "step": 5940
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2455209493637085,
      "learning_rate": 1.8638540820254032e-05,
      "loss": 0.2628,
      "step": 5950
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2687580585479736,
      "learning_rate": 1.8627849292220846e-05,
      "loss": 0.2836,
      "step": 5960
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9072062373161316,
      "learning_rate": 1.861715776418766e-05,
      "loss": 0.2613,
      "step": 5970
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.5231381058692932,
      "learning_rate": 1.8606466236154472e-05,
      "loss": 0.2313,
      "step": 5980
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1670278310775757,
      "learning_rate": 1.8595774708121287e-05,
      "loss": 0.2173,
      "step": 5990
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3123421669006348,
      "learning_rate": 1.85850831800881e-05,
      "loss": 0.2966,
      "step": 6000
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.30361711978912354,
      "eval_runtime": 724.4673,
      "eval_samples_per_second": 3.623,
      "eval_steps_per_second": 3.623,
      "step": 6000
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.547731876373291,
      "learning_rate": 1.8574391652054912e-05,
      "loss": 0.2023,
      "step": 6010
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.5069656372070312,
      "learning_rate": 1.8563700124021727e-05,
      "loss": 0.2617,
      "step": 6020
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6579495668411255,
      "learning_rate": 1.8553008595988538e-05,
      "loss": 0.2063,
      "step": 6030
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.5191477537155151,
      "learning_rate": 1.8542317067955353e-05,
      "loss": 0.2929,
      "step": 6040
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9525880813598633,
      "learning_rate": 1.8531625539922167e-05,
      "loss": 0.2778,
      "step": 6050
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.162392497062683,
      "learning_rate": 1.852093401188898e-05,
      "loss": 0.3272,
      "step": 6060
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0215420722961426,
      "learning_rate": 1.8510242483855793e-05,
      "loss": 0.4162,
      "step": 6070
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.3435794115066528,
      "learning_rate": 1.8499550955822604e-05,
      "loss": 0.3078,
      "step": 6080
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2537834644317627,
      "learning_rate": 1.848885942778942e-05,
      "loss": 0.3465,
      "step": 6090
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6567748188972473,
      "learning_rate": 1.8478167899756234e-05,
      "loss": 0.2572,
      "step": 6100
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1628094911575317,
      "learning_rate": 1.8467476371723048e-05,
      "loss": 0.2796,
      "step": 6110
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2598330974578857,
      "learning_rate": 1.8456784843689863e-05,
      "loss": 0.2771,
      "step": 6120
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1158447265625,
      "learning_rate": 1.8446093315656674e-05,
      "loss": 0.3551,
      "step": 6130
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.6027308702468872,
      "learning_rate": 1.843540178762349e-05,
      "loss": 0.2513,
      "step": 6140
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.6102904677391052,
      "learning_rate": 1.8424710259590303e-05,
      "loss": 0.3179,
      "step": 6150
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.5674083232879639,
      "learning_rate": 1.8414018731557114e-05,
      "loss": 0.2655,
      "step": 6160
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.2638369798660278,
      "learning_rate": 1.840332720352393e-05,
      "loss": 0.2644,
      "step": 6170
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.426132082939148,
      "learning_rate": 1.839263567549074e-05,
      "loss": 0.2566,
      "step": 6180
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.4668307304382324,
      "learning_rate": 1.8381944147457555e-05,
      "loss": 0.2628,
      "step": 6190
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2920691967010498,
      "learning_rate": 1.837125261942437e-05,
      "loss": 0.1825,
      "step": 6200
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9275661110877991,
      "learning_rate": 1.836056109139118e-05,
      "loss": 0.2725,
      "step": 6210
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.5950967073440552,
      "learning_rate": 1.8349869563357995e-05,
      "loss": 0.2611,
      "step": 6220
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.00087571144104,
      "learning_rate": 1.833917803532481e-05,
      "loss": 0.3053,
      "step": 6230
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.8263115882873535,
      "learning_rate": 1.8328486507291624e-05,
      "loss": 0.3361,
      "step": 6240
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7663882374763489,
      "learning_rate": 1.831779497925844e-05,
      "loss": 0.2524,
      "step": 6250
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.7193093299865723,
      "learning_rate": 1.830710345122525e-05,
      "loss": 0.2776,
      "step": 6260
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.060486912727356,
      "learning_rate": 1.8296411923192065e-05,
      "loss": 0.3165,
      "step": 6270
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9634618759155273,
      "learning_rate": 1.8285720395158876e-05,
      "loss": 0.3013,
      "step": 6280
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.5008716583251953,
      "learning_rate": 1.827502886712569e-05,
      "loss": 0.2415,
      "step": 6290
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1367353200912476,
      "learning_rate": 1.8264337339092505e-05,
      "loss": 0.2904,
      "step": 6300
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3837653398513794,
      "learning_rate": 1.8253645811059316e-05,
      "loss": 0.2188,
      "step": 6310
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9452915787696838,
      "learning_rate": 1.824295428302613e-05,
      "loss": 0.2772,
      "step": 6320
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.327658772468567,
      "learning_rate": 1.8232262754992942e-05,
      "loss": 0.3338,
      "step": 6330
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.6797994375228882,
      "learning_rate": 1.8221571226959757e-05,
      "loss": 0.211,
      "step": 6340
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9427977800369263,
      "learning_rate": 1.821087969892657e-05,
      "loss": 0.3364,
      "step": 6350
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3146754503250122,
      "learning_rate": 1.8200188170893382e-05,
      "loss": 0.2219,
      "step": 6360
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9589576721191406,
      "learning_rate": 1.8189496642860197e-05,
      "loss": 0.2701,
      "step": 6370
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3553916215896606,
      "learning_rate": 1.817880511482701e-05,
      "loss": 0.2632,
      "step": 6380
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.903937041759491,
      "learning_rate": 1.8168113586793826e-05,
      "loss": 0.2374,
      "step": 6390
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.36268091201782227,
      "learning_rate": 1.815742205876064e-05,
      "loss": 0.1875,
      "step": 6400
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3089226484298706,
      "learning_rate": 1.8146730530727452e-05,
      "loss": 0.3461,
      "step": 6410
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.2553322315216064,
      "learning_rate": 1.8136039002694267e-05,
      "loss": 0.2269,
      "step": 6420
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.4954564571380615,
      "learning_rate": 1.812534747466108e-05,
      "loss": 0.2377,
      "step": 6430
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2919063568115234,
      "learning_rate": 1.8114655946627892e-05,
      "loss": 0.2444,
      "step": 6440
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.199558973312378,
      "learning_rate": 1.8103964418594707e-05,
      "loss": 0.2649,
      "step": 6450
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.545961618423462,
      "learning_rate": 1.8093272890561518e-05,
      "loss": 0.3749,
      "step": 6460
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.49586188793182373,
      "learning_rate": 1.8082581362528333e-05,
      "loss": 0.3019,
      "step": 6470
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.5551379919052124,
      "learning_rate": 1.8071889834495147e-05,
      "loss": 0.3127,
      "step": 6480
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.5108318328857422,
      "learning_rate": 1.806119830646196e-05,
      "loss": 0.2323,
      "step": 6490
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5721118450164795,
      "learning_rate": 1.8050506778428773e-05,
      "loss": 0.2988,
      "step": 6500
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.274925947189331,
      "learning_rate": 1.8039815250395588e-05,
      "loss": 0.3265,
      "step": 6510
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.36917898058891296,
      "learning_rate": 1.8029123722362402e-05,
      "loss": 0.2633,
      "step": 6520
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6755081415176392,
      "learning_rate": 1.8018432194329217e-05,
      "loss": 0.2968,
      "step": 6530
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9469150304794312,
      "learning_rate": 1.8007740666296028e-05,
      "loss": 0.2826,
      "step": 6540
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.063273310661316,
      "learning_rate": 1.7997049138262843e-05,
      "loss": 0.3308,
      "step": 6550
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8617215752601624,
      "learning_rate": 1.7986357610229654e-05,
      "loss": 0.2729,
      "step": 6560
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6570873260498047,
      "learning_rate": 1.797566608219647e-05,
      "loss": 0.3994,
      "step": 6570
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.3096872568130493,
      "learning_rate": 1.7964974554163283e-05,
      "loss": 0.3449,
      "step": 6580
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2981995344161987,
      "learning_rate": 1.7954283026130094e-05,
      "loss": 0.2676,
      "step": 6590
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.20785653591156,
      "learning_rate": 1.794359149809691e-05,
      "loss": 0.2677,
      "step": 6600
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.3730170726776123,
      "learning_rate": 1.793289997006372e-05,
      "loss": 0.2412,
      "step": 6610
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1406387090682983,
      "learning_rate": 1.7922208442030535e-05,
      "loss": 0.2962,
      "step": 6620
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.043560266494751,
      "learning_rate": 1.791151691399735e-05,
      "loss": 0.3205,
      "step": 6630
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6377795934677124,
      "learning_rate": 1.7900825385964164e-05,
      "loss": 0.3175,
      "step": 6640
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.6420084238052368,
      "learning_rate": 1.789013385793098e-05,
      "loss": 0.3202,
      "step": 6650
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.146934986114502,
      "learning_rate": 1.787944232989779e-05,
      "loss": 0.3711,
      "step": 6660
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2342027425765991,
      "learning_rate": 1.7868750801864604e-05,
      "loss": 0.267,
      "step": 6670
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.072708249092102,
      "learning_rate": 1.785805927383142e-05,
      "loss": 0.3484,
      "step": 6680
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.6595559120178223,
      "learning_rate": 1.784736774579823e-05,
      "loss": 0.2182,
      "step": 6690
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1452486515045166,
      "learning_rate": 1.7836676217765045e-05,
      "loss": 0.2632,
      "step": 6700
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.643386960029602,
      "learning_rate": 1.7825984689731856e-05,
      "loss": 0.3371,
      "step": 6710
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.002915859222412,
      "learning_rate": 1.781529316169867e-05,
      "loss": 0.2853,
      "step": 6720
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.38895583152771,
      "learning_rate": 1.7804601633665485e-05,
      "loss": 0.3054,
      "step": 6730
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8179996609687805,
      "learning_rate": 1.7793910105632296e-05,
      "loss": 0.3033,
      "step": 6740
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.7337080240249634,
      "learning_rate": 1.778321857759911e-05,
      "loss": 0.3237,
      "step": 6750
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0087246894836426,
      "learning_rate": 1.7772527049565922e-05,
      "loss": 0.2932,
      "step": 6760
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8688409924507141,
      "learning_rate": 1.7761835521532737e-05,
      "loss": 0.3298,
      "step": 6770
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.746558427810669,
      "learning_rate": 1.775114399349955e-05,
      "loss": 0.2532,
      "step": 6780
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.46025651693344116,
      "learning_rate": 1.7740452465466366e-05,
      "loss": 0.2409,
      "step": 6790
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3913501501083374,
      "learning_rate": 1.772976093743318e-05,
      "loss": 0.3009,
      "step": 6800
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4870092868804932,
      "learning_rate": 1.771906940939999e-05,
      "loss": 0.3241,
      "step": 6810
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2205857038497925,
      "learning_rate": 1.7708377881366806e-05,
      "loss": 0.3075,
      "step": 6820
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9333316087722778,
      "learning_rate": 1.769768635333362e-05,
      "loss": 0.3286,
      "step": 6830
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.950799822807312,
      "learning_rate": 1.7686994825300432e-05,
      "loss": 0.2622,
      "step": 6840
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.4193669557571411,
      "learning_rate": 1.7676303297267247e-05,
      "loss": 0.2855,
      "step": 6850
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2942736148834229,
      "learning_rate": 1.766561176923406e-05,
      "loss": 0.2892,
      "step": 6860
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3410975933074951,
      "learning_rate": 1.7654920241200872e-05,
      "loss": 0.3603,
      "step": 6870
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0759167671203613,
      "learning_rate": 1.7644228713167687e-05,
      "loss": 0.1859,
      "step": 6880
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.132138967514038,
      "learning_rate": 1.7633537185134498e-05,
      "loss": 0.2558,
      "step": 6890
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.111768126487732,
      "learning_rate": 1.7622845657101313e-05,
      "loss": 0.3066,
      "step": 6900
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2932262420654297,
      "learning_rate": 1.7612154129068127e-05,
      "loss": 0.271,
      "step": 6910
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5524609088897705,
      "learning_rate": 1.7601462601034942e-05,
      "loss": 0.3795,
      "step": 6920
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.6266406774520874,
      "learning_rate": 1.7590771073001757e-05,
      "loss": 0.3895,
      "step": 6930
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5730242133140564,
      "learning_rate": 1.7580079544968568e-05,
      "loss": 0.2152,
      "step": 6940
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.994848906993866,
      "learning_rate": 1.7569388016935382e-05,
      "loss": 0.2856,
      "step": 6950
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3912041187286377,
      "learning_rate": 1.7558696488902197e-05,
      "loss": 0.2706,
      "step": 6960
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7986034750938416,
      "learning_rate": 1.7548004960869008e-05,
      "loss": 0.2561,
      "step": 6970
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8805141448974609,
      "learning_rate": 1.7537313432835823e-05,
      "loss": 0.2812,
      "step": 6980
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.6522420644760132,
      "learning_rate": 1.7526621904802634e-05,
      "loss": 0.356,
      "step": 6990
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5958689451217651,
      "learning_rate": 1.751593037676945e-05,
      "loss": 0.3175,
      "step": 7000
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.2997220456600189,
      "eval_runtime": 723.8797,
      "eval_samples_per_second": 3.626,
      "eval_steps_per_second": 3.626,
      "step": 7000
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.4972519874572754,
      "learning_rate": 1.7505238848736263e-05,
      "loss": 0.1995,
      "step": 7010
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5066018104553223,
      "learning_rate": 1.7494547320703074e-05,
      "loss": 0.2345,
      "step": 7020
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.5124803781509399,
      "learning_rate": 1.748385579266989e-05,
      "loss": 0.2769,
      "step": 7030
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.122707486152649,
      "learning_rate": 1.74731642646367e-05,
      "loss": 0.339,
      "step": 7040
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.4926204681396484,
      "learning_rate": 1.7462472736603515e-05,
      "loss": 0.3421,
      "step": 7050
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1637780666351318,
      "learning_rate": 1.745178120857033e-05,
      "loss": 0.2855,
      "step": 7060
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.389376163482666,
      "learning_rate": 1.7441089680537144e-05,
      "loss": 0.2631,
      "step": 7070
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.28503096103668213,
      "learning_rate": 1.743039815250396e-05,
      "loss": 0.1997,
      "step": 7080
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.7736239433288574,
      "learning_rate": 1.741970662447077e-05,
      "loss": 0.2662,
      "step": 7090
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1267610788345337,
      "learning_rate": 1.7409015096437584e-05,
      "loss": 0.3206,
      "step": 7100
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.198934555053711,
      "learning_rate": 1.73983235684044e-05,
      "loss": 0.2958,
      "step": 7110
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.5472570657730103,
      "learning_rate": 1.738763204037121e-05,
      "loss": 0.3233,
      "step": 7120
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9211782813072205,
      "learning_rate": 1.7376940512338025e-05,
      "loss": 0.2891,
      "step": 7130
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2563238143920898,
      "learning_rate": 1.7366248984304836e-05,
      "loss": 0.3303,
      "step": 7140
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2570931911468506,
      "learning_rate": 1.735555745627165e-05,
      "loss": 0.2448,
      "step": 7150
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.5232224464416504,
      "learning_rate": 1.7344865928238465e-05,
      "loss": 0.1833,
      "step": 7160
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2794901132583618,
      "learning_rate": 1.7334174400205276e-05,
      "loss": 0.3228,
      "step": 7170
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.6884288787841797,
      "learning_rate": 1.732348287217209e-05,
      "loss": 0.2134,
      "step": 7180
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3667330741882324,
      "learning_rate": 1.7312791344138905e-05,
      "loss": 0.3787,
      "step": 7190
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2796748876571655,
      "learning_rate": 1.730209981610572e-05,
      "loss": 0.2589,
      "step": 7200
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4310678243637085,
      "learning_rate": 1.7291408288072535e-05,
      "loss": 0.2709,
      "step": 7210
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.593506395816803,
      "learning_rate": 1.7280716760039346e-05,
      "loss": 0.2481,
      "step": 7220
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0464831590652466,
      "learning_rate": 1.727002523200616e-05,
      "loss": 0.2642,
      "step": 7230
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3801987171173096,
      "learning_rate": 1.725933370397297e-05,
      "loss": 0.3041,
      "step": 7240
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.5455759763717651,
      "learning_rate": 1.7248642175939786e-05,
      "loss": 0.2908,
      "step": 7250
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.129467248916626,
      "learning_rate": 1.72379506479066e-05,
      "loss": 0.2814,
      "step": 7260
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2242250442504883,
      "learning_rate": 1.7227259119873412e-05,
      "loss": 0.2814,
      "step": 7270
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3978253602981567,
      "learning_rate": 1.7216567591840227e-05,
      "loss": 0.3629,
      "step": 7280
    },
    {
      "epoch": 0.31,
      "grad_norm": 2.1869256496429443,
      "learning_rate": 1.7205876063807038e-05,
      "loss": 0.3115,
      "step": 7290
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7740225195884705,
      "learning_rate": 1.7195184535773852e-05,
      "loss": 0.2689,
      "step": 7300
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3868529796600342,
      "learning_rate": 1.7184493007740667e-05,
      "loss": 0.2041,
      "step": 7310
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3765816688537598,
      "learning_rate": 1.7173801479707478e-05,
      "loss": 0.3187,
      "step": 7320
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4401699304580688,
      "learning_rate": 1.7163109951674293e-05,
      "loss": 0.3042,
      "step": 7330
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1115959882736206,
      "learning_rate": 1.7152418423641107e-05,
      "loss": 0.2697,
      "step": 7340
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.3109943866729736,
      "learning_rate": 1.7141726895607922e-05,
      "loss": 0.2528,
      "step": 7350
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1640123128890991,
      "learning_rate": 1.7131035367574736e-05,
      "loss": 0.3746,
      "step": 7360
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.965267539024353,
      "learning_rate": 1.7120343839541548e-05,
      "loss": 0.2754,
      "step": 7370
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0142693519592285,
      "learning_rate": 1.7109652311508362e-05,
      "loss": 0.2681,
      "step": 7380
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0092682838439941,
      "learning_rate": 1.7098960783475177e-05,
      "loss": 0.3292,
      "step": 7390
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.334632396697998,
      "learning_rate": 1.7088269255441988e-05,
      "loss": 0.2817,
      "step": 7400
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1844509840011597,
      "learning_rate": 1.7077577727408803e-05,
      "loss": 0.3351,
      "step": 7410
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9489086866378784,
      "learning_rate": 1.7066886199375614e-05,
      "loss": 0.3674,
      "step": 7420
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6460351347923279,
      "learning_rate": 1.705619467134243e-05,
      "loss": 0.284,
      "step": 7430
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.8620373010635376,
      "learning_rate": 1.7045503143309243e-05,
      "loss": 0.2562,
      "step": 7440
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5187571048736572,
      "learning_rate": 1.7034811615276054e-05,
      "loss": 0.2361,
      "step": 7450
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.4514422416687012,
      "learning_rate": 1.702412008724287e-05,
      "loss": 0.311,
      "step": 7460
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.360364317893982,
      "learning_rate": 1.7013428559209683e-05,
      "loss": 0.3482,
      "step": 7470
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7326737642288208,
      "learning_rate": 1.7002737031176498e-05,
      "loss": 0.2966,
      "step": 7480
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1826750040054321,
      "learning_rate": 1.6992045503143313e-05,
      "loss": 0.3692,
      "step": 7490
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.7465810179710388,
      "learning_rate": 1.6981353975110124e-05,
      "loss": 0.2163,
      "step": 7500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3117215633392334,
      "learning_rate": 1.697066244707694e-05,
      "loss": 0.2935,
      "step": 7510
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.6159420013427734,
      "learning_rate": 1.695997091904375e-05,
      "loss": 0.3475,
      "step": 7520
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8578824400901794,
      "learning_rate": 1.6949279391010564e-05,
      "loss": 0.236,
      "step": 7530
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.314988613128662,
      "learning_rate": 1.693858786297738e-05,
      "loss": 0.4005,
      "step": 7540
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.745547890663147,
      "learning_rate": 1.692789633494419e-05,
      "loss": 0.3014,
      "step": 7550
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0908607244491577,
      "learning_rate": 1.6917204806911005e-05,
      "loss": 0.2723,
      "step": 7560
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5514394044876099,
      "learning_rate": 1.6906513278877816e-05,
      "loss": 0.25,
      "step": 7570
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.3147343397140503,
      "learning_rate": 1.689582175084463e-05,
      "loss": 0.2643,
      "step": 7580
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.328730583190918,
      "learning_rate": 1.6885130222811445e-05,
      "loss": 0.3559,
      "step": 7590
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.286761999130249,
      "learning_rate": 1.687443869477826e-05,
      "loss": 0.2355,
      "step": 7600
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4192743301391602,
      "learning_rate": 1.6863747166745074e-05,
      "loss": 0.223,
      "step": 7610
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4473494291305542,
      "learning_rate": 1.6853055638711885e-05,
      "loss": 0.3227,
      "step": 7620
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.5342003107070923,
      "learning_rate": 1.68423641106787e-05,
      "loss": 0.3029,
      "step": 7630
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.19075356423854828,
      "learning_rate": 1.6831672582645514e-05,
      "loss": 0.2306,
      "step": 7640
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6505617499351501,
      "learning_rate": 1.6820981054612326e-05,
      "loss": 0.329,
      "step": 7650
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0592857599258423,
      "learning_rate": 1.681028952657914e-05,
      "loss": 0.3525,
      "step": 7660
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4337810277938843,
      "learning_rate": 1.679959799854595e-05,
      "loss": 0.2077,
      "step": 7670
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.6717130541801453,
      "learning_rate": 1.6788906470512766e-05,
      "loss": 0.3013,
      "step": 7680
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.411116600036621,
      "learning_rate": 1.677821494247958e-05,
      "loss": 0.2913,
      "step": 7690
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.5340572595596313,
      "learning_rate": 1.6767523414446392e-05,
      "loss": 0.2452,
      "step": 7700
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3017696142196655,
      "learning_rate": 1.6756831886413206e-05,
      "loss": 0.2889,
      "step": 7710
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3901638984680176,
      "learning_rate": 1.6746140358380018e-05,
      "loss": 0.3031,
      "step": 7720
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.5505145192146301,
      "learning_rate": 1.6735448830346832e-05,
      "loss": 0.2894,
      "step": 7730
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0376781225204468,
      "learning_rate": 1.6724757302313647e-05,
      "loss": 0.2598,
      "step": 7740
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.5427649021148682,
      "learning_rate": 1.671406577428046e-05,
      "loss": 0.2362,
      "step": 7750
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8836657404899597,
      "learning_rate": 1.6703374246247276e-05,
      "loss": 0.2493,
      "step": 7760
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1751455068588257,
      "learning_rate": 1.6692682718214087e-05,
      "loss": 0.2914,
      "step": 7770
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.8422716856002808,
      "learning_rate": 1.6681991190180902e-05,
      "loss": 0.2156,
      "step": 7780
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3848544359207153,
      "learning_rate": 1.6671299662147716e-05,
      "loss": 0.3506,
      "step": 7790
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.08953595161438,
      "learning_rate": 1.6660608134114528e-05,
      "loss": 0.3035,
      "step": 7800
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1721199750900269,
      "learning_rate": 1.6649916606081342e-05,
      "loss": 0.316,
      "step": 7810
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2256842851638794,
      "learning_rate": 1.6639225078048157e-05,
      "loss": 0.3358,
      "step": 7820
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.7058022022247314,
      "learning_rate": 1.6628533550014968e-05,
      "loss": 0.2361,
      "step": 7830
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2324358224868774,
      "learning_rate": 1.6617842021981783e-05,
      "loss": 0.2872,
      "step": 7840
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2439178228378296,
      "learning_rate": 1.6607150493948594e-05,
      "loss": 0.2045,
      "step": 7850
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.163204550743103,
      "learning_rate": 1.659645896591541e-05,
      "loss": 0.3052,
      "step": 7860
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.441463828086853,
      "learning_rate": 1.6585767437882223e-05,
      "loss": 0.2734,
      "step": 7870
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1201926469802856,
      "learning_rate": 1.6575075909849038e-05,
      "loss": 0.3267,
      "step": 7880
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5997610688209534,
      "learning_rate": 1.6564384381815852e-05,
      "loss": 0.326,
      "step": 7890
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.5289857983589172,
      "learning_rate": 1.6553692853782663e-05,
      "loss": 0.2579,
      "step": 7900
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2217735052108765,
      "learning_rate": 1.6543001325749478e-05,
      "loss": 0.2064,
      "step": 7910
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.33964985609054565,
      "learning_rate": 1.6532309797716293e-05,
      "loss": 0.2716,
      "step": 7920
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3022332191467285,
      "learning_rate": 1.6521618269683104e-05,
      "loss": 0.3241,
      "step": 7930
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6940826177597046,
      "learning_rate": 1.6510926741649918e-05,
      "loss": 0.3383,
      "step": 7940
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.6339696049690247,
      "learning_rate": 1.650023521361673e-05,
      "loss": 0.1541,
      "step": 7950
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.169640302658081,
      "learning_rate": 1.6489543685583544e-05,
      "loss": 0.3098,
      "step": 7960
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.4935110807418823,
      "learning_rate": 1.647885215755036e-05,
      "loss": 0.2033,
      "step": 7970
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9092743992805481,
      "learning_rate": 1.646816062951717e-05,
      "loss": 0.3111,
      "step": 7980
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.256148099899292,
      "learning_rate": 1.6457469101483984e-05,
      "loss": 0.3366,
      "step": 7990
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.48976951837539673,
      "learning_rate": 1.6446777573450796e-05,
      "loss": 0.2745,
      "step": 8000
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.29697099328041077,
      "eval_runtime": 724.9677,
      "eval_samples_per_second": 3.621,
      "eval_steps_per_second": 3.621,
      "step": 8000
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2660868167877197,
      "learning_rate": 1.643608604541761e-05,
      "loss": 0.3895,
      "step": 8010
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1276386976242065,
      "learning_rate": 1.6425394517384425e-05,
      "loss": 0.3032,
      "step": 8020
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.600878119468689,
      "learning_rate": 1.641470298935124e-05,
      "loss": 0.3556,
      "step": 8030
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.925327479839325,
      "learning_rate": 1.6404011461318054e-05,
      "loss": 0.2233,
      "step": 8040
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3741735219955444,
      "learning_rate": 1.6393319933284865e-05,
      "loss": 0.3422,
      "step": 8050
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.5325759649276733,
      "learning_rate": 1.638262840525168e-05,
      "loss": 0.2476,
      "step": 8060
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.4732736349105835,
      "learning_rate": 1.6371936877218494e-05,
      "loss": 0.2839,
      "step": 8070
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.4162235260009766,
      "learning_rate": 1.6361245349185306e-05,
      "loss": 0.2894,
      "step": 8080
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1100994348526,
      "learning_rate": 1.635055382115212e-05,
      "loss": 0.3045,
      "step": 8090
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0908098220825195,
      "learning_rate": 1.633986229311893e-05,
      "loss": 0.1987,
      "step": 8100
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.718190610408783,
      "learning_rate": 1.6329170765085746e-05,
      "loss": 0.2054,
      "step": 8110
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9196149706840515,
      "learning_rate": 1.631847923705256e-05,
      "loss": 0.3139,
      "step": 8120
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4082086682319641,
      "learning_rate": 1.6307787709019372e-05,
      "loss": 0.2013,
      "step": 8130
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5711147785186768,
      "learning_rate": 1.6297096180986186e-05,
      "loss": 0.2673,
      "step": 8140
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.557804822921753,
      "learning_rate": 1.6286404652953e-05,
      "loss": 0.2959,
      "step": 8150
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9937204122543335,
      "learning_rate": 1.6275713124919816e-05,
      "loss": 0.2772,
      "step": 8160
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3114985227584839,
      "learning_rate": 1.626502159688663e-05,
      "loss": 0.2455,
      "step": 8170
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0089799165725708,
      "learning_rate": 1.625433006885344e-05,
      "loss": 0.2895,
      "step": 8180
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.6083831787109375,
      "learning_rate": 1.6243638540820256e-05,
      "loss": 0.2221,
      "step": 8190
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.423740267753601,
      "learning_rate": 1.6232947012787067e-05,
      "loss": 0.3302,
      "step": 8200
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1989127397537231,
      "learning_rate": 1.6222255484753882e-05,
      "loss": 0.2881,
      "step": 8210
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.505697250366211,
      "learning_rate": 1.6211563956720696e-05,
      "loss": 0.3151,
      "step": 8220
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.430158019065857,
      "learning_rate": 1.6200872428687508e-05,
      "loss": 0.3727,
      "step": 8230
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.5990676879882812,
      "learning_rate": 1.6190180900654322e-05,
      "loss": 0.2395,
      "step": 8240
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.4388302564620972,
      "learning_rate": 1.6179489372621133e-05,
      "loss": 0.231,
      "step": 8250
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3251324892044067,
      "learning_rate": 1.6168797844587948e-05,
      "loss": 0.2308,
      "step": 8260
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.579113245010376,
      "learning_rate": 1.6158106316554763e-05,
      "loss": 0.264,
      "step": 8270
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.4485969543457031,
      "learning_rate": 1.6147414788521577e-05,
      "loss": 0.3602,
      "step": 8280
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.049925446510315,
      "learning_rate": 1.613672326048839e-05,
      "loss": 0.2788,
      "step": 8290
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1734927892684937,
      "learning_rate": 1.6126031732455206e-05,
      "loss": 0.3088,
      "step": 8300
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3248703479766846,
      "learning_rate": 1.6115340204422017e-05,
      "loss": 0.2608,
      "step": 8310
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.4986258745193481,
      "learning_rate": 1.6104648676388832e-05,
      "loss": 0.272,
      "step": 8320
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5751433372497559,
      "learning_rate": 1.6093957148355643e-05,
      "loss": 0.2745,
      "step": 8330
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41133999824523926,
      "learning_rate": 1.6083265620322458e-05,
      "loss": 0.303,
      "step": 8340
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3154222965240479,
      "learning_rate": 1.6072574092289272e-05,
      "loss": 0.2565,
      "step": 8350
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.079390048980713,
      "learning_rate": 1.6061882564256084e-05,
      "loss": 0.4263,
      "step": 8360
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7495001554489136,
      "learning_rate": 1.6051191036222898e-05,
      "loss": 0.2293,
      "step": 8370
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8903822302818298,
      "learning_rate": 1.604049950818971e-05,
      "loss": 0.1908,
      "step": 8380
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.341482549905777,
      "learning_rate": 1.6029807980156524e-05,
      "loss": 0.1891,
      "step": 8390
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3410049676895142,
      "learning_rate": 1.601911645212334e-05,
      "loss": 0.297,
      "step": 8400
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.071378469467163,
      "learning_rate": 1.600842492409015e-05,
      "loss": 0.2819,
      "step": 8410
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2064718008041382,
      "learning_rate": 1.5997733396056964e-05,
      "loss": 0.2714,
      "step": 8420
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1628000736236572,
      "learning_rate": 1.598704186802378e-05,
      "loss": 0.2537,
      "step": 8430
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1280242204666138,
      "learning_rate": 1.5976350339990594e-05,
      "loss": 0.3365,
      "step": 8440
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.335512399673462,
      "learning_rate": 1.5965658811957408e-05,
      "loss": 0.2878,
      "step": 8450
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.6485549211502075,
      "learning_rate": 1.595496728392422e-05,
      "loss": 0.259,
      "step": 8460
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.8183355331420898,
      "learning_rate": 1.5944275755891034e-05,
      "loss": 0.2409,
      "step": 8470
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2742458581924438,
      "learning_rate": 1.5933584227857845e-05,
      "loss": 0.289,
      "step": 8480
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.5766724348068237,
      "learning_rate": 1.592289269982466e-05,
      "loss": 0.2609,
      "step": 8490
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.6179726123809814,
      "learning_rate": 1.5912201171791474e-05,
      "loss": 0.3574,
      "step": 8500
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.4084036350250244,
      "learning_rate": 1.5901509643758286e-05,
      "loss": 0.3276,
      "step": 8510
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3256251811981201,
      "learning_rate": 1.58908181157251e-05,
      "loss": 0.2538,
      "step": 8520
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.5279645919799805,
      "learning_rate": 1.588012658769191e-05,
      "loss": 0.2971,
      "step": 8530
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.5395667552947998,
      "learning_rate": 1.5869435059658726e-05,
      "loss": 0.1957,
      "step": 8540
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0052669048309326,
      "learning_rate": 1.585874353162554e-05,
      "loss": 0.2386,
      "step": 8550
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.4770159721374512,
      "learning_rate": 1.5848052003592355e-05,
      "loss": 0.315,
      "step": 8560
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1264313459396362,
      "learning_rate": 1.583736047555917e-05,
      "loss": 0.2522,
      "step": 8570
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.5729244351387024,
      "learning_rate": 1.582666894752598e-05,
      "loss": 0.2532,
      "step": 8580
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.3553717136383057,
      "learning_rate": 1.5815977419492796e-05,
      "loss": 0.2394,
      "step": 8590
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1498407125473022,
      "learning_rate": 1.580528589145961e-05,
      "loss": 0.2347,
      "step": 8600
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6206165552139282,
      "learning_rate": 1.579459436342642e-05,
      "loss": 0.2964,
      "step": 8610
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.8020766973495483,
      "learning_rate": 1.5783902835393236e-05,
      "loss": 0.2966,
      "step": 8620
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.376586675643921,
      "learning_rate": 1.5773211307360047e-05,
      "loss": 0.2483,
      "step": 8630
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14101998507976532,
      "learning_rate": 1.576251977932686e-05,
      "loss": 0.2715,
      "step": 8640
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.289402723312378,
      "learning_rate": 1.5751828251293676e-05,
      "loss": 0.3159,
      "step": 8650
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8032253980636597,
      "learning_rate": 1.5741136723260487e-05,
      "loss": 0.2424,
      "step": 8660
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2115434408187866,
      "learning_rate": 1.5730445195227302e-05,
      "loss": 0.2243,
      "step": 8670
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6581059694290161,
      "learning_rate": 1.5719753667194113e-05,
      "loss": 0.3348,
      "step": 8680
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.4182924032211304,
      "learning_rate": 1.5709062139160928e-05,
      "loss": 0.3138,
      "step": 8690
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.4853995442390442,
      "learning_rate": 1.5698370611127742e-05,
      "loss": 0.2176,
      "step": 8700
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1197227239608765,
      "learning_rate": 1.5687679083094557e-05,
      "loss": 0.2836,
      "step": 8710
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6049401164054871,
      "learning_rate": 1.567698755506137e-05,
      "loss": 0.2729,
      "step": 8720
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.435071349143982,
      "learning_rate": 1.5666296027028186e-05,
      "loss": 0.2197,
      "step": 8730
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9711297750473022,
      "learning_rate": 1.5655604498994997e-05,
      "loss": 0.2691,
      "step": 8740
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.6840880513191223,
      "learning_rate": 1.5644912970961812e-05,
      "loss": 0.3162,
      "step": 8750
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.4046601057052612,
      "learning_rate": 1.5634221442928623e-05,
      "loss": 0.3281,
      "step": 8760
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3460251092910767,
      "learning_rate": 1.5623529914895438e-05,
      "loss": 0.2746,
      "step": 8770
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0100842714309692,
      "learning_rate": 1.5612838386862252e-05,
      "loss": 0.2267,
      "step": 8780
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2948020696640015,
      "learning_rate": 1.5602146858829064e-05,
      "loss": 0.2884,
      "step": 8790
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.5619585514068604,
      "learning_rate": 1.5591455330795878e-05,
      "loss": 0.3257,
      "step": 8800
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0787180662155151,
      "learning_rate": 1.558076380276269e-05,
      "loss": 0.2558,
      "step": 8810
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3807218074798584,
      "learning_rate": 1.5570072274729504e-05,
      "loss": 0.2361,
      "step": 8820
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3062504529953003,
      "learning_rate": 1.555938074669632e-05,
      "loss": 0.294,
      "step": 8830
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.146668553352356,
      "learning_rate": 1.5548689218663133e-05,
      "loss": 0.2281,
      "step": 8840
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3291873931884766,
      "learning_rate": 1.5537997690629948e-05,
      "loss": 0.306,
      "step": 8850
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4559414386749268,
      "learning_rate": 1.552730616259676e-05,
      "loss": 0.248,
      "step": 8860
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.47034752368927,
      "learning_rate": 1.5516614634563574e-05,
      "loss": 0.3097,
      "step": 8870
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6997694969177246,
      "learning_rate": 1.5505923106530388e-05,
      "loss": 0.3064,
      "step": 8880
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4148691892623901,
      "learning_rate": 1.54952315784972e-05,
      "loss": 0.2126,
      "step": 8890
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0727328062057495,
      "learning_rate": 1.5484540050464014e-05,
      "loss": 0.2122,
      "step": 8900
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4231462478637695,
      "learning_rate": 1.5473848522430825e-05,
      "loss": 0.2167,
      "step": 8910
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2990878820419312,
      "learning_rate": 1.546315699439764e-05,
      "loss": 0.2399,
      "step": 8920
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4959032535552979,
      "learning_rate": 1.5452465466364454e-05,
      "loss": 0.337,
      "step": 8930
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.5070318579673767,
      "learning_rate": 1.5441773938331265e-05,
      "loss": 0.3054,
      "step": 8940
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6422793865203857,
      "learning_rate": 1.543108241029808e-05,
      "loss": 0.3437,
      "step": 8950
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2803994417190552,
      "learning_rate": 1.542039088226489e-05,
      "loss": 0.2896,
      "step": 8960
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8756024837493896,
      "learning_rate": 1.5409699354231706e-05,
      "loss": 0.2862,
      "step": 8970
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.6960049867630005,
      "learning_rate": 1.539900782619852e-05,
      "loss": 0.2929,
      "step": 8980
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.632501244544983,
      "learning_rate": 1.5388316298165335e-05,
      "loss": 0.2223,
      "step": 8990
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.143568754196167,
      "learning_rate": 1.537762477013215e-05,
      "loss": 0.2364,
      "step": 9000
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.29451650381088257,
      "eval_runtime": 724.4918,
      "eval_samples_per_second": 3.623,
      "eval_steps_per_second": 3.623,
      "step": 9000
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2604769468307495,
      "learning_rate": 1.536693324209896e-05,
      "loss": 0.2713,
      "step": 9010
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3442851305007935,
      "learning_rate": 1.5356241714065775e-05,
      "loss": 0.2973,
      "step": 9020
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3075400590896606,
      "learning_rate": 1.534555018603259e-05,
      "loss": 0.312,
      "step": 9030
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9545835256576538,
      "learning_rate": 1.53348586579994e-05,
      "loss": 0.2736,
      "step": 9040
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.513893485069275,
      "learning_rate": 1.5324167129966216e-05,
      "loss": 0.3587,
      "step": 9050
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.5518587827682495,
      "learning_rate": 1.5313475601933027e-05,
      "loss": 0.2368,
      "step": 9060
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1506980657577515,
      "learning_rate": 1.530278407389984e-05,
      "loss": 0.3305,
      "step": 9070
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.301917165517807,
      "learning_rate": 1.5292092545866656e-05,
      "loss": 0.2563,
      "step": 9080
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.9193731546401978,
      "learning_rate": 1.5281401017833467e-05,
      "loss": 0.2974,
      "step": 9090
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.33786001801490784,
      "learning_rate": 1.5270709489800282e-05,
      "loss": 0.2383,
      "step": 9100
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2806650400161743,
      "learning_rate": 1.5260017961767097e-05,
      "loss": 0.3654,
      "step": 9110
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.8010439276695251,
      "learning_rate": 1.524932643373391e-05,
      "loss": 0.1573,
      "step": 9120
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.38508766889572144,
      "learning_rate": 1.5238634905700724e-05,
      "loss": 0.2119,
      "step": 9130
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.3397412300109863,
      "learning_rate": 1.5227943377667537e-05,
      "loss": 0.2416,
      "step": 9140
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.4483121633529663,
      "learning_rate": 1.5217251849634352e-05,
      "loss": 0.3319,
      "step": 9150
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.487582802772522,
      "learning_rate": 1.5206560321601163e-05,
      "loss": 0.3083,
      "step": 9160
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1267998218536377,
      "learning_rate": 1.5195868793567977e-05,
      "loss": 0.322,
      "step": 9170
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.33430472016334534,
      "learning_rate": 1.5185177265534792e-05,
      "loss": 0.2672,
      "step": 9180
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.519127368927002,
      "learning_rate": 1.5174485737501603e-05,
      "loss": 0.2866,
      "step": 9190
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.3801202178001404,
      "learning_rate": 1.5163794209468418e-05,
      "loss": 0.212,
      "step": 9200
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9590790271759033,
      "learning_rate": 1.5153102681435232e-05,
      "loss": 0.2744,
      "step": 9210
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9154264330863953,
      "learning_rate": 1.5142411153402045e-05,
      "loss": 0.3143,
      "step": 9220
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0593945980072021,
      "learning_rate": 1.513171962536886e-05,
      "loss": 0.3197,
      "step": 9230
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.326907992362976,
      "learning_rate": 1.5121028097335671e-05,
      "loss": 0.2583,
      "step": 9240
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1372987031936646,
      "learning_rate": 1.5110336569302486e-05,
      "loss": 0.3976,
      "step": 9250
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.103493571281433,
      "learning_rate": 1.50996450412693e-05,
      "loss": 0.3515,
      "step": 9260
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.488175868988037,
      "learning_rate": 1.5088953513236111e-05,
      "loss": 0.2541,
      "step": 9270
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.129227638244629,
      "learning_rate": 1.5078261985202926e-05,
      "loss": 0.2665,
      "step": 9280
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.25100481510162354,
      "learning_rate": 1.5067570457169739e-05,
      "loss": 0.2921,
      "step": 9290
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9284554123878479,
      "learning_rate": 1.5056878929136553e-05,
      "loss": 0.2039,
      "step": 9300
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1141681671142578,
      "learning_rate": 1.5046187401103368e-05,
      "loss": 0.2677,
      "step": 9310
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.318170428276062,
      "learning_rate": 1.503549587307018e-05,
      "loss": 0.3295,
      "step": 9320
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.755638599395752,
      "learning_rate": 1.5024804345036994e-05,
      "loss": 0.2315,
      "step": 9330
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5140626430511475,
      "learning_rate": 1.5014112817003805e-05,
      "loss": 0.2877,
      "step": 9340
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5192389488220215,
      "learning_rate": 1.5003421288970621e-05,
      "loss": 0.3048,
      "step": 9350
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.6794958114624023,
      "learning_rate": 1.4992729760937436e-05,
      "loss": 0.2534,
      "step": 9360
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1410527229309082,
      "learning_rate": 1.4982038232904247e-05,
      "loss": 0.221,
      "step": 9370
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.434995412826538,
      "learning_rate": 1.4971346704871062e-05,
      "loss": 0.2725,
      "step": 9380
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.6454155445098877,
      "learning_rate": 1.4960655176837873e-05,
      "loss": 0.3178,
      "step": 9390
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3469229936599731,
      "learning_rate": 1.4949963648804688e-05,
      "loss": 0.2983,
      "step": 9400
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2066999673843384,
      "learning_rate": 1.4939272120771502e-05,
      "loss": 0.3064,
      "step": 9410
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9847717881202698,
      "learning_rate": 1.4928580592738315e-05,
      "loss": 0.2867,
      "step": 9420
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.4257533550262451,
      "learning_rate": 1.491788906470513e-05,
      "loss": 0.3746,
      "step": 9430
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7419407367706299,
      "learning_rate": 1.490719753667194e-05,
      "loss": 0.2719,
      "step": 9440
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2427279949188232,
      "learning_rate": 1.4896506008638755e-05,
      "loss": 0.2749,
      "step": 9450
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.414829969406128,
      "learning_rate": 1.488581448060557e-05,
      "loss": 0.264,
      "step": 9460
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.5919959545135498,
      "learning_rate": 1.4875122952572381e-05,
      "loss": 0.299,
      "step": 9470
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.855358362197876,
      "learning_rate": 1.4864431424539196e-05,
      "loss": 0.3181,
      "step": 9480
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5506107807159424,
      "learning_rate": 1.4853739896506009e-05,
      "loss": 0.3019,
      "step": 9490
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1715630292892456,
      "learning_rate": 1.4843048368472823e-05,
      "loss": 0.2954,
      "step": 9500
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1780825853347778,
      "learning_rate": 1.4832356840439638e-05,
      "loss": 0.3686,
      "step": 9510
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.42606037855148315,
      "learning_rate": 1.4821665312406449e-05,
      "loss": 0.1964,
      "step": 9520
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.438881754875183,
      "learning_rate": 1.4810973784373264e-05,
      "loss": 0.2867,
      "step": 9530
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5750954151153564,
      "learning_rate": 1.4800282256340075e-05,
      "loss": 0.2944,
      "step": 9540
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.060033917427063,
      "learning_rate": 1.478959072830689e-05,
      "loss": 0.2527,
      "step": 9550
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.033565640449524,
      "learning_rate": 1.4778899200273704e-05,
      "loss": 0.241,
      "step": 9560
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3681318759918213,
      "learning_rate": 1.4768207672240517e-05,
      "loss": 0.2497,
      "step": 9570
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6497015953063965,
      "learning_rate": 1.4757516144207331e-05,
      "loss": 0.2617,
      "step": 9580
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.28218412399292,
      "learning_rate": 1.4746824616174143e-05,
      "loss": 0.2192,
      "step": 9590
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4463801383972168,
      "learning_rate": 1.4736133088140957e-05,
      "loss": 0.2792,
      "step": 9600
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3574031591415405,
      "learning_rate": 1.4725441560107772e-05,
      "loss": 0.2662,
      "step": 9610
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2786219120025635,
      "learning_rate": 1.4714750032074585e-05,
      "loss": 0.3298,
      "step": 9620
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5232430696487427,
      "learning_rate": 1.47040585040414e-05,
      "loss": 0.2773,
      "step": 9630
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.5431416034698486,
      "learning_rate": 1.469336697600821e-05,
      "loss": 0.3529,
      "step": 9640
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4896546602249146,
      "learning_rate": 1.4682675447975025e-05,
      "loss": 0.2216,
      "step": 9650
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.5691433548927307,
      "learning_rate": 1.467198391994184e-05,
      "loss": 0.2857,
      "step": 9660
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6025089025497437,
      "learning_rate": 1.4661292391908651e-05,
      "loss": 0.2469,
      "step": 9670
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.4537522792816162,
      "learning_rate": 1.4650600863875466e-05,
      "loss": 0.2905,
      "step": 9680
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.406875491142273,
      "learning_rate": 1.463990933584228e-05,
      "loss": 0.3581,
      "step": 9690
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.38244518637657166,
      "learning_rate": 1.4629217807809093e-05,
      "loss": 0.2744,
      "step": 9700
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9224619269371033,
      "learning_rate": 1.4618526279775908e-05,
      "loss": 0.257,
      "step": 9710
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2172904014587402,
      "learning_rate": 1.4607834751742719e-05,
      "loss": 0.3067,
      "step": 9720
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3857319355010986,
      "learning_rate": 1.4597143223709533e-05,
      "loss": 0.2569,
      "step": 9730
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3002261817455292,
      "learning_rate": 1.4586451695676348e-05,
      "loss": 0.2436,
      "step": 9740
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.281596302986145,
      "learning_rate": 1.457576016764316e-05,
      "loss": 0.2353,
      "step": 9750
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.2324105203151703,
      "learning_rate": 1.4565068639609974e-05,
      "loss": 0.2406,
      "step": 9760
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2295266389846802,
      "learning_rate": 1.4554377111576787e-05,
      "loss": 0.2826,
      "step": 9770
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7799286842346191,
      "learning_rate": 1.4543685583543601e-05,
      "loss": 0.2662,
      "step": 9780
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8636375069618225,
      "learning_rate": 1.4532994055510416e-05,
      "loss": 0.2239,
      "step": 9790
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.2575724124908447,
      "learning_rate": 1.4522302527477227e-05,
      "loss": 0.2222,
      "step": 9800
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4864522218704224,
      "learning_rate": 1.4511610999444042e-05,
      "loss": 0.3431,
      "step": 9810
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.415956735610962,
      "learning_rate": 1.4500919471410855e-05,
      "loss": 0.2969,
      "step": 9820
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3511888086795807,
      "learning_rate": 1.4490227943377669e-05,
      "loss": 0.3206,
      "step": 9830
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2428230047225952,
      "learning_rate": 1.4479536415344484e-05,
      "loss": 0.3094,
      "step": 9840
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0282262563705444,
      "learning_rate": 1.4468844887311295e-05,
      "loss": 0.2874,
      "step": 9850
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2298502922058105,
      "learning_rate": 1.445815335927811e-05,
      "loss": 0.2225,
      "step": 9860
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6236432790756226,
      "learning_rate": 1.444746183124492e-05,
      "loss": 0.2786,
      "step": 9870
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8178947567939758,
      "learning_rate": 1.4436770303211735e-05,
      "loss": 0.3189,
      "step": 9880
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6147783994674683,
      "learning_rate": 1.442607877517855e-05,
      "loss": 0.2592,
      "step": 9890
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9849944710731506,
      "learning_rate": 1.4415387247145363e-05,
      "loss": 0.3056,
      "step": 9900
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9528992772102356,
      "learning_rate": 1.4404695719112177e-05,
      "loss": 0.2508,
      "step": 9910
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3130202293395996,
      "learning_rate": 1.4394004191078989e-05,
      "loss": 0.3437,
      "step": 9920
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9695168733596802,
      "learning_rate": 1.4383312663045803e-05,
      "loss": 0.2684,
      "step": 9930
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.278075933456421,
      "learning_rate": 1.4372621135012618e-05,
      "loss": 0.3339,
      "step": 9940
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8056387901306152,
      "learning_rate": 1.4361929606979429e-05,
      "loss": 0.2747,
      "step": 9950
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0743918418884277,
      "learning_rate": 1.4351238078946244e-05,
      "loss": 0.2826,
      "step": 9960
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.519234538078308,
      "learning_rate": 1.4340546550913056e-05,
      "loss": 0.247,
      "step": 9970
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.7004989385604858,
      "learning_rate": 1.4329855022879871e-05,
      "loss": 0.302,
      "step": 9980
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1377911567687988,
      "learning_rate": 1.4319163494846686e-05,
      "loss": 0.3484,
      "step": 9990
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6437290906906128,
      "learning_rate": 1.4308471966813497e-05,
      "loss": 0.2113,
      "step": 10000
    },
    {
      "epoch": 0.43,
      "eval_loss": 0.29192933440208435,
      "eval_runtime": 725.1609,
      "eval_samples_per_second": 3.62,
      "eval_steps_per_second": 3.62,
      "step": 10000
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0423203706741333,
      "learning_rate": 1.4297780438780311e-05,
      "loss": 0.2941,
      "step": 10010
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3324449062347412,
      "learning_rate": 1.4287088910747123e-05,
      "loss": 0.2697,
      "step": 10020
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5406500101089478,
      "learning_rate": 1.4276397382713937e-05,
      "loss": 0.3275,
      "step": 10030
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5122132301330566,
      "learning_rate": 1.4265705854680752e-05,
      "loss": 0.306,
      "step": 10040
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.4428540468215942,
      "learning_rate": 1.4255014326647565e-05,
      "loss": 0.2417,
      "step": 10050
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3402764797210693,
      "learning_rate": 1.424432279861438e-05,
      "loss": 0.3696,
      "step": 10060
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.0675084590911865,
      "learning_rate": 1.423363127058119e-05,
      "loss": 0.2248,
      "step": 10070
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5481032133102417,
      "learning_rate": 1.4222939742548005e-05,
      "loss": 0.3049,
      "step": 10080
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.5340123176574707,
      "learning_rate": 1.421224821451482e-05,
      "loss": 0.3145,
      "step": 10090
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2930084466934204,
      "learning_rate": 1.4201556686481633e-05,
      "loss": 0.2095,
      "step": 10100
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9404712915420532,
      "learning_rate": 1.4190865158448447e-05,
      "loss": 0.2662,
      "step": 10110
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9303451776504517,
      "learning_rate": 1.4180173630415258e-05,
      "loss": 0.3025,
      "step": 10120
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.9981988668441772,
      "learning_rate": 1.4169482102382073e-05,
      "loss": 0.2669,
      "step": 10130
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.6144523620605469,
      "learning_rate": 1.4158790574348888e-05,
      "loss": 0.3024,
      "step": 10140
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9414999485015869,
      "learning_rate": 1.4148099046315699e-05,
      "loss": 0.2389,
      "step": 10150
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.4820905923843384,
      "learning_rate": 1.4137407518282513e-05,
      "loss": 0.2795,
      "step": 10160
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.8797595500946045,
      "learning_rate": 1.4126715990249328e-05,
      "loss": 0.2803,
      "step": 10170
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.508187174797058,
      "learning_rate": 1.411602446221614e-05,
      "loss": 0.3109,
      "step": 10180
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1280133724212646,
      "learning_rate": 1.4105332934182955e-05,
      "loss": 0.2985,
      "step": 10190
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4770303964614868,
      "learning_rate": 1.4094641406149767e-05,
      "loss": 0.2399,
      "step": 10200
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.512947916984558,
      "learning_rate": 1.4083949878116581e-05,
      "loss": 0.3136,
      "step": 10210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4481498003005981,
      "learning_rate": 1.4073258350083396e-05,
      "loss": 0.2952,
      "step": 10220
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.423829436302185,
      "learning_rate": 1.4062566822050207e-05,
      "loss": 0.3248,
      "step": 10230
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.384753942489624,
      "learning_rate": 1.4051875294017022e-05,
      "loss": 0.228,
      "step": 10240
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.751021146774292,
      "learning_rate": 1.4041183765983834e-05,
      "loss": 0.2913,
      "step": 10250
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.46854597330093384,
      "learning_rate": 1.4030492237950649e-05,
      "loss": 0.2479,
      "step": 10260
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2486025094985962,
      "learning_rate": 1.4019800709917464e-05,
      "loss": 0.3152,
      "step": 10270
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5248520374298096,
      "learning_rate": 1.4009109181884275e-05,
      "loss": 0.2291,
      "step": 10280
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2810510396957397,
      "learning_rate": 1.399841765385109e-05,
      "loss": 0.294,
      "step": 10290
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3097807168960571,
      "learning_rate": 1.3987726125817902e-05,
      "loss": 0.3682,
      "step": 10300
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.937171995639801,
      "learning_rate": 1.3977034597784717e-05,
      "loss": 0.1918,
      "step": 10310
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1325255632400513,
      "learning_rate": 1.3966343069751532e-05,
      "loss": 0.3428,
      "step": 10320
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6237976551055908,
      "learning_rate": 1.3955651541718343e-05,
      "loss": 0.2864,
      "step": 10330
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.744676947593689,
      "learning_rate": 1.3944960013685157e-05,
      "loss": 0.2733,
      "step": 10340
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0552682876586914,
      "learning_rate": 1.3934268485651969e-05,
      "loss": 0.3878,
      "step": 10350
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3241534233093262,
      "learning_rate": 1.3923576957618783e-05,
      "loss": 0.3517,
      "step": 10360
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.128098726272583,
      "learning_rate": 1.3912885429585598e-05,
      "loss": 0.1931,
      "step": 10370
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2067347764968872,
      "learning_rate": 1.390219390155241e-05,
      "loss": 0.2836,
      "step": 10380
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3374371528625488,
      "learning_rate": 1.3891502373519225e-05,
      "loss": 0.281,
      "step": 10390
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6885405778884888,
      "learning_rate": 1.3880810845486036e-05,
      "loss": 0.2771,
      "step": 10400
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.8897831439971924,
      "learning_rate": 1.3870119317452851e-05,
      "loss": 0.3144,
      "step": 10410
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5909022688865662,
      "learning_rate": 1.3859427789419666e-05,
      "loss": 0.2855,
      "step": 10420
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.36273106932640076,
      "learning_rate": 1.3848736261386477e-05,
      "loss": 0.1699,
      "step": 10430
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.994723916053772,
      "learning_rate": 1.3838044733353291e-05,
      "loss": 0.2634,
      "step": 10440
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.392650842666626,
      "learning_rate": 1.3827353205320104e-05,
      "loss": 0.2856,
      "step": 10450
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4136525392532349,
      "learning_rate": 1.3816661677286919e-05,
      "loss": 0.2688,
      "step": 10460
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2041053771972656,
      "learning_rate": 1.3805970149253733e-05,
      "loss": 0.3049,
      "step": 10470
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7395906448364258,
      "learning_rate": 1.3795278621220545e-05,
      "loss": 0.1823,
      "step": 10480
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.659977912902832,
      "learning_rate": 1.378458709318736e-05,
      "loss": 0.3273,
      "step": 10490
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.7338221073150635,
      "learning_rate": 1.377389556515417e-05,
      "loss": 0.2503,
      "step": 10500
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4580926895141602,
      "learning_rate": 1.3763204037120985e-05,
      "loss": 0.2313,
      "step": 10510
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2476800680160522,
      "learning_rate": 1.37525125090878e-05,
      "loss": 0.2693,
      "step": 10520
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.138525366783142,
      "learning_rate": 1.3741820981054613e-05,
      "loss": 0.2612,
      "step": 10530
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.198528528213501,
      "learning_rate": 1.3731129453021427e-05,
      "loss": 0.3324,
      "step": 10540
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.40334004163742065,
      "learning_rate": 1.3720437924988238e-05,
      "loss": 0.2491,
      "step": 10550
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.9479646682739258,
      "learning_rate": 1.3709746396955053e-05,
      "loss": 0.2835,
      "step": 10560
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.126214861869812,
      "learning_rate": 1.3699054868921867e-05,
      "loss": 0.2743,
      "step": 10570
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.940011739730835,
      "learning_rate": 1.368836334088868e-05,
      "loss": 0.2589,
      "step": 10580
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9704784750938416,
      "learning_rate": 1.3677671812855495e-05,
      "loss": 0.3165,
      "step": 10590
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.5588451027870178,
      "learning_rate": 1.3666980284822306e-05,
      "loss": 0.2251,
      "step": 10600
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3135231733322144,
      "learning_rate": 1.365628875678912e-05,
      "loss": 0.3083,
      "step": 10610
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9680503606796265,
      "learning_rate": 1.3645597228755935e-05,
      "loss": 0.3098,
      "step": 10620
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4323269128799438,
      "learning_rate": 1.3634905700722747e-05,
      "loss": 0.2189,
      "step": 10630
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1180022954940796,
      "learning_rate": 1.3624214172689561e-05,
      "loss": 0.3012,
      "step": 10640
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1714361906051636,
      "learning_rate": 1.3613522644656376e-05,
      "loss": 0.2149,
      "step": 10650
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3721009492874146,
      "learning_rate": 1.3602831116623189e-05,
      "loss": 0.2649,
      "step": 10660
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.753381609916687,
      "learning_rate": 1.3592139588590003e-05,
      "loss": 0.3178,
      "step": 10670
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4406017065048218,
      "learning_rate": 1.3581448060556814e-05,
      "loss": 0.3078,
      "step": 10680
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4131194353103638,
      "learning_rate": 1.3570756532523629e-05,
      "loss": 0.2296,
      "step": 10690
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4216300249099731,
      "learning_rate": 1.3560065004490444e-05,
      "loss": 0.2659,
      "step": 10700
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.6626172065734863,
      "learning_rate": 1.3549373476457255e-05,
      "loss": 0.1725,
      "step": 10710
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.586622714996338,
      "learning_rate": 1.353868194842407e-05,
      "loss": 0.2553,
      "step": 10720
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1555062532424927,
      "learning_rate": 1.3527990420390882e-05,
      "loss": 0.2366,
      "step": 10730
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2869960069656372,
      "learning_rate": 1.3517298892357697e-05,
      "loss": 0.3361,
      "step": 10740
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.316786527633667,
      "learning_rate": 1.3506607364324511e-05,
      "loss": 0.2665,
      "step": 10750
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1048557758331299,
      "learning_rate": 1.3495915836291323e-05,
      "loss": 0.26,
      "step": 10760
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3030188083648682,
      "learning_rate": 1.3485224308258137e-05,
      "loss": 0.3736,
      "step": 10770
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.489071011543274,
      "learning_rate": 1.347453278022495e-05,
      "loss": 0.2438,
      "step": 10780
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4267820119857788,
      "learning_rate": 1.3463841252191765e-05,
      "loss": 0.2823,
      "step": 10790
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.509927749633789,
      "learning_rate": 1.345314972415858e-05,
      "loss": 0.2502,
      "step": 10800
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3388985395431519,
      "learning_rate": 1.344245819612539e-05,
      "loss": 0.3098,
      "step": 10810
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9887898564338684,
      "learning_rate": 1.3431766668092205e-05,
      "loss": 0.2625,
      "step": 10820
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4629664421081543,
      "learning_rate": 1.3421075140059016e-05,
      "loss": 0.3074,
      "step": 10830
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2335575819015503,
      "learning_rate": 1.3410383612025831e-05,
      "loss": 0.3448,
      "step": 10840
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.6466829180717468,
      "learning_rate": 1.3399692083992646e-05,
      "loss": 0.2274,
      "step": 10850
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1292864084243774,
      "learning_rate": 1.3389000555959458e-05,
      "loss": 0.3568,
      "step": 10860
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.5793204307556152,
      "learning_rate": 1.3378309027926273e-05,
      "loss": 0.2982,
      "step": 10870
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9163182973861694,
      "learning_rate": 1.3367617499893084e-05,
      "loss": 0.2476,
      "step": 10880
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6297417879104614,
      "learning_rate": 1.3356925971859899e-05,
      "loss": 0.2918,
      "step": 10890
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.167577862739563,
      "learning_rate": 1.3346234443826713e-05,
      "loss": 0.3065,
      "step": 10900
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6771129369735718,
      "learning_rate": 1.3335542915793525e-05,
      "loss": 0.3406,
      "step": 10910
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1910159587860107,
      "learning_rate": 1.332485138776034e-05,
      "loss": 0.3563,
      "step": 10920
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3197792768478394,
      "learning_rate": 1.3314159859727152e-05,
      "loss": 0.2608,
      "step": 10930
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.648751139640808,
      "learning_rate": 1.3303468331693967e-05,
      "loss": 0.2954,
      "step": 10940
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3287606239318848,
      "learning_rate": 1.3292776803660781e-05,
      "loss": 0.2983,
      "step": 10950
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7304186820983887,
      "learning_rate": 1.3282085275627592e-05,
      "loss": 0.2893,
      "step": 10960
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.8554930686950684,
      "learning_rate": 1.3271393747594407e-05,
      "loss": 0.2295,
      "step": 10970
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7270618677139282,
      "learning_rate": 1.3260702219561218e-05,
      "loss": 0.2493,
      "step": 10980
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3066902160644531,
      "learning_rate": 1.3250010691528033e-05,
      "loss": 0.2832,
      "step": 10990
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1693063974380493,
      "learning_rate": 1.3239319163494847e-05,
      "loss": 0.2449,
      "step": 11000
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.28999316692352295,
      "eval_runtime": 724.9811,
      "eval_samples_per_second": 3.621,
      "eval_steps_per_second": 3.621,
      "step": 11000
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.521554946899414,
      "learning_rate": 1.322862763546166e-05,
      "loss": 0.2565,
      "step": 11010
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2787705659866333,
      "learning_rate": 1.3217936107428475e-05,
      "loss": 0.3263,
      "step": 11020
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4977266788482666,
      "learning_rate": 1.3207244579395286e-05,
      "loss": 0.2806,
      "step": 11030
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2588587999343872,
      "learning_rate": 1.31965530513621e-05,
      "loss": 0.2668,
      "step": 11040
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4914802312850952,
      "learning_rate": 1.3185861523328915e-05,
      "loss": 0.3128,
      "step": 11050
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.44560179114341736,
      "learning_rate": 1.3175169995295728e-05,
      "loss": 0.2328,
      "step": 11060
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4394863843917847,
      "learning_rate": 1.3164478467262543e-05,
      "loss": 0.2468,
      "step": 11070
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9289019107818604,
      "learning_rate": 1.3153786939229357e-05,
      "loss": 0.2659,
      "step": 11080
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7315177917480469,
      "learning_rate": 1.3143095411196169e-05,
      "loss": 0.2505,
      "step": 11090
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.7901235818862915,
      "learning_rate": 1.3132403883162983e-05,
      "loss": 0.2547,
      "step": 11100
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.953416109085083,
      "learning_rate": 1.3121712355129794e-05,
      "loss": 0.194,
      "step": 11110
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9127142429351807,
      "learning_rate": 1.3111020827096609e-05,
      "loss": 0.3278,
      "step": 11120
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.438841462135315,
      "learning_rate": 1.3100329299063424e-05,
      "loss": 0.2319,
      "step": 11130
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5523960590362549,
      "learning_rate": 1.3089637771030236e-05,
      "loss": 0.2835,
      "step": 11140
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6927253007888794,
      "learning_rate": 1.3078946242997051e-05,
      "loss": 0.3436,
      "step": 11150
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5060522556304932,
      "learning_rate": 1.3068254714963862e-05,
      "loss": 0.2642,
      "step": 11160
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.1925201416015625,
      "learning_rate": 1.3057563186930677e-05,
      "loss": 0.3581,
      "step": 11170
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5703428983688354,
      "learning_rate": 1.3046871658897491e-05,
      "loss": 0.2352,
      "step": 11180
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.558837652206421,
      "learning_rate": 1.3036180130864303e-05,
      "loss": 0.1993,
      "step": 11190
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.6146512031555176,
      "learning_rate": 1.3025488602831117e-05,
      "loss": 0.3458,
      "step": 11200
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4977048635482788,
      "learning_rate": 1.301479707479793e-05,
      "loss": 0.2087,
      "step": 11210
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9568657875061035,
      "learning_rate": 1.3004105546764745e-05,
      "loss": 0.2414,
      "step": 11220
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8324788808822632,
      "learning_rate": 1.299341401873156e-05,
      "loss": 0.2919,
      "step": 11230
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6888036727905273,
      "learning_rate": 1.298272249069837e-05,
      "loss": 0.2211,
      "step": 11240
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4353554248809814,
      "learning_rate": 1.2972030962665185e-05,
      "loss": 0.2472,
      "step": 11250
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3575337529182434,
      "learning_rate": 1.2961339434631998e-05,
      "loss": 0.1987,
      "step": 11260
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6726675629615784,
      "learning_rate": 1.2950647906598813e-05,
      "loss": 0.2302,
      "step": 11270
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5212070941925049,
      "learning_rate": 1.2939956378565627e-05,
      "loss": 0.2378,
      "step": 11280
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.96961909532547,
      "learning_rate": 1.2929264850532438e-05,
      "loss": 0.2576,
      "step": 11290
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0876591205596924,
      "learning_rate": 1.2918573322499253e-05,
      "loss": 0.2605,
      "step": 11300
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3504005670547485,
      "learning_rate": 1.2907881794466064e-05,
      "loss": 0.2775,
      "step": 11310
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.614423394203186,
      "learning_rate": 1.2897190266432879e-05,
      "loss": 0.2486,
      "step": 11320
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3067432641983032,
      "learning_rate": 1.2886498738399693e-05,
      "loss": 0.2799,
      "step": 11330
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5527353286743164,
      "learning_rate": 1.2875807210366506e-05,
      "loss": 0.2936,
      "step": 11340
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.205640435218811,
      "learning_rate": 1.286511568233332e-05,
      "loss": 0.2204,
      "step": 11350
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2316466569900513,
      "learning_rate": 1.2854424154300132e-05,
      "loss": 0.2781,
      "step": 11360
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.7161717414855957,
      "learning_rate": 1.2843732626266947e-05,
      "loss": 0.2726,
      "step": 11370
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3140755891799927,
      "learning_rate": 1.2833041098233761e-05,
      "loss": 0.324,
      "step": 11380
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9362431764602661,
      "learning_rate": 1.2822349570200572e-05,
      "loss": 0.2673,
      "step": 11390
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2993865013122559,
      "learning_rate": 1.2811658042167387e-05,
      "loss": 0.286,
      "step": 11400
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.5074551701545715,
      "learning_rate": 1.28009665141342e-05,
      "loss": 0.2424,
      "step": 11410
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4799578189849854,
      "learning_rate": 1.2790274986101014e-05,
      "loss": 0.3183,
      "step": 11420
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.8446125984191895,
      "learning_rate": 1.2779583458067829e-05,
      "loss": 0.2772,
      "step": 11430
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5015558004379272,
      "learning_rate": 1.276889193003464e-05,
      "loss": 0.2248,
      "step": 11440
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7593899965286255,
      "learning_rate": 1.2758200402001455e-05,
      "loss": 0.2801,
      "step": 11450
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.364517092704773,
      "learning_rate": 1.2747508873968266e-05,
      "loss": 0.2833,
      "step": 11460
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2675049304962158,
      "learning_rate": 1.273681734593508e-05,
      "loss": 0.2412,
      "step": 11470
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9750456809997559,
      "learning_rate": 1.2726125817901895e-05,
      "loss": 0.298,
      "step": 11480
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.437341570854187,
      "learning_rate": 1.2715434289868708e-05,
      "loss": 0.2448,
      "step": 11490
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6045538783073425,
      "learning_rate": 1.2704742761835523e-05,
      "loss": 0.2119,
      "step": 11500
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4051337242126465,
      "learning_rate": 1.2694051233802334e-05,
      "loss": 0.2008,
      "step": 11510
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.5876652002334595,
      "learning_rate": 1.2683359705769149e-05,
      "loss": 0.2903,
      "step": 11520
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2795990705490112,
      "learning_rate": 1.2672668177735963e-05,
      "loss": 0.3502,
      "step": 11530
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.138434886932373,
      "learning_rate": 1.2661976649702776e-05,
      "loss": 0.2436,
      "step": 11540
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4865120649337769,
      "learning_rate": 1.265128512166959e-05,
      "loss": 0.302,
      "step": 11550
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7874823808670044,
      "learning_rate": 1.2640593593636405e-05,
      "loss": 0.2273,
      "step": 11560
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7398353815078735,
      "learning_rate": 1.2629902065603216e-05,
      "loss": 0.3221,
      "step": 11570
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8422690629959106,
      "learning_rate": 1.2619210537570031e-05,
      "loss": 0.221,
      "step": 11580
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.0885813236236572,
      "learning_rate": 1.2608519009536842e-05,
      "loss": 0.3213,
      "step": 11590
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1192684173583984,
      "learning_rate": 1.2597827481503657e-05,
      "loss": 0.2906,
      "step": 11600
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2677446603775024,
      "learning_rate": 1.2587135953470471e-05,
      "loss": 0.2373,
      "step": 11610
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6095311641693115,
      "learning_rate": 1.2576444425437284e-05,
      "loss": 0.2325,
      "step": 11620
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9067690372467041,
      "learning_rate": 1.2565752897404099e-05,
      "loss": 0.2607,
      "step": 11630
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.6342405080795288,
      "learning_rate": 1.255506136937091e-05,
      "loss": 0.3588,
      "step": 11640
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3113874197006226,
      "learning_rate": 1.2544369841337725e-05,
      "loss": 0.2553,
      "step": 11650
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3199551105499268,
      "learning_rate": 1.253367831330454e-05,
      "loss": 0.2182,
      "step": 11660
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.266027569770813,
      "learning_rate": 1.252298678527135e-05,
      "loss": 0.2526,
      "step": 11670
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4716346263885498,
      "learning_rate": 1.2512295257238165e-05,
      "loss": 0.2141,
      "step": 11680
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.526045799255371,
      "learning_rate": 1.2501603729204978e-05,
      "loss": 0.2842,
      "step": 11690
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.39413079619407654,
      "learning_rate": 1.2490912201171792e-05,
      "loss": 0.312,
      "step": 11700
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.43261128664016724,
      "learning_rate": 1.2480220673138605e-05,
      "loss": 0.3141,
      "step": 11710
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1484614610671997,
      "learning_rate": 1.2469529145105418e-05,
      "loss": 0.3337,
      "step": 11720
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2421343326568604,
      "learning_rate": 1.2458837617072233e-05,
      "loss": 0.2414,
      "step": 11730
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0221580266952515,
      "learning_rate": 1.2448146089039046e-05,
      "loss": 0.251,
      "step": 11740
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4560279846191406,
      "learning_rate": 1.243745456100586e-05,
      "loss": 0.304,
      "step": 11750
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.5632816553115845,
      "learning_rate": 1.2426763032972673e-05,
      "loss": 0.3161,
      "step": 11760
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7862232327461243,
      "learning_rate": 1.2416071504939486e-05,
      "loss": 0.235,
      "step": 11770
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.587677240371704,
      "learning_rate": 1.24053799769063e-05,
      "loss": 0.3245,
      "step": 11780
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7129762172698975,
      "learning_rate": 1.2394688448873114e-05,
      "loss": 0.3095,
      "step": 11790
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.7323946952819824,
      "learning_rate": 1.2383996920839927e-05,
      "loss": 0.3047,
      "step": 11800
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4802186489105225,
      "learning_rate": 1.237330539280674e-05,
      "loss": 0.2621,
      "step": 11810
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.809801459312439,
      "learning_rate": 1.2362613864773554e-05,
      "loss": 0.2061,
      "step": 11820
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1173226833343506,
      "learning_rate": 1.2351922336740369e-05,
      "loss": 0.2186,
      "step": 11830
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.5539370775222778,
      "learning_rate": 1.2341230808707182e-05,
      "loss": 0.1998,
      "step": 11840
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.32077139616012573,
      "learning_rate": 1.2330539280673994e-05,
      "loss": 0.2728,
      "step": 11850
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6027793288230896,
      "learning_rate": 1.2319847752640807e-05,
      "loss": 0.2333,
      "step": 11860
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.790863037109375,
      "learning_rate": 1.230915622460762e-05,
      "loss": 0.297,
      "step": 11870
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5631848573684692,
      "learning_rate": 1.2298464696574435e-05,
      "loss": 0.3199,
      "step": 11880
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8170543909072876,
      "learning_rate": 1.228777316854125e-05,
      "loss": 0.2455,
      "step": 11890
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9270610809326172,
      "learning_rate": 1.2277081640508062e-05,
      "loss": 0.2039,
      "step": 11900
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.37637460231781,
      "learning_rate": 1.2266390112474875e-05,
      "loss": 0.3528,
      "step": 11910
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.979034960269928,
      "learning_rate": 1.225569858444169e-05,
      "loss": 0.249,
      "step": 11920
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4904437065124512,
      "learning_rate": 1.2245007056408503e-05,
      "loss": 0.2544,
      "step": 11930
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4901533126831055,
      "learning_rate": 1.2234315528375316e-05,
      "loss": 0.2882,
      "step": 11940
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4645349979400635,
      "learning_rate": 1.2223624000342128e-05,
      "loss": 0.329,
      "step": 11950
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.36449670791625977,
      "learning_rate": 1.2212932472308943e-05,
      "loss": 0.2742,
      "step": 11960
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6154406070709229,
      "learning_rate": 1.2202240944275758e-05,
      "loss": 0.3121,
      "step": 11970
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.687341570854187,
      "learning_rate": 1.219154941624257e-05,
      "loss": 0.2923,
      "step": 11980
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.5311498641967773,
      "learning_rate": 1.2180857888209383e-05,
      "loss": 0.2886,
      "step": 11990
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.9357864260673523,
      "learning_rate": 1.2170166360176196e-05,
      "loss": 0.3625,
      "step": 12000
    },
    {
      "epoch": 0.51,
      "eval_loss": 0.28864240646362305,
      "eval_runtime": 723.4363,
      "eval_samples_per_second": 3.629,
      "eval_steps_per_second": 3.629,
      "step": 12000
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.4111590385437012,
      "learning_rate": 1.215947483214301e-05,
      "loss": 0.2696,
      "step": 12010
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.6022282838821411,
      "learning_rate": 1.2148783304109824e-05,
      "loss": 0.2319,
      "step": 12020
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.8184062242507935,
      "learning_rate": 1.2138091776076638e-05,
      "loss": 0.2449,
      "step": 12030
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.407994031906128,
      "learning_rate": 1.2127400248043451e-05,
      "loss": 0.2579,
      "step": 12040
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5871583223342896,
      "learning_rate": 1.2116708720010264e-05,
      "loss": 0.2809,
      "step": 12050
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.520634651184082,
      "learning_rate": 1.2106017191977077e-05,
      "loss": 0.2968,
      "step": 12060
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.0759673118591309,
      "learning_rate": 1.2095325663943892e-05,
      "loss": 0.2508,
      "step": 12070
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3613682985305786,
      "learning_rate": 1.2084634135910705e-05,
      "loss": 0.3111,
      "step": 12080
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7108718156814575,
      "learning_rate": 1.2073942607877519e-05,
      "loss": 0.2168,
      "step": 12090
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.9383495450019836,
      "learning_rate": 1.2063251079844332e-05,
      "loss": 0.2726,
      "step": 12100
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3960988521575928,
      "learning_rate": 1.2052559551811145e-05,
      "loss": 0.2859,
      "step": 12110
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.538845419883728,
      "learning_rate": 1.204186802377796e-05,
      "loss": 0.2498,
      "step": 12120
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.5295881032943726,
      "learning_rate": 1.2031176495744772e-05,
      "loss": 0.3214,
      "step": 12130
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3301714658737183,
      "learning_rate": 1.2020484967711585e-05,
      "loss": 0.2719,
      "step": 12140
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.3220511674880981,
      "learning_rate": 1.2009793439678398e-05,
      "loss": 0.3646,
      "step": 12150
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.9047530889511108,
      "learning_rate": 1.1999101911645213e-05,
      "loss": 0.2142,
      "step": 12160
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.0524251461029053,
      "learning_rate": 1.1988410383612027e-05,
      "loss": 0.2009,
      "step": 12170
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2319122552871704,
      "learning_rate": 1.197771885557884e-05,
      "loss": 0.308,
      "step": 12180
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.840131163597107,
      "learning_rate": 1.1967027327545653e-05,
      "loss": 0.2145,
      "step": 12190
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2186757326126099,
      "learning_rate": 1.1956335799512466e-05,
      "loss": 0.293,
      "step": 12200
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.1713247299194336,
      "learning_rate": 1.194564427147928e-05,
      "loss": 0.2574,
      "step": 12210
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.254959225654602,
      "learning_rate": 1.1934952743446094e-05,
      "loss": 0.2434,
      "step": 12220
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.4863431453704834,
      "learning_rate": 1.1924261215412908e-05,
      "loss": 0.2314,
      "step": 12230
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.2933266162872314,
      "learning_rate": 1.1913569687379721e-05,
      "loss": 0.2488,
      "step": 12240
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.7385591268539429,
      "learning_rate": 1.1902878159346534e-05,
      "loss": 0.1826,
      "step": 12250
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.37174391746521,
      "learning_rate": 1.1892186631313349e-05,
      "loss": 0.2752,
      "step": 12260
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.7767287492752075,
      "learning_rate": 1.1881495103280161e-05,
      "loss": 0.2439,
      "step": 12270
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.104283094406128,
      "learning_rate": 1.1870803575246974e-05,
      "loss": 0.2928,
      "step": 12280
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.619200348854065,
      "learning_rate": 1.1860112047213787e-05,
      "loss": 0.2893,
      "step": 12290
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.5207479000091553,
      "learning_rate": 1.1849420519180602e-05,
      "loss": 0.2198,
      "step": 12300
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5396816730499268,
      "learning_rate": 1.1838728991147416e-05,
      "loss": 0.2513,
      "step": 12310
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.320083498954773,
      "learning_rate": 1.182803746311423e-05,
      "loss": 0.3055,
      "step": 12320
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7695205211639404,
      "learning_rate": 1.1817345935081042e-05,
      "loss": 0.2442,
      "step": 12330
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5489622354507446,
      "learning_rate": 1.1806654407047855e-05,
      "loss": 0.2344,
      "step": 12340
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.3750993609428406,
      "learning_rate": 1.1795962879014668e-05,
      "loss": 0.2775,
      "step": 12350
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.0383208990097046,
      "learning_rate": 1.1785271350981483e-05,
      "loss": 0.287,
      "step": 12360
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9313101768493652,
      "learning_rate": 1.1774579822948297e-05,
      "loss": 0.2122,
      "step": 12370
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.0353946685791016,
      "learning_rate": 1.176388829491511e-05,
      "loss": 0.1734,
      "step": 12380
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5547572374343872,
      "learning_rate": 1.1753196766881923e-05,
      "loss": 0.2981,
      "step": 12390
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3856102228164673,
      "learning_rate": 1.1742505238848738e-05,
      "loss": 0.2994,
      "step": 12400
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.531904935836792,
      "learning_rate": 1.173181371081555e-05,
      "loss": 0.3756,
      "step": 12410
    },
    {
      "epoch": 0.53,
      "grad_norm": 2.094586133956909,
      "learning_rate": 1.1721122182782363e-05,
      "loss": 0.3098,
      "step": 12420
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7834848165512085,
      "learning_rate": 1.1710430654749178e-05,
      "loss": 0.3085,
      "step": 12430
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7133625745773315,
      "learning_rate": 1.169973912671599e-05,
      "loss": 0.2443,
      "step": 12440
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.3347253799438477,
      "learning_rate": 1.1689047598682805e-05,
      "loss": 0.2587,
      "step": 12450
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.1894792318344116,
      "learning_rate": 1.1678356070649618e-05,
      "loss": 0.3476,
      "step": 12460
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.9191799759864807,
      "learning_rate": 1.1667664542616431e-05,
      "loss": 0.2627,
      "step": 12470
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.7583900690078735,
      "learning_rate": 1.1656973014583244e-05,
      "loss": 0.3333,
      "step": 12480
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.709892988204956,
      "learning_rate": 1.1646281486550057e-05,
      "loss": 0.2901,
      "step": 12490
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.209567904472351,
      "learning_rate": 1.1635589958516872e-05,
      "loss": 0.3299,
      "step": 12500
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.2263731956481934,
      "learning_rate": 1.1624898430483686e-05,
      "loss": 0.2332,
      "step": 12510
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.081700563430786,
      "learning_rate": 1.1614206902450499e-05,
      "loss": 0.1971,
      "step": 12520
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.557934284210205,
      "learning_rate": 1.1603515374417312e-05,
      "loss": 0.2782,
      "step": 12530
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0485540628433228,
      "learning_rate": 1.1592823846384125e-05,
      "loss": 0.2243,
      "step": 12540
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.334101915359497,
      "learning_rate": 1.158213231835094e-05,
      "loss": 0.279,
      "step": 12550
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.4565443992614746,
      "learning_rate": 1.1571440790317752e-05,
      "loss": 0.1374,
      "step": 12560
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5097641944885254,
      "learning_rate": 1.1560749262284567e-05,
      "loss": 0.2359,
      "step": 12570
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.661726713180542,
      "learning_rate": 1.155005773425138e-05,
      "loss": 0.2493,
      "step": 12580
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.250640630722046,
      "learning_rate": 1.1539366206218193e-05,
      "loss": 0.3093,
      "step": 12590
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5207370519638062,
      "learning_rate": 1.1528674678185007e-05,
      "loss": 0.2776,
      "step": 12600
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.0267208814620972,
      "learning_rate": 1.151798315015182e-05,
      "loss": 0.2753,
      "step": 12610
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8552076816558838,
      "learning_rate": 1.1507291622118633e-05,
      "loss": 0.3093,
      "step": 12620
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.437272071838379,
      "learning_rate": 1.1496600094085446e-05,
      "loss": 0.2375,
      "step": 12630
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.501410961151123,
      "learning_rate": 1.148590856605226e-05,
      "loss": 0.233,
      "step": 12640
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.467377781867981,
      "learning_rate": 1.1475217038019075e-05,
      "loss": 0.269,
      "step": 12650
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.761566400527954,
      "learning_rate": 1.1464525509985888e-05,
      "loss": 0.2337,
      "step": 12660
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.377015233039856,
      "learning_rate": 1.1453833981952701e-05,
      "loss": 0.3192,
      "step": 12670
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.6204584836959839,
      "learning_rate": 1.1443142453919514e-05,
      "loss": 0.2133,
      "step": 12680
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4143110513687134,
      "learning_rate": 1.1432450925886328e-05,
      "loss": 0.2732,
      "step": 12690
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.5838228464126587,
      "learning_rate": 1.1421759397853141e-05,
      "loss": 0.2647,
      "step": 12700
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.6103923320770264,
      "learning_rate": 1.1411067869819956e-05,
      "loss": 0.2309,
      "step": 12710
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.8054130673408508,
      "learning_rate": 1.1400376341786769e-05,
      "loss": 0.2087,
      "step": 12720
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.7568681836128235,
      "learning_rate": 1.1389684813753582e-05,
      "loss": 0.2681,
      "step": 12730
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.4718890190124512,
      "learning_rate": 1.1378993285720396e-05,
      "loss": 0.3022,
      "step": 12740
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2961267232894897,
      "learning_rate": 1.136830175768721e-05,
      "loss": 0.2781,
      "step": 12750
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7558177709579468,
      "learning_rate": 1.1357610229654022e-05,
      "loss": 0.269,
      "step": 12760
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.2855894565582275,
      "learning_rate": 1.1346918701620835e-05,
      "loss": 0.3093,
      "step": 12770
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7339811325073242,
      "learning_rate": 1.133622717358765e-05,
      "loss": 0.2843,
      "step": 12780
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4967893362045288,
      "learning_rate": 1.1325535645554464e-05,
      "loss": 0.3178,
      "step": 12790
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3402734994888306,
      "learning_rate": 1.1314844117521277e-05,
      "loss": 0.4127,
      "step": 12800
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5175135135650635,
      "learning_rate": 1.130415258948809e-05,
      "loss": 0.2835,
      "step": 12810
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.8381747007369995,
      "learning_rate": 1.1293461061454903e-05,
      "loss": 0.2472,
      "step": 12820
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.7054857015609741,
      "learning_rate": 1.1282769533421716e-05,
      "loss": 0.2651,
      "step": 12830
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.6103936433792114,
      "learning_rate": 1.127207800538853e-05,
      "loss": 0.3366,
      "step": 12840
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5826315879821777,
      "learning_rate": 1.1261386477355345e-05,
      "loss": 0.221,
      "step": 12850
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5946601629257202,
      "learning_rate": 1.1250694949322158e-05,
      "loss": 0.2389,
      "step": 12860
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3440847396850586,
      "learning_rate": 1.124000342128897e-05,
      "loss": 0.22,
      "step": 12870
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.091260552406311,
      "learning_rate": 1.1229311893255785e-05,
      "loss": 0.2028,
      "step": 12880
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3081095218658447,
      "learning_rate": 1.1218620365222598e-05,
      "loss": 0.3098,
      "step": 12890
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.3650559186935425,
      "learning_rate": 1.1207928837189411e-05,
      "loss": 0.3036,
      "step": 12900
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.138054609298706,
      "learning_rate": 1.1197237309156226e-05,
      "loss": 0.3989,
      "step": 12910
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.44711464643478394,
      "learning_rate": 1.1186545781123039e-05,
      "loss": 0.2714,
      "step": 12920
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.689819097518921,
      "learning_rate": 1.1175854253089853e-05,
      "loss": 0.3361,
      "step": 12930
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.5556221008300781,
      "learning_rate": 1.1165162725056666e-05,
      "loss": 0.2722,
      "step": 12940
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.4304065704345703,
      "learning_rate": 1.1154471197023479e-05,
      "loss": 0.2332,
      "step": 12950
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.546396017074585,
      "learning_rate": 1.1143779668990292e-05,
      "loss": 0.2367,
      "step": 12960
    },
    {
      "epoch": 0.55,
      "grad_norm": 1.240825891494751,
      "learning_rate": 1.1133088140957105e-05,
      "loss": 0.2505,
      "step": 12970
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0400917530059814,
      "learning_rate": 1.112239661292392e-05,
      "loss": 0.2892,
      "step": 12980
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3303265571594238,
      "learning_rate": 1.1111705084890734e-05,
      "loss": 0.2925,
      "step": 12990
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7284603118896484,
      "learning_rate": 1.1101013556857547e-05,
      "loss": 0.2842,
      "step": 13000
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.28705063462257385,
      "eval_runtime": 723.3418,
      "eval_samples_per_second": 3.629,
      "eval_steps_per_second": 3.629,
      "step": 13000
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.5586212873458862,
      "learning_rate": 1.109032202882436e-05,
      "loss": 0.2245,
      "step": 13010
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.8284128904342651,
      "learning_rate": 1.1079630500791173e-05,
      "loss": 0.339,
      "step": 13020
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.3137271404266357,
      "learning_rate": 1.1068938972757987e-05,
      "loss": 0.3301,
      "step": 13030
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9450187087059021,
      "learning_rate": 1.10582474447248e-05,
      "loss": 0.2844,
      "step": 13040
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.2990212440490723,
      "learning_rate": 1.1047555916691615e-05,
      "loss": 0.2438,
      "step": 13050
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6383928060531616,
      "learning_rate": 1.1036864388658428e-05,
      "loss": 0.3229,
      "step": 13060
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.8455484509468079,
      "learning_rate": 1.102617286062524e-05,
      "loss": 0.2633,
      "step": 13070
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4581819772720337,
      "learning_rate": 1.1015481332592055e-05,
      "loss": 0.2508,
      "step": 13080
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.4028260707855225,
      "learning_rate": 1.1004789804558868e-05,
      "loss": 0.2661,
      "step": 13090
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.160582423210144,
      "learning_rate": 1.0994098276525681e-05,
      "loss": 0.1804,
      "step": 13100
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.44243019819259644,
      "learning_rate": 1.0983406748492494e-05,
      "loss": 0.201,
      "step": 13110
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.515499472618103,
      "learning_rate": 1.0972715220459308e-05,
      "loss": 0.219,
      "step": 13120
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6256725788116455,
      "learning_rate": 1.0962023692426123e-05,
      "loss": 0.273,
      "step": 13130
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2550541162490845,
      "learning_rate": 1.0951332164392936e-05,
      "loss": 0.2127,
      "step": 13140
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.610400915145874,
      "learning_rate": 1.0940640636359749e-05,
      "loss": 0.2248,
      "step": 13150
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.6094419956207275,
      "learning_rate": 1.0929949108326562e-05,
      "loss": 0.3388,
      "step": 13160
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.0041921138763428,
      "learning_rate": 1.0919257580293376e-05,
      "loss": 0.2938,
      "step": 13170
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.7831820249557495,
      "learning_rate": 1.090856605226019e-05,
      "loss": 0.2833,
      "step": 13180
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.7312248349189758,
      "learning_rate": 1.0897874524227004e-05,
      "loss": 0.3495,
      "step": 13190
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6068356037139893,
      "learning_rate": 1.0887182996193817e-05,
      "loss": 0.2075,
      "step": 13200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9844744801521301,
      "learning_rate": 1.087649146816063e-05,
      "loss": 0.2378,
      "step": 13210
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.5537856817245483,
      "learning_rate": 1.0865799940127444e-05,
      "loss": 0.3123,
      "step": 13220
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6598459482192993,
      "learning_rate": 1.0855108412094257e-05,
      "loss": 0.1839,
      "step": 13230
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5403544902801514,
      "learning_rate": 1.084441688406107e-05,
      "loss": 0.3316,
      "step": 13240
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5505884885787964,
      "learning_rate": 1.0833725356027883e-05,
      "loss": 0.2263,
      "step": 13250
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.164667010307312,
      "learning_rate": 1.0823033827994697e-05,
      "loss": 0.2357,
      "step": 13260
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.0050718784332275,
      "learning_rate": 1.0812342299961512e-05,
      "loss": 0.312,
      "step": 13270
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.6712182760238647,
      "learning_rate": 1.0801650771928325e-05,
      "loss": 0.2851,
      "step": 13280
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3011595010757446,
      "learning_rate": 1.0790959243895138e-05,
      "loss": 0.3122,
      "step": 13290
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.4638516902923584,
      "learning_rate": 1.078026771586195e-05,
      "loss": 0.3451,
      "step": 13300
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.002462387084961,
      "learning_rate": 1.0769576187828764e-05,
      "loss": 0.3091,
      "step": 13310
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.5127629041671753,
      "learning_rate": 1.0758884659795578e-05,
      "loss": 0.325,
      "step": 13320
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3897117376327515,
      "learning_rate": 1.0748193131762393e-05,
      "loss": 0.336,
      "step": 13330
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.0952467918395996,
      "learning_rate": 1.0737501603729206e-05,
      "loss": 0.2614,
      "step": 13340
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3275729417800903,
      "learning_rate": 1.0726810075696019e-05,
      "loss": 0.3429,
      "step": 13350
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.1525442600250244,
      "learning_rate": 1.0716118547662833e-05,
      "loss": 0.2468,
      "step": 13360
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.30350831151008606,
      "learning_rate": 1.0705427019629646e-05,
      "loss": 0.2348,
      "step": 13370
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3304235935211182,
      "learning_rate": 1.0694735491596459e-05,
      "loss": 0.2467,
      "step": 13380
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.8656107187271118,
      "learning_rate": 1.0684043963563274e-05,
      "loss": 0.2903,
      "step": 13390
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.629549503326416,
      "learning_rate": 1.0673352435530086e-05,
      "loss": 0.2487,
      "step": 13400
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.2032965421676636,
      "learning_rate": 1.0662660907496901e-05,
      "loss": 0.3188,
      "step": 13410
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.9554927945137024,
      "learning_rate": 1.0651969379463714e-05,
      "loss": 0.2553,
      "step": 13420
    },
    {
      "epoch": 0.57,
      "grad_norm": 1.3113603591918945,
      "learning_rate": 1.0641277851430527e-05,
      "loss": 0.2883,
      "step": 13430
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.8312632441520691,
      "learning_rate": 1.063058632339734e-05,
      "loss": 0.2022,
      "step": 13440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9667862057685852,
      "learning_rate": 1.0619894795364153e-05,
      "loss": 0.2301,
      "step": 13450
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2205736637115479,
      "learning_rate": 1.0609203267330967e-05,
      "loss": 0.2868,
      "step": 13460
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3188972473144531,
      "learning_rate": 1.0598511739297782e-05,
      "loss": 0.3332,
      "step": 13470
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.3259069919586182,
      "learning_rate": 1.0587820211264595e-05,
      "loss": 0.3246,
      "step": 13480
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9433852434158325,
      "learning_rate": 1.0577128683231408e-05,
      "loss": 0.2405,
      "step": 13490
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.4277312755584717,
      "learning_rate": 1.056643715519822e-05,
      "loss": 0.2472,
      "step": 13500
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.356473445892334,
      "learning_rate": 1.0555745627165035e-05,
      "loss": 0.2392,
      "step": 13510
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.409432291984558,
      "learning_rate": 1.0545054099131848e-05,
      "loss": 0.2743,
      "step": 13520
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5438143014907837,
      "learning_rate": 1.0534362571098663e-05,
      "loss": 0.3129,
      "step": 13530
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.1248584985733032,
      "learning_rate": 1.0523671043065475e-05,
      "loss": 0.2425,
      "step": 13540
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6672108173370361,
      "learning_rate": 1.0512979515032288e-05,
      "loss": 0.3162,
      "step": 13550
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7803637981414795,
      "learning_rate": 1.0502287986999103e-05,
      "loss": 0.2916,
      "step": 13560
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2748734951019287,
      "learning_rate": 1.0491596458965916e-05,
      "loss": 0.3251,
      "step": 13570
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6222273111343384,
      "learning_rate": 1.0480904930932729e-05,
      "loss": 0.3014,
      "step": 13580
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2178946733474731,
      "learning_rate": 1.0470213402899542e-05,
      "loss": 0.2055,
      "step": 13590
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.2955182790756226,
      "learning_rate": 1.0459521874866356e-05,
      "loss": 0.2508,
      "step": 13600
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8437422513961792,
      "learning_rate": 1.044883034683317e-05,
      "loss": 0.3423,
      "step": 13610
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.7928389310836792,
      "learning_rate": 1.0438138818799984e-05,
      "loss": 0.2719,
      "step": 13620
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.449962854385376,
      "learning_rate": 1.0427447290766797e-05,
      "loss": 0.2477,
      "step": 13630
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9765427112579346,
      "learning_rate": 1.041675576273361e-05,
      "loss": 0.3278,
      "step": 13640
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.9894959926605225,
      "learning_rate": 1.0406064234700424e-05,
      "loss": 0.2566,
      "step": 13650
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.6264784336090088,
      "learning_rate": 1.0395372706667237e-05,
      "loss": 0.242,
      "step": 13660
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.3622090518474579,
      "learning_rate": 1.0384681178634052e-05,
      "loss": 0.2238,
      "step": 13670
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.194150686264038,
      "learning_rate": 1.0373989650600864e-05,
      "loss": 0.2495,
      "step": 13680
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5117076635360718,
      "learning_rate": 1.0363298122567677e-05,
      "loss": 0.273,
      "step": 13690
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4607040882110596,
      "learning_rate": 1.0352606594534492e-05,
      "loss": 0.2846,
      "step": 13700
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.606956422328949,
      "learning_rate": 1.0341915066501305e-05,
      "loss": 0.2299,
      "step": 13710
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3394110202789307,
      "learning_rate": 1.0331223538468118e-05,
      "loss": 0.2011,
      "step": 13720
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8602047562599182,
      "learning_rate": 1.0320532010434932e-05,
      "loss": 0.308,
      "step": 13730
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.1760591268539429,
      "learning_rate": 1.0309840482401745e-05,
      "loss": 0.275,
      "step": 13740
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.8969042301177979,
      "learning_rate": 1.029914895436856e-05,
      "loss": 0.2535,
      "step": 13750
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2679780721664429,
      "learning_rate": 1.0288457426335373e-05,
      "loss": 0.3519,
      "step": 13760
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.2634357213974,
      "learning_rate": 1.0277765898302186e-05,
      "loss": 0.3072,
      "step": 13770
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.8203260898590088,
      "learning_rate": 1.0267074370268999e-05,
      "loss": 0.2424,
      "step": 13780
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.0629446506500244,
      "learning_rate": 1.0256382842235813e-05,
      "loss": 0.282,
      "step": 13790
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.536684274673462,
      "learning_rate": 1.0245691314202626e-05,
      "loss": 0.2475,
      "step": 13800
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3255248069763184,
      "learning_rate": 1.023499978616944e-05,
      "loss": 0.3409,
      "step": 13810
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.6080198884010315,
      "learning_rate": 1.0224308258136253e-05,
      "loss": 0.2359,
      "step": 13820
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.3682292699813843,
      "learning_rate": 1.0213616730103066e-05,
      "loss": 0.2851,
      "step": 13830
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.5914239287376404,
      "learning_rate": 1.0202925202069881e-05,
      "loss": 0.2589,
      "step": 13840
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.7421528697013855,
      "learning_rate": 1.0192233674036694e-05,
      "loss": 0.208,
      "step": 13850
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.7349880933761597,
      "learning_rate": 1.0181542146003507e-05,
      "loss": 0.3116,
      "step": 13860
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.4327486753463745,
      "learning_rate": 1.0170850617970321e-05,
      "loss": 0.2386,
      "step": 13870
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.4642992615699768,
      "learning_rate": 1.0160159089937134e-05,
      "loss": 0.1998,
      "step": 13880
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.258100986480713,
      "learning_rate": 1.0149467561903949e-05,
      "loss": 0.2297,
      "step": 13890
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5650568008422852,
      "learning_rate": 1.0138776033870762e-05,
      "loss": 0.3061,
      "step": 13900
    },
    {
      "epoch": 0.59,
      "grad_norm": 1.5970039367675781,
      "learning_rate": 1.0128084505837575e-05,
      "loss": 0.2475,
      "step": 13910
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.088095784187317,
      "learning_rate": 1.0117392977804388e-05,
      "loss": 0.2073,
      "step": 13920
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.3463103771209717,
      "learning_rate": 1.01067014497712e-05,
      "loss": 0.2937,
      "step": 13930
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1650015115737915,
      "learning_rate": 1.0096009921738015e-05,
      "loss": 0.2959,
      "step": 13940
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9344959259033203,
      "learning_rate": 1.008531839370483e-05,
      "loss": 0.3288,
      "step": 13950
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.07078218460083,
      "learning_rate": 1.0074626865671643e-05,
      "loss": 0.2281,
      "step": 13960
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2803857326507568,
      "learning_rate": 1.0063935337638455e-05,
      "loss": 0.2671,
      "step": 13970
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.020341396331787,
      "learning_rate": 1.0053243809605268e-05,
      "loss": 0.3048,
      "step": 13980
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.0374947786331177,
      "learning_rate": 1.0042552281572083e-05,
      "loss": 0.2545,
      "step": 13990
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.1783450841903687,
      "learning_rate": 1.0031860753538896e-05,
      "loss": 0.3212,
      "step": 14000
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.28568172454833984,
      "eval_runtime": 724.4594,
      "eval_samples_per_second": 3.623,
      "eval_steps_per_second": 3.623,
      "step": 14000
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.524078130722046,
      "learning_rate": 1.002116922550571e-05,
      "loss": 0.4334,
      "step": 14010
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8936148881912231,
      "learning_rate": 1.0010477697472523e-05,
      "loss": 0.3297,
      "step": 14020
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6102403402328491,
      "learning_rate": 9.999786169439338e-06,
      "loss": 0.2563,
      "step": 14030
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.9975719451904297,
      "learning_rate": 9.98909464140615e-06,
      "loss": 0.2681,
      "step": 14040
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.9601218700408936,
      "learning_rate": 9.978403113372964e-06,
      "loss": 0.281,
      "step": 14050
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.4198092222213745,
      "learning_rate": 9.967711585339777e-06,
      "loss": 0.2659,
      "step": 14060
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.8115490674972534,
      "learning_rate": 9.95702005730659e-06,
      "loss": 0.2622,
      "step": 14070
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4054194986820221,
      "learning_rate": 9.946328529273404e-06,
      "loss": 0.1891,
      "step": 14080
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.6250613331794739,
      "learning_rate": 9.935637001240219e-06,
      "loss": 0.2083,
      "step": 14090
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.3231582641601562,
      "learning_rate": 9.924945473207032e-06,
      "loss": 0.2915,
      "step": 14100
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.2368215322494507,
      "learning_rate": 9.914253945173844e-06,
      "loss": 0.2395,
      "step": 14110
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5760231614112854,
      "learning_rate": 9.903562417140657e-06,
      "loss": 0.2085,
      "step": 14120
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5169440507888794,
      "learning_rate": 9.892870889107472e-06,
      "loss": 0.2313,
      "step": 14130
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5533033013343811,
      "learning_rate": 9.882179361074285e-06,
      "loss": 0.1766,
      "step": 14140
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8049521446228027,
      "learning_rate": 9.8714878330411e-06,
      "loss": 0.3262,
      "step": 14150
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6558477878570557,
      "learning_rate": 9.860796305007912e-06,
      "loss": 0.3225,
      "step": 14160
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.547539710998535,
      "learning_rate": 9.850104776974725e-06,
      "loss": 0.2213,
      "step": 14170
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.299486517906189,
      "learning_rate": 9.83941324894154e-06,
      "loss": 0.2436,
      "step": 14180
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.240500569343567,
      "learning_rate": 9.828721720908353e-06,
      "loss": 0.36,
      "step": 14190
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4890427589416504,
      "learning_rate": 9.818030192875166e-06,
      "loss": 0.3397,
      "step": 14200
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.1673401594161987,
      "learning_rate": 9.80733866484198e-06,
      "loss": 0.3844,
      "step": 14210
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.526557445526123,
      "learning_rate": 9.796647136808793e-06,
      "loss": 0.2961,
      "step": 14220
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7744495272636414,
      "learning_rate": 9.785955608775608e-06,
      "loss": 0.2269,
      "step": 14230
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.017279028892517,
      "learning_rate": 9.77526408074242e-06,
      "loss": 0.2778,
      "step": 14240
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.3307360410690308,
      "learning_rate": 9.764572552709233e-06,
      "loss": 0.2652,
      "step": 14250
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.9835050106048584,
      "learning_rate": 9.753881024676046e-06,
      "loss": 0.4251,
      "step": 14260
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.7444770336151123,
      "learning_rate": 9.743189496642861e-06,
      "loss": 0.4155,
      "step": 14270
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9765080809593201,
      "learning_rate": 9.732497968609674e-06,
      "loss": 0.3598,
      "step": 14280
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.021905541419983,
      "learning_rate": 9.721806440576488e-06,
      "loss": 0.2744,
      "step": 14290
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2594578266143799,
      "learning_rate": 9.711114912543301e-06,
      "loss": 0.2869,
      "step": 14300
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.577490508556366,
      "learning_rate": 9.700423384510114e-06,
      "loss": 0.2658,
      "step": 14310
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.6074928045272827,
      "learning_rate": 9.689731856476929e-06,
      "loss": 0.302,
      "step": 14320
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.7348517179489136,
      "learning_rate": 9.679040328443742e-06,
      "loss": 0.251,
      "step": 14330
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.3154085874557495,
      "learning_rate": 9.668348800410555e-06,
      "loss": 0.2126,
      "step": 14340
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.9201337099075317,
      "learning_rate": 9.65765727237737e-06,
      "loss": 0.2918,
      "step": 14350
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.4696847200393677,
      "learning_rate": 9.646965744344182e-06,
      "loss": 0.2667,
      "step": 14360
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.8066143989562988,
      "learning_rate": 9.636274216310997e-06,
      "loss": 0.2475,
      "step": 14370
    },
    {
      "epoch": 0.61,
      "grad_norm": 1.2137576341629028,
      "learning_rate": 9.62558268827781e-06,
      "loss": 0.3338,
      "step": 14380
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.641977071762085,
      "learning_rate": 9.614891160244622e-06,
      "loss": 0.1935,
      "step": 14390
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.4105808138847351,
      "learning_rate": 9.604199632211435e-06,
      "loss": 0.2311,
      "step": 14400
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1240133047103882,
      "learning_rate": 9.593508104178248e-06,
      "loss": 0.253,
      "step": 14410
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8558523058891296,
      "learning_rate": 9.582816576145063e-06,
      "loss": 0.2446,
      "step": 14420
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9270945191383362,
      "learning_rate": 9.572125048111877e-06,
      "loss": 0.1567,
      "step": 14430
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3928089141845703,
      "learning_rate": 9.56143352007869e-06,
      "loss": 0.2218,
      "step": 14440
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4143332242965698,
      "learning_rate": 9.550741992045503e-06,
      "loss": 0.3017,
      "step": 14450
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.8082038164138794,
      "learning_rate": 9.540050464012316e-06,
      "loss": 0.2102,
      "step": 14460
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9417390823364258,
      "learning_rate": 9.52935893597913e-06,
      "loss": 0.243,
      "step": 14470
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9922715425491333,
      "learning_rate": 9.518667407945944e-06,
      "loss": 0.254,
      "step": 14480
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7445050477981567,
      "learning_rate": 9.507975879912758e-06,
      "loss": 0.2327,
      "step": 14490
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3041194677352905,
      "learning_rate": 9.497284351879571e-06,
      "loss": 0.2288,
      "step": 14500
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.1003551483154297,
      "learning_rate": 9.486592823846386e-06,
      "loss": 0.2899,
      "step": 14510
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.9816350340843201,
      "learning_rate": 9.475901295813199e-06,
      "loss": 0.3107,
      "step": 14520
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.3327507972717285,
      "learning_rate": 9.465209767780011e-06,
      "loss": 0.2617,
      "step": 14530
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.5683039426803589,
      "learning_rate": 9.454518239746824e-06,
      "loss": 0.2642,
      "step": 14540
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7973060607910156,
      "learning_rate": 9.443826711713637e-06,
      "loss": 0.3205,
      "step": 14550
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.6652307510375977,
      "learning_rate": 9.433135183680454e-06,
      "loss": 0.2445,
      "step": 14560
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.8369666337966919,
      "learning_rate": 9.422443655647266e-06,
      "loss": 0.2449,
      "step": 14570
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0838358402252197,
      "learning_rate": 9.41175212761408e-06,
      "loss": 0.2867,
      "step": 14580
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.6031412482261658,
      "learning_rate": 9.401060599580892e-06,
      "loss": 0.2916,
      "step": 14590
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.4140188694000244,
      "learning_rate": 9.390369071547705e-06,
      "loss": 0.2776,
      "step": 14600
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.7064476013183594,
      "learning_rate": 9.37967754351452e-06,
      "loss": 0.268,
      "step": 14610
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.6984526515007019,
      "learning_rate": 9.368986015481333e-06,
      "loss": 0.2456,
      "step": 14620
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.929290771484375,
      "learning_rate": 9.358294487448147e-06,
      "loss": 0.3345,
      "step": 14630
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3792154788970947,
      "learning_rate": 9.34760295941496e-06,
      "loss": 0.3632,
      "step": 14640
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6616376638412476,
      "learning_rate": 9.336911431381773e-06,
      "loss": 0.2484,
      "step": 14650
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.9666366577148438,
      "learning_rate": 9.326219903348588e-06,
      "loss": 0.3225,
      "step": 14660
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4586312770843506,
      "learning_rate": 9.3155283753154e-06,
      "loss": 0.2882,
      "step": 14670
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8420127630233765,
      "learning_rate": 9.304836847282213e-06,
      "loss": 0.3387,
      "step": 14680
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6266543865203857,
      "learning_rate": 9.294145319249028e-06,
      "loss": 0.2533,
      "step": 14690
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.084519386291504,
      "learning_rate": 9.283453791215841e-06,
      "loss": 0.2768,
      "step": 14700
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.7449173927307129,
      "learning_rate": 9.272762263182655e-06,
      "loss": 0.2571,
      "step": 14710
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6146538257598877,
      "learning_rate": 9.262070735149468e-06,
      "loss": 0.2683,
      "step": 14720
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0252535343170166,
      "learning_rate": 9.251379207116281e-06,
      "loss": 0.2527,
      "step": 14730
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.2575879096984863,
      "learning_rate": 9.240687679083094e-06,
      "loss": 0.2338,
      "step": 14740
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6287661790847778,
      "learning_rate": 9.229996151049909e-06,
      "loss": 0.2299,
      "step": 14750
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.8396592140197754,
      "learning_rate": 9.219304623016722e-06,
      "loss": 0.2983,
      "step": 14760
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6569551229476929,
      "learning_rate": 9.208613094983536e-06,
      "loss": 0.3047,
      "step": 14770
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.6723943948745728,
      "learning_rate": 9.197921566950349e-06,
      "loss": 0.3783,
      "step": 14780
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.3788098096847534,
      "learning_rate": 9.187230038917162e-06,
      "loss": 0.2649,
      "step": 14790
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.4192668199539185,
      "learning_rate": 9.176538510883977e-06,
      "loss": 0.334,
      "step": 14800
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.4973412752151489,
      "learning_rate": 9.16584698285079e-06,
      "loss": 0.2744,
      "step": 14810
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.1861329078674316,
      "learning_rate": 9.155155454817602e-06,
      "loss": 0.3123,
      "step": 14820
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.8043335676193237,
      "learning_rate": 9.144463926784417e-06,
      "loss": 0.2196,
      "step": 14830
    },
    {
      "epoch": 0.63,
      "grad_norm": 1.0542680025100708,
      "learning_rate": 9.13377239875123e-06,
      "loss": 0.2414,
      "step": 14840
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0333465337753296,
      "learning_rate": 9.123080870718044e-06,
      "loss": 0.2565,
      "step": 14850
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.1885613203048706,
      "learning_rate": 9.112389342684857e-06,
      "loss": 0.3163,
      "step": 14860
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.581654965877533,
      "learning_rate": 9.10169781465167e-06,
      "loss": 0.214,
      "step": 14870
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6048453450202942,
      "learning_rate": 9.091006286618483e-06,
      "loss": 0.2983,
      "step": 14880
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5735325813293457,
      "learning_rate": 9.080314758585296e-06,
      "loss": 0.3317,
      "step": 14890
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.7455854415893555,
      "learning_rate": 9.06962323055211e-06,
      "loss": 0.2534,
      "step": 14900
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0895622968673706,
      "learning_rate": 9.058931702518925e-06,
      "loss": 0.2136,
      "step": 14910
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5702235698699951,
      "learning_rate": 9.048240174485738e-06,
      "loss": 0.276,
      "step": 14920
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.5860484838485718,
      "learning_rate": 9.037548646452551e-06,
      "loss": 0.2666,
      "step": 14930
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.6659513711929321,
      "learning_rate": 9.026857118419364e-06,
      "loss": 0.2876,
      "step": 14940
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6673885583877563,
      "learning_rate": 9.016165590386178e-06,
      "loss": 0.2404,
      "step": 14950
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.688685417175293,
      "learning_rate": 9.005474062352991e-06,
      "loss": 0.2854,
      "step": 14960
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.720796823501587,
      "learning_rate": 8.994782534319806e-06,
      "loss": 0.2173,
      "step": 14970
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.397529125213623,
      "learning_rate": 8.984091006286619e-06,
      "loss": 0.2922,
      "step": 14980
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.22396047413349152,
      "learning_rate": 8.973399478253433e-06,
      "loss": 0.2728,
      "step": 14990
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0635597705841064,
      "learning_rate": 8.962707950220246e-06,
      "loss": 0.268,
      "step": 15000
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.28437885642051697,
      "eval_runtime": 725.118,
      "eval_samples_per_second": 3.62,
      "eval_steps_per_second": 3.62,
      "step": 15000
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.513645052909851,
      "learning_rate": 8.95201642218706e-06,
      "loss": 0.2556,
      "step": 15010
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0724984407424927,
      "learning_rate": 8.941324894153872e-06,
      "loss": 0.3331,
      "step": 15020
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.578676700592041,
      "learning_rate": 8.930633366120687e-06,
      "loss": 0.2881,
      "step": 15030
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0848708152770996,
      "learning_rate": 8.919941838087501e-06,
      "loss": 0.2547,
      "step": 15040
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.4382801055908203,
      "learning_rate": 8.909250310054314e-06,
      "loss": 0.3453,
      "step": 15050
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8959014415740967,
      "learning_rate": 8.898558782021127e-06,
      "loss": 0.239,
      "step": 15060
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.6240043640136719,
      "learning_rate": 8.88786725398794e-06,
      "loss": 0.2882,
      "step": 15070
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8244088292121887,
      "learning_rate": 8.877175725954753e-06,
      "loss": 0.2555,
      "step": 15080
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.734838604927063,
      "learning_rate": 8.866484197921568e-06,
      "loss": 0.2658,
      "step": 15090
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2601791620254517,
      "learning_rate": 8.85579266988838e-06,
      "loss": 0.1804,
      "step": 15100
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7996275424957275,
      "learning_rate": 8.845101141855195e-06,
      "loss": 0.2125,
      "step": 15110
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1702100038528442,
      "learning_rate": 8.834409613822008e-06,
      "loss": 0.2321,
      "step": 15120
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.331282377243042,
      "learning_rate": 8.82371808578882e-06,
      "loss": 0.243,
      "step": 15130
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8098249435424805,
      "learning_rate": 8.813026557755635e-06,
      "loss": 0.3547,
      "step": 15140
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7702208757400513,
      "learning_rate": 8.802335029722448e-06,
      "loss": 0.2651,
      "step": 15150
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8864209651947021,
      "learning_rate": 8.791643501689261e-06,
      "loss": 0.2887,
      "step": 15160
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.9551683068275452,
      "learning_rate": 8.780951973656076e-06,
      "loss": 0.2131,
      "step": 15170
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.7116152048110962,
      "learning_rate": 8.770260445622889e-06,
      "loss": 0.3279,
      "step": 15180
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.6629717350006104,
      "learning_rate": 8.759568917589703e-06,
      "loss": 0.2891,
      "step": 15190
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.2747759819030762,
      "learning_rate": 8.748877389556516e-06,
      "loss": 0.2046,
      "step": 15200
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4106781780719757,
      "learning_rate": 8.738185861523329e-06,
      "loss": 0.2833,
      "step": 15210
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.992921769618988,
      "learning_rate": 8.727494333490142e-06,
      "loss": 0.2136,
      "step": 15220
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.4198073744773865,
      "learning_rate": 8.716802805456957e-06,
      "loss": 0.3348,
      "step": 15230
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1878832578659058,
      "learning_rate": 8.70611127742377e-06,
      "loss": 0.2509,
      "step": 15240
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.8268302083015442,
      "learning_rate": 8.695419749390584e-06,
      "loss": 0.2256,
      "step": 15250
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5567193031311035,
      "learning_rate": 8.684728221357397e-06,
      "loss": 0.2802,
      "step": 15260
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7815147042274475,
      "learning_rate": 8.67403669332421e-06,
      "loss": 0.2003,
      "step": 15270
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4928635358810425,
      "learning_rate": 8.663345165291024e-06,
      "loss": 0.2327,
      "step": 15280
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.5355299711227417,
      "learning_rate": 8.652653637257837e-06,
      "loss": 0.263,
      "step": 15290
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.4012532234191895,
      "learning_rate": 8.64196210922465e-06,
      "loss": 0.2927,
      "step": 15300
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.3609552383422852,
      "learning_rate": 8.631270581191465e-06,
      "loss": 0.1812,
      "step": 15310
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.467421531677246,
      "learning_rate": 8.620579053158278e-06,
      "loss": 0.3053,
      "step": 15320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5414460897445679,
      "learning_rate": 8.609887525125092e-06,
      "loss": 0.3187,
      "step": 15330
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.734771728515625,
      "learning_rate": 8.599195997091905e-06,
      "loss": 0.3247,
      "step": 15340
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.355758547782898,
      "learning_rate": 8.588504469058718e-06,
      "loss": 0.2485,
      "step": 15350
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5582537651062012,
      "learning_rate": 8.577812941025531e-06,
      "loss": 0.2817,
      "step": 15360
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0321025848388672,
      "learning_rate": 8.567121412992344e-06,
      "loss": 0.246,
      "step": 15370
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.385475993156433,
      "learning_rate": 8.556429884959158e-06,
      "loss": 0.2279,
      "step": 15380
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1320533752441406,
      "learning_rate": 8.545738356925973e-06,
      "loss": 0.3448,
      "step": 15390
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.2290769815444946,
      "learning_rate": 8.535046828892786e-06,
      "loss": 0.3703,
      "step": 15400
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.4826769828796387,
      "learning_rate": 8.524355300859599e-06,
      "loss": 0.3062,
      "step": 15410
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.5145704746246338,
      "learning_rate": 8.513663772826412e-06,
      "loss": 0.2935,
      "step": 15420
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.422502875328064,
      "learning_rate": 8.502972244793226e-06,
      "loss": 0.2854,
      "step": 15430
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6103410720825195,
      "learning_rate": 8.49228071676004e-06,
      "loss": 0.2622,
      "step": 15440
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.9380178451538086,
      "learning_rate": 8.481589188726854e-06,
      "loss": 0.2454,
      "step": 15450
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6294391751289368,
      "learning_rate": 8.470897660693667e-06,
      "loss": 0.2895,
      "step": 15460
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.0028759241104126,
      "learning_rate": 8.460206132660481e-06,
      "loss": 0.2976,
      "step": 15470
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.4527121782302856,
      "learning_rate": 8.449514604627294e-06,
      "loss": 0.2364,
      "step": 15480
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.1290619373321533,
      "learning_rate": 8.438823076594107e-06,
      "loss": 0.2274,
      "step": 15490
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.6816926002502441,
      "learning_rate": 8.42813154856092e-06,
      "loss": 0.1854,
      "step": 15500
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.42577335238456726,
      "learning_rate": 8.417440020527735e-06,
      "loss": 0.2231,
      "step": 15510
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.6541588306427002,
      "learning_rate": 8.406748492494549e-06,
      "loss": 0.2584,
      "step": 15520
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8759567737579346,
      "learning_rate": 8.396056964461362e-06,
      "loss": 0.341,
      "step": 15530
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.813607096672058,
      "learning_rate": 8.385365436428175e-06,
      "loss": 0.2912,
      "step": 15540
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.1639060974121094,
      "learning_rate": 8.374673908394988e-06,
      "loss": 0.2621,
      "step": 15550
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.7351619005203247,
      "learning_rate": 8.3639823803618e-06,
      "loss": 0.2242,
      "step": 15560
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4281669855117798,
      "learning_rate": 8.353290852328615e-06,
      "loss": 0.2153,
      "step": 15570
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8418521881103516,
      "learning_rate": 8.342599324295428e-06,
      "loss": 0.3198,
      "step": 15580
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1627845764160156,
      "learning_rate": 8.331907796262243e-06,
      "loss": 0.2677,
      "step": 15590
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1741573810577393,
      "learning_rate": 8.321216268229056e-06,
      "loss": 0.3021,
      "step": 15600
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.8926565647125244,
      "learning_rate": 8.310524740195869e-06,
      "loss": 0.2674,
      "step": 15610
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3018664121627808,
      "learning_rate": 8.299833212162683e-06,
      "loss": 0.2676,
      "step": 15620
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0577726364135742,
      "learning_rate": 8.289141684129496e-06,
      "loss": 0.2334,
      "step": 15630
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.0688176155090332,
      "learning_rate": 8.278450156096309e-06,
      "loss": 0.2257,
      "step": 15640
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.5763875246047974,
      "learning_rate": 8.267758628063124e-06,
      "loss": 0.3243,
      "step": 15650
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4031733274459839,
      "learning_rate": 8.257067100029936e-06,
      "loss": 0.2593,
      "step": 15660
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1910873651504517,
      "learning_rate": 8.246375571996751e-06,
      "loss": 0.2545,
      "step": 15670
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4505400657653809,
      "learning_rate": 8.235684043963564e-06,
      "loss": 0.2632,
      "step": 15680
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1138726472854614,
      "learning_rate": 8.224992515930377e-06,
      "loss": 0.2372,
      "step": 15690
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.35006654262542725,
      "learning_rate": 8.21430098789719e-06,
      "loss": 0.2521,
      "step": 15700
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.08748684823513031,
      "learning_rate": 8.203609459864004e-06,
      "loss": 0.1722,
      "step": 15710
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.412725806236267,
      "learning_rate": 8.192917931830817e-06,
      "loss": 0.3096,
      "step": 15720
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.1667555570602417,
      "learning_rate": 8.182226403797632e-06,
      "loss": 0.2169,
      "step": 15730
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.4237066507339478,
      "learning_rate": 8.171534875764445e-06,
      "loss": 0.2691,
      "step": 15740
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.9538145065307617,
      "learning_rate": 8.160843347731258e-06,
      "loss": 0.2871,
      "step": 15750
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3144102096557617,
      "learning_rate": 8.150151819698072e-06,
      "loss": 0.3488,
      "step": 15760
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3611897230148315,
      "learning_rate": 8.139460291664885e-06,
      "loss": 0.3303,
      "step": 15770
    },
    {
      "epoch": 0.67,
      "grad_norm": 1.3799595832824707,
      "learning_rate": 8.128768763631698e-06,
      "loss": 0.219,
      "step": 15780
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.668034315109253,
      "learning_rate": 8.118077235598513e-06,
      "loss": 0.2388,
      "step": 15790
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5971308946609497,
      "learning_rate": 8.107385707565325e-06,
      "loss": 0.2627,
      "step": 15800
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0657904148101807,
      "learning_rate": 8.09669417953214e-06,
      "loss": 0.3738,
      "step": 15810
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5219871997833252,
      "learning_rate": 8.086002651498953e-06,
      "loss": 0.2712,
      "step": 15820
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3576066493988037,
      "learning_rate": 8.075311123465766e-06,
      "loss": 0.2269,
      "step": 15830
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.46663615107536316,
      "learning_rate": 8.064619595432579e-06,
      "loss": 0.2637,
      "step": 15840
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.303505778312683,
      "learning_rate": 8.053928067399392e-06,
      "loss": 0.2567,
      "step": 15850
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.4887677431106567,
      "learning_rate": 8.043236539366206e-06,
      "loss": 0.2349,
      "step": 15860
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.1590794324874878,
      "learning_rate": 8.03254501133302e-06,
      "loss": 0.1811,
      "step": 15870
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2042158842086792,
      "learning_rate": 8.021853483299834e-06,
      "loss": 0.2798,
      "step": 15880
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3485026359558105,
      "learning_rate": 8.011161955266647e-06,
      "loss": 0.25,
      "step": 15890
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0724091529846191,
      "learning_rate": 8.00047042723346e-06,
      "loss": 0.2773,
      "step": 15900
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.3222469091415405,
      "learning_rate": 7.989778899200274e-06,
      "loss": 0.2995,
      "step": 15910
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6721364259719849,
      "learning_rate": 7.979087371167087e-06,
      "loss": 0.2624,
      "step": 15920
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.2429472208023071,
      "learning_rate": 7.968395843133902e-06,
      "loss": 0.3154,
      "step": 15930
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0873665809631348,
      "learning_rate": 7.957704315100714e-06,
      "loss": 0.3274,
      "step": 15940
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.505881667137146,
      "learning_rate": 7.947012787067529e-06,
      "loss": 0.3024,
      "step": 15950
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.270854115486145,
      "learning_rate": 7.936321259034342e-06,
      "loss": 0.2678,
      "step": 15960
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.057631015777588,
      "learning_rate": 7.925629731001155e-06,
      "loss": 0.2458,
      "step": 15970
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.0892575979232788,
      "learning_rate": 7.914938202967968e-06,
      "loss": 0.26,
      "step": 15980
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.5207908153533936,
      "learning_rate": 7.904246674934782e-06,
      "loss": 0.3445,
      "step": 15990
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.260044127702713,
      "learning_rate": 7.893555146901597e-06,
      "loss": 0.243,
      "step": 16000
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.28331151604652405,
      "eval_runtime": 725.4956,
      "eval_samples_per_second": 3.618,
      "eval_steps_per_second": 3.618,
      "step": 16000
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.7562625408172607,
      "learning_rate": 7.88286361886841e-06,
      "loss": 0.3162,
      "step": 16010
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.345934271812439,
      "learning_rate": 7.872172090835223e-06,
      "loss": 0.2931,
      "step": 16020
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4966931343078613,
      "learning_rate": 7.861480562802036e-06,
      "loss": 0.3202,
      "step": 16030
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.870701014995575,
      "learning_rate": 7.850789034768849e-06,
      "loss": 0.2207,
      "step": 16040
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.625737190246582,
      "learning_rate": 7.840097506735663e-06,
      "loss": 0.3443,
      "step": 16050
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.0116320848464966,
      "learning_rate": 7.829405978702476e-06,
      "loss": 0.2401,
      "step": 16060
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4225465059280396,
      "learning_rate": 7.81871445066929e-06,
      "loss": 0.2843,
      "step": 16070
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.431636929512024,
      "learning_rate": 7.808022922636103e-06,
      "loss": 0.3309,
      "step": 16080
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.6509156823158264,
      "learning_rate": 7.797331394602916e-06,
      "loss": 0.3032,
      "step": 16090
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3334473371505737,
      "learning_rate": 7.786639866569731e-06,
      "loss": 0.277,
      "step": 16100
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9514261484146118,
      "learning_rate": 7.775948338536544e-06,
      "loss": 0.2781,
      "step": 16110
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.3709739446640015,
      "learning_rate": 7.765256810503357e-06,
      "loss": 0.1887,
      "step": 16120
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6061532497406006,
      "learning_rate": 7.754565282470171e-06,
      "loss": 0.3095,
      "step": 16130
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.838525652885437,
      "learning_rate": 7.743873754436984e-06,
      "loss": 0.2067,
      "step": 16140
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.6846084594726562,
      "learning_rate": 7.733182226403799e-06,
      "loss": 0.3684,
      "step": 16150
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.8462849855422974,
      "learning_rate": 7.722490698370612e-06,
      "loss": 0.2835,
      "step": 16160
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.1211297512054443,
      "learning_rate": 7.711799170337425e-06,
      "loss": 0.2635,
      "step": 16170
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.1077930927276611,
      "learning_rate": 7.701107642304238e-06,
      "loss": 0.3094,
      "step": 16180
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.5570545196533203,
      "learning_rate": 7.690416114271052e-06,
      "loss": 0.1732,
      "step": 16190
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9120204448699951,
      "learning_rate": 7.679724586237865e-06,
      "loss": 0.2673,
      "step": 16200
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.9987232685089111,
      "learning_rate": 7.66903305820468e-06,
      "loss": 0.3162,
      "step": 16210
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.185995101928711,
      "learning_rate": 7.658341530171493e-06,
      "loss": 0.1953,
      "step": 16220
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.115384578704834,
      "learning_rate": 7.647650002138305e-06,
      "loss": 0.2795,
      "step": 16230
    },
    {
      "epoch": 0.69,
      "grad_norm": 1.4279825687408447,
      "learning_rate": 7.63695847410512e-06,
      "loss": 0.3198,
      "step": 16240
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.7727551460266113,
      "learning_rate": 7.626266946071933e-06,
      "loss": 0.1791,
      "step": 16250
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.111930012702942,
      "learning_rate": 7.615575418038747e-06,
      "loss": 0.1609,
      "step": 16260
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2772401571273804,
      "learning_rate": 7.6048838900055595e-06,
      "loss": 0.2285,
      "step": 16270
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4833557605743408,
      "learning_rate": 7.594192361972373e-06,
      "loss": 0.3629,
      "step": 16280
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.148733139038086,
      "learning_rate": 7.583500833939188e-06,
      "loss": 0.3316,
      "step": 16290
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7273215055465698,
      "learning_rate": 7.572809305906001e-06,
      "loss": 0.2467,
      "step": 16300
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3998558521270752,
      "learning_rate": 7.562117777872814e-06,
      "loss": 0.3375,
      "step": 16310
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7394685745239258,
      "learning_rate": 7.551426249839627e-06,
      "loss": 0.2817,
      "step": 16320
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8543031215667725,
      "learning_rate": 7.54073472180644e-06,
      "loss": 0.3229,
      "step": 16330
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.2623634338378906,
      "learning_rate": 7.530043193773255e-06,
      "loss": 0.2761,
      "step": 16340
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8163831233978271,
      "learning_rate": 7.519351665740068e-06,
      "loss": 0.2069,
      "step": 16350
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9632366895675659,
      "learning_rate": 7.5086601377068815e-06,
      "loss": 0.2492,
      "step": 16360
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.8275055885314941,
      "learning_rate": 7.497968609673694e-06,
      "loss": 0.3063,
      "step": 16370
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.9849192500114441,
      "learning_rate": 7.487277081640507e-06,
      "loss": 0.2323,
      "step": 16380
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5248016119003296,
      "learning_rate": 7.476585553607322e-06,
      "loss": 0.2007,
      "step": 16390
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3257591724395752,
      "learning_rate": 7.465894025574136e-06,
      "loss": 0.3133,
      "step": 16400
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7025784254074097,
      "learning_rate": 7.4552024975409485e-06,
      "loss": 0.2533,
      "step": 16410
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5280382633209229,
      "learning_rate": 7.444510969507762e-06,
      "loss": 0.3578,
      "step": 16420
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.4710984230041504,
      "learning_rate": 7.433819441474577e-06,
      "loss": 0.2613,
      "step": 16430
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3103187084197998,
      "learning_rate": 7.42312791344139e-06,
      "loss": 0.3518,
      "step": 16440
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1157431602478027,
      "learning_rate": 7.412436385408203e-06,
      "loss": 0.2789,
      "step": 16450
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7345497608184814,
      "learning_rate": 7.401744857375016e-06,
      "loss": 0.2528,
      "step": 16460
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.3827546834945679,
      "learning_rate": 7.391053329341829e-06,
      "loss": 0.2671,
      "step": 16470
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7863246202468872,
      "learning_rate": 7.380361801308644e-06,
      "loss": 0.3351,
      "step": 16480
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.0652037858963013,
      "learning_rate": 7.369670273275457e-06,
      "loss": 0.3173,
      "step": 16490
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.960849642753601,
      "learning_rate": 7.3589787452422705e-06,
      "loss": 0.2782,
      "step": 16500
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.6677004098892212,
      "learning_rate": 7.3482872172090834e-06,
      "loss": 0.2801,
      "step": 16510
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.3960629999637604,
      "learning_rate": 7.337595689175897e-06,
      "loss": 0.2802,
      "step": 16520
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3435742855072021,
      "learning_rate": 7.326904161142712e-06,
      "loss": 0.2685,
      "step": 16530
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.45319402217865,
      "learning_rate": 7.316212633109525e-06,
      "loss": 0.2582,
      "step": 16540
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.552150011062622,
      "learning_rate": 7.3055211050763376e-06,
      "loss": 0.2025,
      "step": 16550
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4515620470046997,
      "learning_rate": 7.294829577043151e-06,
      "loss": 0.3147,
      "step": 16560
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3934032917022705,
      "learning_rate": 7.284138049009964e-06,
      "loss": 0.2415,
      "step": 16570
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.7596319317817688,
      "learning_rate": 7.273446520976779e-06,
      "loss": 0.2249,
      "step": 16580
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5651285648345947,
      "learning_rate": 7.262754992943592e-06,
      "loss": 0.3021,
      "step": 16590
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.6495565176010132,
      "learning_rate": 7.2520634649104054e-06,
      "loss": 0.233,
      "step": 16600
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.462274432182312,
      "learning_rate": 7.241371936877218e-06,
      "loss": 0.1742,
      "step": 16610
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.339796543121338,
      "learning_rate": 7.230680408844033e-06,
      "loss": 0.2792,
      "step": 16620
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.7782492637634277,
      "learning_rate": 7.219988880810847e-06,
      "loss": 0.3628,
      "step": 16630
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.5089490413665771,
      "learning_rate": 7.2092973527776596e-06,
      "loss": 0.3336,
      "step": 16640
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.109879970550537,
      "learning_rate": 7.1986058247444724e-06,
      "loss": 0.2545,
      "step": 16650
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.2111417055130005,
      "learning_rate": 7.187914296711286e-06,
      "loss": 0.2137,
      "step": 16660
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.8545695543289185,
      "learning_rate": 7.177222768678101e-06,
      "loss": 0.3883,
      "step": 16670
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.3440911769866943,
      "learning_rate": 7.166531240644914e-06,
      "loss": 0.2422,
      "step": 16680
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.1524708271026611,
      "learning_rate": 7.1558397126117266e-06,
      "loss": 0.3335,
      "step": 16690
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.4967660903930664,
      "learning_rate": 7.14514818457854e-06,
      "loss": 0.2958,
      "step": 16700
    },
    {
      "epoch": 0.71,
      "grad_norm": 1.9980436563491821,
      "learning_rate": 7.134456656545353e-06,
      "loss": 0.259,
      "step": 16710
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.552362084388733,
      "learning_rate": 7.123765128512168e-06,
      "loss": 0.2655,
      "step": 16720
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.598483920097351,
      "learning_rate": 7.113073600478981e-06,
      "loss": 0.2923,
      "step": 16730
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3273662328720093,
      "learning_rate": 7.1023820724457944e-06,
      "loss": 0.2292,
      "step": 16740
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0416781902313232,
      "learning_rate": 7.091690544412607e-06,
      "loss": 0.2621,
      "step": 16750
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.1339530944824219,
      "learning_rate": 7.080999016379421e-06,
      "loss": 0.2979,
      "step": 16760
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.5829472541809082,
      "learning_rate": 7.070307488346236e-06,
      "loss": 0.2589,
      "step": 16770
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.082724690437317,
      "learning_rate": 7.0596159603130486e-06,
      "loss": 0.2782,
      "step": 16780
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7554551362991333,
      "learning_rate": 7.0489244322798615e-06,
      "loss": 0.3032,
      "step": 16790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7307656407356262,
      "learning_rate": 7.038232904246675e-06,
      "loss": 0.2912,
      "step": 16800
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4283900558948517,
      "learning_rate": 7.027541376213488e-06,
      "loss": 0.2301,
      "step": 16810
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8512189388275146,
      "learning_rate": 7.016849848180303e-06,
      "loss": 0.3162,
      "step": 16820
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7733767628669739,
      "learning_rate": 7.006158320147116e-06,
      "loss": 0.2526,
      "step": 16830
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3180809020996094,
      "learning_rate": 6.995466792113929e-06,
      "loss": 0.304,
      "step": 16840
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.9411458373069763,
      "learning_rate": 6.984775264080742e-06,
      "loss": 0.2483,
      "step": 16850
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4274362325668335,
      "learning_rate": 6.974083736047557e-06,
      "loss": 0.2895,
      "step": 16860
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.5330219268798828,
      "learning_rate": 6.9633922080143706e-06,
      "loss": 0.3237,
      "step": 16870
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.3733952045440674,
      "learning_rate": 6.9527006799811835e-06,
      "loss": 0.2302,
      "step": 16880
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7584679126739502,
      "learning_rate": 6.942009151947996e-06,
      "loss": 0.1393,
      "step": 16890
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4547606706619263,
      "learning_rate": 6.93131762391481e-06,
      "loss": 0.4434,
      "step": 16900
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7756198644638062,
      "learning_rate": 6.920626095881625e-06,
      "loss": 0.2481,
      "step": 16910
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.4046207666397095,
      "learning_rate": 6.909934567848438e-06,
      "loss": 0.2637,
      "step": 16920
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7403382062911987,
      "learning_rate": 6.8992430398152505e-06,
      "loss": 0.2551,
      "step": 16930
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.6513488292694092,
      "learning_rate": 6.888551511782064e-06,
      "loss": 0.267,
      "step": 16940
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.981141209602356,
      "learning_rate": 6.877859983748877e-06,
      "loss": 0.3149,
      "step": 16950
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.587557315826416,
      "learning_rate": 6.867168455715692e-06,
      "loss": 0.2752,
      "step": 16960
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.423572063446045,
      "learning_rate": 6.856476927682505e-06,
      "loss": 0.3142,
      "step": 16970
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4907152652740479,
      "learning_rate": 6.845785399649318e-06,
      "loss": 0.2302,
      "step": 16980
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.5867573022842407,
      "learning_rate": 6.835093871616131e-06,
      "loss": 0.2678,
      "step": 16990
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.1766605377197266,
      "learning_rate": 6.824402343582945e-06,
      "loss": 0.2637,
      "step": 17000
    },
    {
      "epoch": 0.73,
      "eval_loss": 0.2820214033126831,
      "eval_runtime": 727.5205,
      "eval_samples_per_second": 3.608,
      "eval_steps_per_second": 3.608,
      "step": 17000
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6134331226348877,
      "learning_rate": 6.8137108155497596e-06,
      "loss": 0.2563,
      "step": 17010
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.8724571466445923,
      "learning_rate": 6.8030192875165725e-06,
      "loss": 0.2699,
      "step": 17020
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6675009727478027,
      "learning_rate": 6.792327759483385e-06,
      "loss": 0.3396,
      "step": 17030
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3739118576049805,
      "learning_rate": 6.781636231450199e-06,
      "loss": 0.2602,
      "step": 17040
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.5296533107757568,
      "learning_rate": 6.770944703417012e-06,
      "loss": 0.321,
      "step": 17050
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7172380685806274,
      "learning_rate": 6.760253175383827e-06,
      "loss": 0.3281,
      "step": 17060
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0067393779754639,
      "learning_rate": 6.7495616473506395e-06,
      "loss": 0.2112,
      "step": 17070
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.6408286094665527,
      "learning_rate": 6.738870119317453e-06,
      "loss": 0.263,
      "step": 17080
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.0741021633148193,
      "learning_rate": 6.728178591284266e-06,
      "loss": 0.2141,
      "step": 17090
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.9130356311798096,
      "learning_rate": 6.717487063251081e-06,
      "loss": 0.2707,
      "step": 17100
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.6322886943817139,
      "learning_rate": 6.7067955352178945e-06,
      "loss": 0.2543,
      "step": 17110
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.3644626140594482,
      "learning_rate": 6.696104007184707e-06,
      "loss": 0.201,
      "step": 17120
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.5050878524780273,
      "learning_rate": 6.68541247915152e-06,
      "loss": 0.3911,
      "step": 17130
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.7086361646652222,
      "learning_rate": 6.674720951118334e-06,
      "loss": 0.277,
      "step": 17140
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.2378696203231812,
      "learning_rate": 6.664029423085149e-06,
      "loss": 0.2659,
      "step": 17150
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.28878676891326904,
      "learning_rate": 6.6533378950519615e-06,
      "loss": 0.2127,
      "step": 17160
    },
    {
      "epoch": 0.73,
      "grad_norm": 1.4712361097335815,
      "learning_rate": 6.642646367018774e-06,
      "loss": 0.2849,
      "step": 17170
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.8184759020805359,
      "learning_rate": 6.631954838985588e-06,
      "loss": 0.2217,
      "step": 17180
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2751189470291138,
      "learning_rate": 6.621263310952401e-06,
      "loss": 0.3138,
      "step": 17190
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2277837991714478,
      "learning_rate": 6.610571782919216e-06,
      "loss": 0.224,
      "step": 17200
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3977444171905518,
      "learning_rate": 6.5998802548860285e-06,
      "loss": 0.3214,
      "step": 17210
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.5280158519744873,
      "learning_rate": 6.589188726852842e-06,
      "loss": 0.2201,
      "step": 17220
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7390294075012207,
      "learning_rate": 6.578497198819655e-06,
      "loss": 0.3945,
      "step": 17230
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.847938060760498,
      "learning_rate": 6.567805670786469e-06,
      "loss": 0.2649,
      "step": 17240
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.2361197471618652,
      "learning_rate": 6.5571141427532835e-06,
      "loss": 0.2751,
      "step": 17250
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4194788932800293,
      "learning_rate": 6.546422614720096e-06,
      "loss": 0.3102,
      "step": 17260
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.3365349769592285,
      "learning_rate": 6.535731086686909e-06,
      "loss": 0.2748,
      "step": 17270
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6227434873580933,
      "learning_rate": 6.525039558653723e-06,
      "loss": 0.1697,
      "step": 17280
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4761158227920532,
      "learning_rate": 6.514348030620536e-06,
      "loss": 0.2092,
      "step": 17290
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.452365517616272,
      "learning_rate": 6.5036565025873505e-06,
      "loss": 0.2856,
      "step": 17300
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.4888577461242676,
      "learning_rate": 6.492964974554163e-06,
      "loss": 0.2906,
      "step": 17310
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0541887283325195,
      "learning_rate": 6.482273446520977e-06,
      "loss": 0.2329,
      "step": 17320
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.525460958480835,
      "learning_rate": 6.47158191848779e-06,
      "loss": 0.2906,
      "step": 17330
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.344924807548523,
      "learning_rate": 6.460890390454605e-06,
      "loss": 0.2448,
      "step": 17340
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.531410813331604,
      "learning_rate": 6.450198862421418e-06,
      "loss": 0.2766,
      "step": 17350
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.5645554065704346,
      "learning_rate": 6.439507334388231e-06,
      "loss": 0.3127,
      "step": 17360
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0429326295852661,
      "learning_rate": 6.428815806355044e-06,
      "loss": 0.2903,
      "step": 17370
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.444632887840271,
      "learning_rate": 6.418124278321858e-06,
      "loss": 0.3159,
      "step": 17380
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7301841974258423,
      "learning_rate": 6.4074327502886725e-06,
      "loss": 0.3094,
      "step": 17390
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.7571852207183838,
      "learning_rate": 6.396741222255485e-06,
      "loss": 0.2968,
      "step": 17400
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.6029530763626099,
      "learning_rate": 6.386049694222298e-06,
      "loss": 0.311,
      "step": 17410
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.425225853919983,
      "learning_rate": 6.375358166189112e-06,
      "loss": 0.2154,
      "step": 17420
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6350953578948975,
      "learning_rate": 6.364666638155925e-06,
      "loss": 0.2167,
      "step": 17430
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.014453887939453,
      "learning_rate": 6.3539751101227395e-06,
      "loss": 0.3004,
      "step": 17440
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2577359676361084,
      "learning_rate": 6.343283582089552e-06,
      "loss": 0.318,
      "step": 17450
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3385210037231445,
      "learning_rate": 6.332592054056366e-06,
      "loss": 0.2435,
      "step": 17460
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6101685762405396,
      "learning_rate": 6.321900526023179e-06,
      "loss": 0.2659,
      "step": 17470
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.2299684286117554,
      "learning_rate": 6.311208997989993e-06,
      "loss": 0.2579,
      "step": 17480
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4631069898605347,
      "learning_rate": 6.300517469956807e-06,
      "loss": 0.2345,
      "step": 17490
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.5958843231201172,
      "learning_rate": 6.28982594192362e-06,
      "loss": 0.2753,
      "step": 17500
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.75363689661026,
      "learning_rate": 6.279134413890433e-06,
      "loss": 0.2647,
      "step": 17510
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.8319271802902222,
      "learning_rate": 6.268442885857247e-06,
      "loss": 0.2161,
      "step": 17520
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1227954626083374,
      "learning_rate": 6.25775135782406e-06,
      "loss": 0.2148,
      "step": 17530
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6076189279556274,
      "learning_rate": 6.2470598297908735e-06,
      "loss": 0.2254,
      "step": 17540
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.8326496481895447,
      "learning_rate": 6.236368301757687e-06,
      "loss": 0.2329,
      "step": 17550
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0561809539794922,
      "learning_rate": 6.225676773724501e-06,
      "loss": 0.2667,
      "step": 17560
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.6364758014678955,
      "learning_rate": 6.214985245691315e-06,
      "loss": 0.2686,
      "step": 17570
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.549539566040039,
      "learning_rate": 6.204293717658128e-06,
      "loss": 0.2376,
      "step": 17580
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.4841638803482056,
      "learning_rate": 6.193602189624941e-06,
      "loss": 0.2122,
      "step": 17590
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.3772845268249512,
      "learning_rate": 6.182910661591755e-06,
      "loss": 0.2454,
      "step": 17600
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.1783114671707153,
      "learning_rate": 6.172219133558568e-06,
      "loss": 0.2804,
      "step": 17610
    },
    {
      "epoch": 0.75,
      "grad_norm": 1.0790706872940063,
      "learning_rate": 6.161527605525382e-06,
      "loss": 0.2553,
      "step": 17620
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.556152880191803,
      "learning_rate": 6.1508360774921955e-06,
      "loss": 0.3238,
      "step": 17630
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.699195921421051,
      "learning_rate": 6.140144549459009e-06,
      "loss": 0.2442,
      "step": 17640
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.48245784640312195,
      "learning_rate": 6.129453021425822e-06,
      "loss": 0.2371,
      "step": 17650
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.24577142298221588,
      "learning_rate": 6.118761493392636e-06,
      "loss": 0.2631,
      "step": 17660
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4465044736862183,
      "learning_rate": 6.10806996535945e-06,
      "loss": 0.2716,
      "step": 17670
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5131734609603882,
      "learning_rate": 6.0973784373262626e-06,
      "loss": 0.317,
      "step": 17680
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3493348360061646,
      "learning_rate": 6.086686909293076e-06,
      "loss": 0.2691,
      "step": 17690
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.9181902408599854,
      "learning_rate": 6.07599538125989e-06,
      "loss": 0.2265,
      "step": 17700
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.298422932624817,
      "learning_rate": 6.065303853226703e-06,
      "loss": 0.281,
      "step": 17710
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4777404069900513,
      "learning_rate": 6.054612325193517e-06,
      "loss": 0.2878,
      "step": 17720
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.17796920239925385,
      "learning_rate": 6.0439207971603304e-06,
      "loss": 0.2802,
      "step": 17730
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7858997583389282,
      "learning_rate": 6.033229269127144e-06,
      "loss": 0.2854,
      "step": 17740
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4680688381195068,
      "learning_rate": 6.022537741093957e-06,
      "loss": 0.3127,
      "step": 17750
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4348810911178589,
      "learning_rate": 6.011846213060772e-06,
      "loss": 0.2214,
      "step": 17760
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8669999837875366,
      "learning_rate": 6.0011546850275846e-06,
      "loss": 0.2977,
      "step": 17770
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3835127353668213,
      "learning_rate": 5.9904631569943975e-06,
      "loss": 0.2959,
      "step": 17780
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.1459161341190338,
      "learning_rate": 5.979771628961211e-06,
      "loss": 0.284,
      "step": 17790
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.34873297810554504,
      "learning_rate": 5.969080100928025e-06,
      "loss": 0.2076,
      "step": 17800
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4953603446483612,
      "learning_rate": 5.958388572894839e-06,
      "loss": 0.1894,
      "step": 17810
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.5037516355514526,
      "learning_rate": 5.947697044861652e-06,
      "loss": 0.3002,
      "step": 17820
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.4168676137924194,
      "learning_rate": 5.937005516828465e-06,
      "loss": 0.3252,
      "step": 17830
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.7141263484954834,
      "learning_rate": 5.926313988795279e-06,
      "loss": 0.2514,
      "step": 17840
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.46694108843803406,
      "learning_rate": 5.915622460762092e-06,
      "loss": 0.1569,
      "step": 17850
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.070002794265747,
      "learning_rate": 5.904930932728906e-06,
      "loss": 0.321,
      "step": 17860
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6978471875190735,
      "learning_rate": 5.8942394046957194e-06,
      "loss": 0.2425,
      "step": 17870
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.36733949184417725,
      "learning_rate": 5.883547876662533e-06,
      "loss": 0.2707,
      "step": 17880
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5369586944580078,
      "learning_rate": 5.872856348629346e-06,
      "loss": 0.3399,
      "step": 17890
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7792127132415771,
      "learning_rate": 5.86216482059616e-06,
      "loss": 0.205,
      "step": 17900
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.1946344375610352,
      "learning_rate": 5.8514732925629736e-06,
      "loss": 0.2494,
      "step": 17910
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.4753875434398651,
      "learning_rate": 5.8407817645297865e-06,
      "loss": 0.3015,
      "step": 17920
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8695874214172363,
      "learning_rate": 5.830090236496601e-06,
      "loss": 0.3162,
      "step": 17930
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.389681100845337,
      "learning_rate": 5.819398708463414e-06,
      "loss": 0.2136,
      "step": 17940
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5513501167297363,
      "learning_rate": 5.808707180430227e-06,
      "loss": 0.2304,
      "step": 17950
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2427436113357544,
      "learning_rate": 5.798015652397041e-06,
      "loss": 0.2637,
      "step": 17960
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.366276741027832,
      "learning_rate": 5.787324124363854e-06,
      "loss": 0.3129,
      "step": 17970
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.813937246799469,
      "learning_rate": 5.776632596330668e-06,
      "loss": 0.2374,
      "step": 17980
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.061448335647583,
      "learning_rate": 5.765941068297481e-06,
      "loss": 0.3075,
      "step": 17990
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6732263565063477,
      "learning_rate": 5.7552495402642956e-06,
      "loss": 0.3044,
      "step": 18000
    },
    {
      "epoch": 0.77,
      "eval_loss": 0.28148090839385986,
      "eval_runtime": 723.9744,
      "eval_samples_per_second": 3.626,
      "eval_steps_per_second": 3.626,
      "step": 18000
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8169238567352295,
      "learning_rate": 5.7445580122311085e-06,
      "loss": 0.2259,
      "step": 18010
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6639877557754517,
      "learning_rate": 5.733866484197921e-06,
      "loss": 0.286,
      "step": 18020
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.2574822902679443,
      "learning_rate": 5.723174956164735e-06,
      "loss": 0.2636,
      "step": 18030
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.336854100227356,
      "learning_rate": 5.712483428131549e-06,
      "loss": 0.2809,
      "step": 18040
    },
    {
      "epoch": 0.77,
      "grad_norm": 2.0704808235168457,
      "learning_rate": 5.701791900098363e-06,
      "loss": 0.2267,
      "step": 18050
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.7422277927398682,
      "learning_rate": 5.6911003720651755e-06,
      "loss": 0.2652,
      "step": 18060
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4742006063461304,
      "learning_rate": 5.680408844031989e-06,
      "loss": 0.2895,
      "step": 18070
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.4797508716583252,
      "learning_rate": 5.669717315998803e-06,
      "loss": 0.2652,
      "step": 18080
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.639237403869629,
      "learning_rate": 5.659025787965616e-06,
      "loss": 0.2731,
      "step": 18090
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.6747946739196777,
      "learning_rate": 5.64833425993243e-06,
      "loss": 0.2824,
      "step": 18100
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.0646374225616455,
      "learning_rate": 5.637642731899243e-06,
      "loss": 0.1898,
      "step": 18110
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.5693702697753906,
      "learning_rate": 5.626951203866057e-06,
      "loss": 0.2151,
      "step": 18120
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5065871477127075,
      "learning_rate": 5.61625967583287e-06,
      "loss": 0.3228,
      "step": 18130
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4651265144348145,
      "learning_rate": 5.605568147799684e-06,
      "loss": 0.3345,
      "step": 18140
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4482052326202393,
      "learning_rate": 5.5948766197664975e-06,
      "loss": 0.2678,
      "step": 18150
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.204856038093567,
      "learning_rate": 5.58418509173331e-06,
      "loss": 0.2055,
      "step": 18160
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.418346881866455,
      "learning_rate": 5.573493563700125e-06,
      "loss": 0.293,
      "step": 18170
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.143961787223816,
      "learning_rate": 5.562802035666938e-06,
      "loss": 0.274,
      "step": 18180
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.0562467575073242,
      "learning_rate": 5.552110507633751e-06,
      "loss": 0.284,
      "step": 18190
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.547081470489502,
      "learning_rate": 5.5414189796005645e-06,
      "loss": 0.2294,
      "step": 18200
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5345153212547302,
      "learning_rate": 5.530727451567378e-06,
      "loss": 0.2832,
      "step": 18210
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.7331386804580688,
      "learning_rate": 5.520035923534192e-06,
      "loss": 0.3029,
      "step": 18220
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5370285511016846,
      "learning_rate": 5.509344395501005e-06,
      "loss": 0.3337,
      "step": 18230
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8212000131607056,
      "learning_rate": 5.4986528674678195e-06,
      "loss": 0.272,
      "step": 18240
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.2140369415283203,
      "learning_rate": 5.487961339434632e-06,
      "loss": 0.3268,
      "step": 18250
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.6761475801467896,
      "learning_rate": 5.477269811401445e-06,
      "loss": 0.2417,
      "step": 18260
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.44355088472366333,
      "learning_rate": 5.466578283368259e-06,
      "loss": 0.3128,
      "step": 18270
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1448158025741577,
      "learning_rate": 5.455886755335073e-06,
      "loss": 0.2328,
      "step": 18280
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.9284491539001465,
      "learning_rate": 5.4451952273018865e-06,
      "loss": 0.257,
      "step": 18290
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5607272386550903,
      "learning_rate": 5.434503699268699e-06,
      "loss": 0.3138,
      "step": 18300
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.4255638122558594,
      "learning_rate": 5.423812171235513e-06,
      "loss": 0.2679,
      "step": 18310
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.8359743356704712,
      "learning_rate": 5.413120643202327e-06,
      "loss": 0.1984,
      "step": 18320
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1124532222747803,
      "learning_rate": 5.40242911516914e-06,
      "loss": 0.2252,
      "step": 18330
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.1575407981872559,
      "learning_rate": 5.3917375871359535e-06,
      "loss": 0.2663,
      "step": 18340
    },
    {
      "epoch": 0.78,
      "grad_norm": 1.5289403200149536,
      "learning_rate": 5.381046059102767e-06,
      "loss": 0.2637,
      "step": 18350
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9829461574554443,
      "learning_rate": 5.370354531069581e-06,
      "loss": 0.1873,
      "step": 18360
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4657831192016602,
      "learning_rate": 5.359663003036394e-06,
      "loss": 0.288,
      "step": 18370
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.0750350952148438,
      "learning_rate": 5.348971475003208e-06,
      "loss": 0.2448,
      "step": 18380
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.09721839427948,
      "learning_rate": 5.338279946970021e-06,
      "loss": 0.2387,
      "step": 18390
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.7533342838287354,
      "learning_rate": 5.327588418936834e-06,
      "loss": 0.3325,
      "step": 18400
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1028013229370117,
      "learning_rate": 5.316896890903649e-06,
      "loss": 0.2493,
      "step": 18410
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.5101841688156128,
      "learning_rate": 5.306205362870462e-06,
      "loss": 0.2579,
      "step": 18420
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1692147254943848,
      "learning_rate": 5.295513834837275e-06,
      "loss": 0.3505,
      "step": 18430
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.9621861577033997,
      "learning_rate": 5.284822306804088e-06,
      "loss": 0.2329,
      "step": 18440
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2126178741455078,
      "learning_rate": 5.274130778770902e-06,
      "loss": 0.2121,
      "step": 18450
    },
    {
      "epoch": 0.79,
      "grad_norm": 3.083861827850342,
      "learning_rate": 5.263439250737716e-06,
      "loss": 0.2562,
      "step": 18460
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4929713010787964,
      "learning_rate": 5.252747722704529e-06,
      "loss": 0.3021,
      "step": 18470
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.2151212692260742,
      "learning_rate": 5.242056194671343e-06,
      "loss": 0.2092,
      "step": 18480
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.455644965171814,
      "learning_rate": 5.231364666638156e-06,
      "loss": 0.2236,
      "step": 18490
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.3367928266525269,
      "learning_rate": 5.220673138604969e-06,
      "loss": 0.3556,
      "step": 18500
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9097875356674194,
      "learning_rate": 5.209981610571783e-06,
      "loss": 0.2344,
      "step": 18510
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.5312250852584839,
      "learning_rate": 5.199290082538597e-06,
      "loss": 0.3012,
      "step": 18520
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.6682274341583252,
      "learning_rate": 5.18859855450541e-06,
      "loss": 0.2163,
      "step": 18530
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.4203938245773315,
      "learning_rate": 5.177907026472223e-06,
      "loss": 0.2729,
      "step": 18540
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7337244749069214,
      "learning_rate": 5.167215498439037e-06,
      "loss": 0.2748,
      "step": 18550
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.7170621156692505,
      "learning_rate": 5.156523970405851e-06,
      "loss": 0.2289,
      "step": 18560
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.550545334815979,
      "learning_rate": 5.145832442372664e-06,
      "loss": 0.2715,
      "step": 18570
    },
    {
      "epoch": 0.79,
      "grad_norm": 1.9878852367401123,
      "learning_rate": 5.135140914339478e-06,
      "loss": 0.2485,
      "step": 18580
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.4621310234069824,
      "learning_rate": 5.124449386306291e-06,
      "loss": 0.2734,
      "step": 18590
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3859111070632935,
      "learning_rate": 5.113757858273105e-06,
      "loss": 0.2814,
      "step": 18600
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2936170101165771,
      "learning_rate": 5.103066330239918e-06,
      "loss": 0.2957,
      "step": 18610
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8196244835853577,
      "learning_rate": 5.0923748022067315e-06,
      "loss": 0.2857,
      "step": 18620
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8500794172286987,
      "learning_rate": 5.081683274173545e-06,
      "loss": 0.2371,
      "step": 18630
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.639357328414917,
      "learning_rate": 5.070991746140358e-06,
      "loss": 0.2686,
      "step": 18640
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3078681230545044,
      "learning_rate": 5.060300218107173e-06,
      "loss": 0.2886,
      "step": 18650
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4547007083892822,
      "learning_rate": 5.049608690073986e-06,
      "loss": 0.2173,
      "step": 18660
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.7326126098632812,
      "learning_rate": 5.0389171620407986e-06,
      "loss": 0.2562,
      "step": 18670
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.7136622667312622,
      "learning_rate": 5.028225634007612e-06,
      "loss": 0.2619,
      "step": 18680
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.2889693975448608,
      "learning_rate": 5.017534105974426e-06,
      "loss": 0.2463,
      "step": 18690
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5443241596221924,
      "learning_rate": 5.00684257794124e-06,
      "loss": 0.3051,
      "step": 18700
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.1673879623413086,
      "learning_rate": 4.996151049908053e-06,
      "loss": 0.2741,
      "step": 18710
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6798927783966064,
      "learning_rate": 4.985459521874867e-06,
      "loss": 0.2781,
      "step": 18720
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.0368566513061523,
      "learning_rate": 4.97476799384168e-06,
      "loss": 0.2821,
      "step": 18730
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5566349029541016,
      "learning_rate": 4.964076465808493e-06,
      "loss": 0.209,
      "step": 18740
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.38402676582336426,
      "learning_rate": 4.953384937775307e-06,
      "loss": 0.2502,
      "step": 18750
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0607352256774902,
      "learning_rate": 4.9426934097421205e-06,
      "loss": 0.2528,
      "step": 18760
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3854211568832397,
      "learning_rate": 4.932001881708934e-06,
      "loss": 0.2454,
      "step": 18770
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5108941793441772,
      "learning_rate": 4.921310353675747e-06,
      "loss": 0.3161,
      "step": 18780
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.7952318787574768,
      "learning_rate": 4.910618825642561e-06,
      "loss": 0.2929,
      "step": 18790
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6543712615966797,
      "learning_rate": 4.899927297609375e-06,
      "loss": 0.3483,
      "step": 18800
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.4805083274841309,
      "learning_rate": 4.8892357695761876e-06,
      "loss": 0.3152,
      "step": 18810
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.98894464969635,
      "learning_rate": 4.878544241543002e-06,
      "loss": 0.326,
      "step": 18820
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.395279884338379,
      "learning_rate": 4.867852713509815e-06,
      "loss": 0.3576,
      "step": 18830
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4279651641845703,
      "learning_rate": 4.857161185476629e-06,
      "loss": 0.2705,
      "step": 18840
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9477773904800415,
      "learning_rate": 4.846469657443442e-06,
      "loss": 0.2241,
      "step": 18850
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.3816578388214111,
      "learning_rate": 4.8357781294102554e-06,
      "loss": 0.3647,
      "step": 18860
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0197827816009521,
      "learning_rate": 4.825086601377069e-06,
      "loss": 0.2483,
      "step": 18870
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.0694117546081543,
      "learning_rate": 4.814395073343882e-06,
      "loss": 0.1919,
      "step": 18880
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.301337718963623,
      "learning_rate": 4.803703545310697e-06,
      "loss": 0.2376,
      "step": 18890
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7530789375305176,
      "learning_rate": 4.7930120172775096e-06,
      "loss": 0.1915,
      "step": 18900
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4984374046325684,
      "learning_rate": 4.7823204892443225e-06,
      "loss": 0.3073,
      "step": 18910
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.9108795523643494,
      "learning_rate": 4.771628961211136e-06,
      "loss": 0.2587,
      "step": 18920
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5691479444503784,
      "learning_rate": 4.76093743317795e-06,
      "loss": 0.2726,
      "step": 18930
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5155397653579712,
      "learning_rate": 4.750245905144764e-06,
      "loss": 0.2642,
      "step": 18940
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.47887399792671204,
      "learning_rate": 4.739554377111577e-06,
      "loss": 0.2764,
      "step": 18950
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.5488721132278442,
      "learning_rate": 4.728862849078391e-06,
      "loss": 0.2355,
      "step": 18960
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.680169701576233,
      "learning_rate": 4.718171321045204e-06,
      "loss": 0.333,
      "step": 18970
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.7875615358352661,
      "learning_rate": 4.707479793012017e-06,
      "loss": 0.2763,
      "step": 18980
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.361792802810669,
      "learning_rate": 4.696788264978831e-06,
      "loss": 0.3317,
      "step": 18990
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.8337761163711548,
      "learning_rate": 4.6860967369456444e-06,
      "loss": 0.3215,
      "step": 19000
    },
    {
      "epoch": 0.81,
      "eval_loss": 0.2806670665740967,
      "eval_runtime": 725.3575,
      "eval_samples_per_second": 3.619,
      "eval_steps_per_second": 3.619,
      "step": 19000
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.6348110437393188,
      "learning_rate": 4.675405208912458e-06,
      "loss": 0.3244,
      "step": 19010
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.1754637956619263,
      "learning_rate": 4.664713680879271e-06,
      "loss": 0.2799,
      "step": 19020
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.208817958831787,
      "learning_rate": 4.654022152846085e-06,
      "loss": 0.2544,
      "step": 19030
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.7799526453018188,
      "learning_rate": 4.6433306248128986e-06,
      "loss": 0.2377,
      "step": 19040
    },
    {
      "epoch": 0.81,
      "grad_norm": 1.4865870475769043,
      "learning_rate": 4.6326390967797115e-06,
      "loss": 0.2708,
      "step": 19050
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0428436994552612,
      "learning_rate": 4.621947568746526e-06,
      "loss": 0.2706,
      "step": 19060
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.610446810722351,
      "learning_rate": 4.611256040713339e-06,
      "loss": 0.2874,
      "step": 19070
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1283249855041504,
      "learning_rate": 4.600564512680153e-06,
      "loss": 0.2859,
      "step": 19080
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.5211512446403503,
      "learning_rate": 4.589872984646966e-06,
      "loss": 0.2003,
      "step": 19090
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0005412101745605,
      "learning_rate": 4.579181456613779e-06,
      "loss": 0.3341,
      "step": 19100
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.1681153774261475,
      "learning_rate": 4.568489928580593e-06,
      "loss": 0.2462,
      "step": 19110
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7033127546310425,
      "learning_rate": 4.557798400547406e-06,
      "loss": 0.297,
      "step": 19120
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.857256531715393,
      "learning_rate": 4.5471068725142206e-06,
      "loss": 0.216,
      "step": 19130
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5543212890625,
      "learning_rate": 4.5364153444810335e-06,
      "loss": 0.2549,
      "step": 19140
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6118571758270264,
      "learning_rate": 4.525723816447846e-06,
      "loss": 0.242,
      "step": 19150
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3139938116073608,
      "learning_rate": 4.51503228841466e-06,
      "loss": 0.1966,
      "step": 19160
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.3517504930496216,
      "learning_rate": 4.504340760381474e-06,
      "loss": 0.322,
      "step": 19170
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.4506675004959106,
      "learning_rate": 4.493649232348288e-06,
      "loss": 0.2782,
      "step": 19180
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.2330050468444824,
      "learning_rate": 4.4829577043151005e-06,
      "loss": 0.2066,
      "step": 19190
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.7577097415924072,
      "learning_rate": 4.472266176281915e-06,
      "loss": 0.2356,
      "step": 19200
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8050975799560547,
      "learning_rate": 4.461574648248728e-06,
      "loss": 0.1885,
      "step": 19210
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.9157169461250305,
      "learning_rate": 4.450883120215541e-06,
      "loss": 0.3144,
      "step": 19220
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.1593618392944336,
      "learning_rate": 4.440191592182355e-06,
      "loss": 0.2935,
      "step": 19230
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.6472878456115723,
      "learning_rate": 4.429500064149168e-06,
      "loss": 0.3008,
      "step": 19240
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.4067589044570923,
      "learning_rate": 4.418808536115982e-06,
      "loss": 0.228,
      "step": 19250
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.5136160850524902,
      "learning_rate": 4.408117008082795e-06,
      "loss": 0.2224,
      "step": 19260
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.0517427921295166,
      "learning_rate": 4.39742548004961e-06,
      "loss": 0.2722,
      "step": 19270
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.8161576390266418,
      "learning_rate": 4.3867339520164225e-06,
      "loss": 0.1888,
      "step": 19280
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9231964349746704,
      "learning_rate": 4.376042423983235e-06,
      "loss": 0.3015,
      "step": 19290
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1220698356628418,
      "learning_rate": 4.36535089595005e-06,
      "loss": 0.2701,
      "step": 19300
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6526310443878174,
      "learning_rate": 4.354659367916863e-06,
      "loss": 0.2766,
      "step": 19310
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3200291395187378,
      "learning_rate": 4.343967839883677e-06,
      "loss": 0.2888,
      "step": 19320
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8474840521812439,
      "learning_rate": 4.3332763118504895e-06,
      "loss": 0.1594,
      "step": 19330
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.0715354681015015,
      "learning_rate": 4.322584783817303e-06,
      "loss": 0.2548,
      "step": 19340
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6366125345230103,
      "learning_rate": 4.311893255784117e-06,
      "loss": 0.2316,
      "step": 19350
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.1797294616699219,
      "learning_rate": 4.30120172775093e-06,
      "loss": 0.3062,
      "step": 19360
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.804210901260376,
      "learning_rate": 4.2905101997177445e-06,
      "loss": 0.3199,
      "step": 19370
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6196907758712769,
      "learning_rate": 4.279818671684557e-06,
      "loss": 0.2771,
      "step": 19380
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.536963939666748,
      "learning_rate": 4.269127143651371e-06,
      "loss": 0.2401,
      "step": 19390
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7951123714447021,
      "learning_rate": 4.258435615618184e-06,
      "loss": 0.2795,
      "step": 19400
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7093210220336914,
      "learning_rate": 4.247744087584998e-06,
      "loss": 0.2696,
      "step": 19410
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.468648910522461,
      "learning_rate": 4.2370525595518115e-06,
      "loss": 0.239,
      "step": 19420
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.7071514129638672,
      "learning_rate": 4.226361031518624e-06,
      "loss": 0.2508,
      "step": 19430
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.2710678577423096,
      "learning_rate": 4.215669503485439e-06,
      "loss": 0.3053,
      "step": 19440
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.40787941217422485,
      "learning_rate": 4.204977975452252e-06,
      "loss": 0.1768,
      "step": 19450
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.5459786653518677,
      "learning_rate": 4.194286447419065e-06,
      "loss": 0.2442,
      "step": 19460
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.8360964059829712,
      "learning_rate": 4.183594919385879e-06,
      "loss": 0.2409,
      "step": 19470
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.6664453744888306,
      "learning_rate": 4.172903391352692e-06,
      "loss": 0.2923,
      "step": 19480
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.8328944444656372,
      "learning_rate": 4.162211863319506e-06,
      "loss": 0.3348,
      "step": 19490
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.329923391342163,
      "learning_rate": 4.151520335286319e-06,
      "loss": 0.241,
      "step": 19500
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.857359766960144,
      "learning_rate": 4.1408288072531335e-06,
      "loss": 0.2665,
      "step": 19510
    },
    {
      "epoch": 0.83,
      "grad_norm": 1.3279260396957397,
      "learning_rate": 4.130137279219946e-06,
      "loss": 0.2747,
      "step": 19520
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5623851418495178,
      "learning_rate": 4.119445751186759e-06,
      "loss": 0.293,
      "step": 19530
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.9695821404457092,
      "learning_rate": 4.108754223153574e-06,
      "loss": 0.2226,
      "step": 19540
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5537303686141968,
      "learning_rate": 4.098062695120387e-06,
      "loss": 0.2976,
      "step": 19550
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3451898097991943,
      "learning_rate": 4.0873711670872005e-06,
      "loss": 0.1376,
      "step": 19560
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6091583967208862,
      "learning_rate": 4.076679639054013e-06,
      "loss": 0.2926,
      "step": 19570
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2783880233764648,
      "learning_rate": 4.065988111020827e-06,
      "loss": 0.2155,
      "step": 19580
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5634405612945557,
      "learning_rate": 4.055296582987641e-06,
      "loss": 0.2468,
      "step": 19590
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.2196435928344727,
      "learning_rate": 4.044605054954454e-06,
      "loss": 0.2736,
      "step": 19600
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.1052618026733398,
      "learning_rate": 4.033913526921268e-06,
      "loss": 0.1902,
      "step": 19610
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.0461392402648926,
      "learning_rate": 4.023221998888081e-06,
      "loss": 0.2401,
      "step": 19620
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.018387794494629,
      "learning_rate": 4.012530470854895e-06,
      "loss": 0.1889,
      "step": 19630
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.5885155200958252,
      "learning_rate": 4.001838942821708e-06,
      "loss": 0.2172,
      "step": 19640
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6627037525177002,
      "learning_rate": 3.991147414788522e-06,
      "loss": 0.3571,
      "step": 19650
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.526663303375244,
      "learning_rate": 3.980455886755335e-06,
      "loss": 0.2859,
      "step": 19660
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.408158779144287,
      "learning_rate": 3.969764358722148e-06,
      "loss": 0.3155,
      "step": 19670
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5291844010353088,
      "learning_rate": 3.959072830688963e-06,
      "loss": 0.3203,
      "step": 19680
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.3866539001464844,
      "learning_rate": 3.948381302655776e-06,
      "loss": 0.2746,
      "step": 19690
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.770019292831421,
      "learning_rate": 3.937689774622589e-06,
      "loss": 0.3102,
      "step": 19700
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.5872108936309814,
      "learning_rate": 3.926998246589403e-06,
      "loss": 0.2744,
      "step": 19710
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.4363799095153809,
      "learning_rate": 3.916306718556216e-06,
      "loss": 0.3351,
      "step": 19720
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.621124029159546,
      "learning_rate": 3.90561519052303e-06,
      "loss": 0.22,
      "step": 19730
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.7860730886459351,
      "learning_rate": 3.894923662489843e-06,
      "loss": 0.2996,
      "step": 19740
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.509900450706482,
      "learning_rate": 3.884232134456657e-06,
      "loss": 0.2206,
      "step": 19750
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.6252710819244385,
      "learning_rate": 3.87354060642347e-06,
      "loss": 0.2664,
      "step": 19760
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7106454372406006,
      "learning_rate": 3.862849078390283e-06,
      "loss": 0.2616,
      "step": 19770
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4708368182182312,
      "learning_rate": 3.852157550357098e-06,
      "loss": 0.2449,
      "step": 19780
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.077736258506775,
      "learning_rate": 3.841466022323911e-06,
      "loss": 0.2095,
      "step": 19790
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.513526201248169,
      "learning_rate": 3.830774494290724e-06,
      "loss": 0.3018,
      "step": 19800
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5548251867294312,
      "learning_rate": 3.820082966257537e-06,
      "loss": 0.266,
      "step": 19810
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.468637228012085,
      "learning_rate": 3.809391438224351e-06,
      "loss": 0.2705,
      "step": 19820
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.918297290802002,
      "learning_rate": 3.7986999101911648e-06,
      "loss": 0.1738,
      "step": 19830
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9246996641159058,
      "learning_rate": 3.788008382157978e-06,
      "loss": 0.3189,
      "step": 19840
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6016210913658142,
      "learning_rate": 3.777316854124792e-06,
      "loss": 0.2114,
      "step": 19850
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.487116813659668,
      "learning_rate": 3.766625326091605e-06,
      "loss": 0.3601,
      "step": 19860
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6005154252052307,
      "learning_rate": 3.755933798058419e-06,
      "loss": 0.1942,
      "step": 19870
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.7871759533882141,
      "learning_rate": 3.7452422700252322e-06,
      "loss": 0.2652,
      "step": 19880
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.7553240060806274,
      "learning_rate": 3.7345507419920456e-06,
      "loss": 0.267,
      "step": 19890
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5873836278915405,
      "learning_rate": 3.7238592139588593e-06,
      "loss": 0.2783,
      "step": 19900
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.5446547269821167,
      "learning_rate": 3.7131676859256726e-06,
      "loss": 0.238,
      "step": 19910
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.8010129928588867,
      "learning_rate": 3.7024761578924864e-06,
      "loss": 0.3319,
      "step": 19920
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.9204622507095337,
      "learning_rate": 3.6917846298592997e-06,
      "loss": 0.2043,
      "step": 19930
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.3931059837341309,
      "learning_rate": 3.681093101826113e-06,
      "loss": 0.2035,
      "step": 19940
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.6370054483413696,
      "learning_rate": 3.6704015737929267e-06,
      "loss": 0.1776,
      "step": 19950
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.2700872421264648,
      "learning_rate": 3.65971004575974e-06,
      "loss": 0.1917,
      "step": 19960
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4752899408340454,
      "learning_rate": 3.649018517726554e-06,
      "loss": 0.2799,
      "step": 19970
    },
    {
      "epoch": 0.85,
      "grad_norm": 1.4988728761672974,
      "learning_rate": 3.638326989693367e-06,
      "loss": 0.3265,
      "step": 19980
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.4419431686401367,
      "learning_rate": 3.627635461660181e-06,
      "loss": 0.1696,
      "step": 19990
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2975348234176636,
      "learning_rate": 3.616943933626994e-06,
      "loss": 0.3035,
      "step": 20000
    },
    {
      "epoch": 0.86,
      "eval_loss": 0.2801257073879242,
      "eval_runtime": 728.0041,
      "eval_samples_per_second": 3.606,
      "eval_steps_per_second": 3.606,
      "step": 20000
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4683632850646973,
      "learning_rate": 3.6062524055938075e-06,
      "loss": 0.2634,
      "step": 20010
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4789695739746094,
      "learning_rate": 3.5955608775606212e-06,
      "loss": 0.1802,
      "step": 20020
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.5572445392608643,
      "learning_rate": 3.5848693495274346e-06,
      "loss": 0.267,
      "step": 20030
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.6257091760635376,
      "learning_rate": 3.5741778214942483e-06,
      "loss": 0.2977,
      "step": 20040
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.15636146068573,
      "learning_rate": 3.5634862934610616e-06,
      "loss": 0.2839,
      "step": 20050
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.5898599028587341,
      "learning_rate": 3.552794765427875e-06,
      "loss": 0.1798,
      "step": 20060
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.9413459300994873,
      "learning_rate": 3.5421032373946887e-06,
      "loss": 0.2133,
      "step": 20070
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.2152724266052246,
      "learning_rate": 3.531411709361502e-06,
      "loss": 0.3534,
      "step": 20080
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1782097816467285,
      "learning_rate": 3.5207201813283158e-06,
      "loss": 0.2401,
      "step": 20090
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.463384747505188,
      "learning_rate": 3.510028653295129e-06,
      "loss": 0.2867,
      "step": 20100
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.583741307258606,
      "learning_rate": 3.499337125261943e-06,
      "loss": 0.3068,
      "step": 20110
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.242352247238159,
      "learning_rate": 3.488645597228756e-06,
      "loss": 0.3032,
      "step": 20120
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.8833545446395874,
      "learning_rate": 3.4779540691955695e-06,
      "loss": 0.2475,
      "step": 20130
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.5028290748596191,
      "learning_rate": 3.467262541162383e-06,
      "loss": 0.2924,
      "step": 20140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8068978190422058,
      "learning_rate": 3.4565710131291965e-06,
      "loss": 0.2066,
      "step": 20150
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.7907723188400269,
      "learning_rate": 3.4458794850960103e-06,
      "loss": 0.2343,
      "step": 20160
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.4213279485702515,
      "learning_rate": 3.4351879570628236e-06,
      "loss": 0.2314,
      "step": 20170
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.992523193359375,
      "learning_rate": 3.424496429029637e-06,
      "loss": 0.2335,
      "step": 20180
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.943364143371582,
      "learning_rate": 3.4138049009964506e-06,
      "loss": 0.2698,
      "step": 20190
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8451588153839111,
      "learning_rate": 3.403113372963264e-06,
      "loss": 0.2275,
      "step": 20200
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8790697455406189,
      "learning_rate": 3.3924218449300777e-06,
      "loss": 0.2992,
      "step": 20210
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.0771020650863647,
      "learning_rate": 3.381730316896891e-06,
      "loss": 0.2765,
      "step": 20220
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6050302982330322,
      "learning_rate": 3.3710387888637048e-06,
      "loss": 0.3152,
      "step": 20230
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7889021635055542,
      "learning_rate": 3.360347260830518e-06,
      "loss": 0.2705,
      "step": 20240
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7155824899673462,
      "learning_rate": 3.3496557327973314e-06,
      "loss": 0.2358,
      "step": 20250
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.525499939918518,
      "learning_rate": 3.338964204764145e-06,
      "loss": 0.2864,
      "step": 20260
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.5915669202804565,
      "learning_rate": 3.3282726767309585e-06,
      "loss": 0.3057,
      "step": 20270
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.4160834550857544,
      "learning_rate": 3.317581148697772e-06,
      "loss": 0.3198,
      "step": 20280
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.8256967067718506,
      "learning_rate": 3.3068896206645855e-06,
      "loss": 0.3714,
      "step": 20290
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7936044931411743,
      "learning_rate": 3.296198092631399e-06,
      "loss": 0.3119,
      "step": 20300
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.676224946975708,
      "learning_rate": 3.2855065645982126e-06,
      "loss": 0.2964,
      "step": 20310
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6861636638641357,
      "learning_rate": 3.274815036565026e-06,
      "loss": 0.2943,
      "step": 20320
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3303172588348389,
      "learning_rate": 3.2641235085318397e-06,
      "loss": 0.3104,
      "step": 20330
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.1866278648376465,
      "learning_rate": 3.253431980498653e-06,
      "loss": 0.2141,
      "step": 20340
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0365592241287231,
      "learning_rate": 3.2427404524654667e-06,
      "loss": 0.3416,
      "step": 20350
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.459282398223877,
      "learning_rate": 3.23204892443228e-06,
      "loss": 0.2585,
      "step": 20360
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.6340843439102173,
      "learning_rate": 3.2213573963990934e-06,
      "loss": 0.3291,
      "step": 20370
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0160205364227295,
      "learning_rate": 3.210665868365907e-06,
      "loss": 0.2779,
      "step": 20380
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.5435386896133423,
      "learning_rate": 3.1999743403327204e-06,
      "loss": 0.2962,
      "step": 20390
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.7846759557724,
      "learning_rate": 3.189282812299534e-06,
      "loss": 0.3307,
      "step": 20400
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0949546098709106,
      "learning_rate": 3.1785912842663475e-06,
      "loss": 0.2842,
      "step": 20410
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.3512996435165405,
      "learning_rate": 3.167899756233161e-06,
      "loss": 0.1599,
      "step": 20420
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.0077359676361084,
      "learning_rate": 3.1572082281999745e-06,
      "loss": 0.2367,
      "step": 20430
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.0846115350723267,
      "learning_rate": 3.146516700166788e-06,
      "loss": 0.2842,
      "step": 20440
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.775773286819458,
      "learning_rate": 3.1358251721336016e-06,
      "loss": 0.3693,
      "step": 20450
    },
    {
      "epoch": 0.87,
      "grad_norm": 1.273743987083435,
      "learning_rate": 3.125133644100415e-06,
      "loss": 0.1991,
      "step": 20460
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9747302532196045,
      "learning_rate": 3.1144421160672282e-06,
      "loss": 0.2712,
      "step": 20470
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0632569789886475,
      "learning_rate": 3.103750588034042e-06,
      "loss": 0.1996,
      "step": 20480
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.9707571268081665,
      "learning_rate": 3.0930590600008557e-06,
      "loss": 0.259,
      "step": 20490
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.8578463792800903,
      "learning_rate": 3.082367531967669e-06,
      "loss": 0.2718,
      "step": 20500
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.364024043083191,
      "learning_rate": 3.0716760039344824e-06,
      "loss": 0.286,
      "step": 20510
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.889105200767517,
      "learning_rate": 3.0609844759012957e-06,
      "loss": 0.3877,
      "step": 20520
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7760081887245178,
      "learning_rate": 3.0502929478681094e-06,
      "loss": 0.2942,
      "step": 20530
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.337218999862671,
      "learning_rate": 3.039601419834923e-06,
      "loss": 0.2408,
      "step": 20540
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7336854934692383,
      "learning_rate": 3.0289098918017365e-06,
      "loss": 0.2446,
      "step": 20550
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7218358516693115,
      "learning_rate": 3.0182183637685502e-06,
      "loss": 0.2916,
      "step": 20560
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.353239893913269,
      "learning_rate": 3.007526835735363e-06,
      "loss": 0.2271,
      "step": 20570
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3424440622329712,
      "learning_rate": 2.996835307702177e-06,
      "loss": 0.1838,
      "step": 20580
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7765246629714966,
      "learning_rate": 2.98614377966899e-06,
      "loss": 0.2297,
      "step": 20590
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.5459234714508057,
      "learning_rate": 2.975452251635804e-06,
      "loss": 0.237,
      "step": 20600
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.3786978721618652,
      "learning_rate": 2.9647607236026177e-06,
      "loss": 0.3027,
      "step": 20610
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.752719759941101,
      "learning_rate": 2.954069195569431e-06,
      "loss": 0.2343,
      "step": 20620
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0173258781433105,
      "learning_rate": 2.9433776675362443e-06,
      "loss": 0.2926,
      "step": 20630
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.7836118936538696,
      "learning_rate": 2.9326861395030576e-06,
      "loss": 0.3481,
      "step": 20640
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.6392675638198853,
      "learning_rate": 2.9219946114698714e-06,
      "loss": 0.3013,
      "step": 20650
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.780731439590454,
      "learning_rate": 2.911303083436685e-06,
      "loss": 0.3201,
      "step": 20660
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.4690662622451782,
      "learning_rate": 2.9006115554034984e-06,
      "loss": 0.296,
      "step": 20670
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0076282024383545,
      "learning_rate": 2.889920027370312e-06,
      "loss": 0.2674,
      "step": 20680
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.0581295490264893,
      "learning_rate": 2.879228499337125e-06,
      "loss": 0.279,
      "step": 20690
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4765079021453857,
      "learning_rate": 2.868536971303939e-06,
      "loss": 0.199,
      "step": 20700
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8704187870025635,
      "learning_rate": 2.8578454432707526e-06,
      "loss": 0.3242,
      "step": 20710
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6298437118530273,
      "learning_rate": 2.847153915237566e-06,
      "loss": 0.3463,
      "step": 20720
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7616426944732666,
      "learning_rate": 2.8364623872043796e-06,
      "loss": 0.316,
      "step": 20730
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7571655511856079,
      "learning_rate": 2.825770859171193e-06,
      "loss": 0.2785,
      "step": 20740
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2807729244232178,
      "learning_rate": 2.8150793311380063e-06,
      "loss": 0.2903,
      "step": 20750
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.0931808948516846,
      "learning_rate": 2.8043878031048196e-06,
      "loss": 0.2828,
      "step": 20760
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.365422010421753,
      "learning_rate": 2.7936962750716333e-06,
      "loss": 0.2096,
      "step": 20770
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7812340259552002,
      "learning_rate": 2.783004747038447e-06,
      "loss": 0.2138,
      "step": 20780
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7966362833976746,
      "learning_rate": 2.7723132190052604e-06,
      "loss": 0.2117,
      "step": 20790
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.7535682916641235,
      "learning_rate": 2.761621690972074e-06,
      "loss": 0.2997,
      "step": 20800
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.6805943250656128,
      "learning_rate": 2.750930162938887e-06,
      "loss": 0.273,
      "step": 20810
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.7648265361785889,
      "learning_rate": 2.7402386349057008e-06,
      "loss": 0.2357,
      "step": 20820
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.5482624769210815,
      "learning_rate": 2.7295471068725145e-06,
      "loss": 0.4329,
      "step": 20830
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.8852219581604004,
      "learning_rate": 2.718855578839328e-06,
      "loss": 0.3749,
      "step": 20840
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.0209131240844727,
      "learning_rate": 2.7081640508061416e-06,
      "loss": 0.246,
      "step": 20850
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.509803056716919,
      "learning_rate": 2.697472522772955e-06,
      "loss": 0.2432,
      "step": 20860
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.4673519134521484,
      "learning_rate": 2.6867809947397682e-06,
      "loss": 0.2827,
      "step": 20870
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.221211314201355,
      "learning_rate": 2.6760894667065815e-06,
      "loss": 0.318,
      "step": 20880
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.556725263595581,
      "learning_rate": 2.6653979386733953e-06,
      "loss": 0.2383,
      "step": 20890
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.892601728439331,
      "learning_rate": 2.654706410640209e-06,
      "loss": 0.2533,
      "step": 20900
    },
    {
      "epoch": 0.89,
      "grad_norm": 1.2974258661270142,
      "learning_rate": 2.6440148826070223e-06,
      "loss": 0.2373,
      "step": 20910
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.8865992426872253,
      "learning_rate": 2.633323354573836e-06,
      "loss": 0.3695,
      "step": 20920
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3536285161972046,
      "learning_rate": 2.622631826540649e-06,
      "loss": 0.2478,
      "step": 20930
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.4449937343597412,
      "learning_rate": 2.6119402985074627e-06,
      "loss": 0.2714,
      "step": 20940
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.3378198146820068,
      "learning_rate": 2.6012487704742765e-06,
      "loss": 0.1586,
      "step": 20950
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2998536825180054,
      "learning_rate": 2.59055724244109e-06,
      "loss": 0.24,
      "step": 20960
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.7956554889678955,
      "learning_rate": 2.5798657144079035e-06,
      "loss": 0.2418,
      "step": 20970
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.552020251750946,
      "learning_rate": 2.569174186374717e-06,
      "loss": 0.1598,
      "step": 20980
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.7426754236221313,
      "learning_rate": 2.55848265834153e-06,
      "loss": 0.1951,
      "step": 20990
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.018735647201538,
      "learning_rate": 2.5477911303083435e-06,
      "loss": 0.2782,
      "step": 21000
    },
    {
      "epoch": 0.9,
      "eval_loss": 0.2797212600708008,
      "eval_runtime": 726.6048,
      "eval_samples_per_second": 3.613,
      "eval_steps_per_second": 3.613,
      "step": 21000
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9098771810531616,
      "learning_rate": 2.5370996022751572e-06,
      "loss": 0.1921,
      "step": 21010
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8438965082168579,
      "learning_rate": 2.526408074241971e-06,
      "loss": 0.2275,
      "step": 21020
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.8463839888572693,
      "learning_rate": 2.5157165462087843e-06,
      "loss": 0.2814,
      "step": 21030
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8752577304840088,
      "learning_rate": 2.505025018175598e-06,
      "loss": 0.2532,
      "step": 21040
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.698163390159607,
      "learning_rate": 2.494333490142411e-06,
      "loss": 0.2418,
      "step": 21050
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1710107326507568,
      "learning_rate": 2.4836419621092247e-06,
      "loss": 0.3317,
      "step": 21060
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.0845979452133179,
      "learning_rate": 2.4729504340760384e-06,
      "loss": 0.2638,
      "step": 21070
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.2631670236587524,
      "learning_rate": 2.4622589060428517e-06,
      "loss": 0.2181,
      "step": 21080
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6492443084716797,
      "learning_rate": 2.4515673780096655e-06,
      "loss": 0.2918,
      "step": 21090
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.592057228088379,
      "learning_rate": 2.440875849976479e-06,
      "loss": 0.2317,
      "step": 21100
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.8948746919631958,
      "learning_rate": 2.430184321943292e-06,
      "loss": 0.2117,
      "step": 21110
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.1797429323196411,
      "learning_rate": 2.4194927939101054e-06,
      "loss": 0.2533,
      "step": 21120
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5474517345428467,
      "learning_rate": 2.408801265876919e-06,
      "loss": 0.2411,
      "step": 21130
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.358510732650757,
      "learning_rate": 2.398109737843733e-06,
      "loss": 0.2724,
      "step": 21140
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.6777244806289673,
      "learning_rate": 2.3874182098105462e-06,
      "loss": 0.2456,
      "step": 21150
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.016559362411499,
      "learning_rate": 2.37672668177736e-06,
      "loss": 0.2346,
      "step": 21160
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.557481288909912,
      "learning_rate": 2.366035153744173e-06,
      "loss": 0.2172,
      "step": 21170
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.80044424533844,
      "learning_rate": 2.3553436257109866e-06,
      "loss": 0.2372,
      "step": 21180
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8657573461532593,
      "learning_rate": 2.3446520976778004e-06,
      "loss": 0.2655,
      "step": 21190
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.6300511956214905,
      "learning_rate": 2.3339605696446137e-06,
      "loss": 0.2189,
      "step": 21200
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.5322602987289429,
      "learning_rate": 2.3232690416114274e-06,
      "loss": 0.3346,
      "step": 21210
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3361198902130127,
      "learning_rate": 2.3125775135782408e-06,
      "loss": 0.2499,
      "step": 21220
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.6094852685928345,
      "learning_rate": 2.301885985545054e-06,
      "loss": 0.3094,
      "step": 21230
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.63857102394104,
      "learning_rate": 2.2911944575118674e-06,
      "loss": 0.1493,
      "step": 21240
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.9539527893066406,
      "learning_rate": 2.280502929478681e-06,
      "loss": 0.2169,
      "step": 21250
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.633158564567566,
      "learning_rate": 2.269811401445495e-06,
      "loss": 0.2322,
      "step": 21260
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2307212352752686,
      "learning_rate": 2.259119873412308e-06,
      "loss": 0.2488,
      "step": 21270
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3956515789031982,
      "learning_rate": 2.248428345379122e-06,
      "loss": 0.2915,
      "step": 21280
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.6880549192428589,
      "learning_rate": 2.237736817345935e-06,
      "loss": 0.3029,
      "step": 21290
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.5216917991638184,
      "learning_rate": 2.2270452893127486e-06,
      "loss": 0.2247,
      "step": 21300
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8467305898666382,
      "learning_rate": 2.2163537612795623e-06,
      "loss": 0.2646,
      "step": 21310
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.3330765962600708,
      "learning_rate": 2.2056622332463756e-06,
      "loss": 0.2488,
      "step": 21320
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1099202632904053,
      "learning_rate": 2.1949707052131894e-06,
      "loss": 0.2693,
      "step": 21330
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.2068411111831665,
      "learning_rate": 2.1842791771800027e-06,
      "loss": 0.2991,
      "step": 21340
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.1306545734405518,
      "learning_rate": 2.173587649146816e-06,
      "loss": 0.236,
      "step": 21350
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.5915275812149048,
      "learning_rate": 2.1628961211136298e-06,
      "loss": 0.3004,
      "step": 21360
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.1800589561462402,
      "learning_rate": 2.152204593080443e-06,
      "loss": 0.3071,
      "step": 21370
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.5082319974899292,
      "learning_rate": 2.141513065047257e-06,
      "loss": 0.339,
      "step": 21380
    },
    {
      "epoch": 0.91,
      "grad_norm": 1.8929213285446167,
      "learning_rate": 2.13082153701407e-06,
      "loss": 0.2925,
      "step": 21390
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.327682375907898,
      "learning_rate": 2.120130008980884e-06,
      "loss": 0.2796,
      "step": 21400
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6215041875839233,
      "learning_rate": 2.109438480947697e-06,
      "loss": 0.2972,
      "step": 21410
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.6613726019859314,
      "learning_rate": 2.0987469529145105e-06,
      "loss": 0.2056,
      "step": 21420
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.1004761457443237,
      "learning_rate": 2.0880554248813243e-06,
      "loss": 0.2618,
      "step": 21430
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.947812557220459,
      "learning_rate": 2.0773638968481376e-06,
      "loss": 0.2511,
      "step": 21440
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.360576868057251,
      "learning_rate": 2.0666723688149513e-06,
      "loss": 0.2816,
      "step": 21450
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.7568234205245972,
      "learning_rate": 2.0559808407817647e-06,
      "loss": 0.2519,
      "step": 21460
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7215583324432373,
      "learning_rate": 2.045289312748578e-06,
      "loss": 0.266,
      "step": 21470
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4494292736053467,
      "learning_rate": 2.0345977847153917e-06,
      "loss": 0.2932,
      "step": 21480
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.9193036556243896,
      "learning_rate": 2.023906256682205e-06,
      "loss": 0.3244,
      "step": 21490
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.180497884750366,
      "learning_rate": 2.0132147286490188e-06,
      "loss": 0.2827,
      "step": 21500
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.9281535148620605,
      "learning_rate": 2.002523200615832e-06,
      "loss": 0.2563,
      "step": 21510
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5688047409057617,
      "learning_rate": 1.991831672582646e-06,
      "loss": 0.2478,
      "step": 21520
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.0574721097946167,
      "learning_rate": 1.9811401445494587e-06,
      "loss": 0.2607,
      "step": 21530
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.6195805072784424,
      "learning_rate": 1.9704486165162725e-06,
      "loss": 0.2328,
      "step": 21540
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7275416254997253,
      "learning_rate": 1.9597570884830862e-06,
      "loss": 0.3181,
      "step": 21550
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.2870715856552124,
      "learning_rate": 1.9490655604498995e-06,
      "loss": 0.2158,
      "step": 21560
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.5403444170951843,
      "learning_rate": 1.9383740324167133e-06,
      "loss": 0.1756,
      "step": 21570
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.4405326843261719,
      "learning_rate": 1.9276825043835266e-06,
      "loss": 0.2981,
      "step": 21580
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.3264801502227783,
      "learning_rate": 1.91699097635034e-06,
      "loss": 0.2795,
      "step": 21590
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.5810723304748535,
      "learning_rate": 1.9062994483171535e-06,
      "loss": 0.3247,
      "step": 21600
    },
    {
      "epoch": 0.92,
      "grad_norm": 1.8738797903060913,
      "learning_rate": 1.895607920283967e-06,
      "loss": 0.2422,
      "step": 21610
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.8885111808776855,
      "learning_rate": 1.8849163922507805e-06,
      "loss": 0.1963,
      "step": 21620
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.174816370010376,
      "learning_rate": 1.874224864217594e-06,
      "loss": 0.355,
      "step": 21630
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7681065797805786,
      "learning_rate": 1.8635333361844076e-06,
      "loss": 0.2499,
      "step": 21640
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.7060753107070923,
      "learning_rate": 1.852841808151221e-06,
      "loss": 0.252,
      "step": 21650
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3900879621505737,
      "learning_rate": 1.8421502801180344e-06,
      "loss": 0.1502,
      "step": 21660
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.4470151662826538,
      "learning_rate": 1.831458752084848e-06,
      "loss": 0.2158,
      "step": 21670
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.42671799659729,
      "learning_rate": 1.8207672240516615e-06,
      "loss": 0.2375,
      "step": 21680
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.726136565208435,
      "learning_rate": 1.810075696018475e-06,
      "loss": 0.226,
      "step": 21690
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7168618440628052,
      "learning_rate": 1.7993841679852886e-06,
      "loss": 0.2069,
      "step": 21700
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3889240026474,
      "learning_rate": 1.7886926399521019e-06,
      "loss": 0.2848,
      "step": 21710
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3380602598190308,
      "learning_rate": 1.7780011119189154e-06,
      "loss": 0.176,
      "step": 21720
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.8142827153205872,
      "learning_rate": 1.767309583885729e-06,
      "loss": 0.2658,
      "step": 21730
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7005711793899536,
      "learning_rate": 1.7566180558525425e-06,
      "loss": 0.3086,
      "step": 21740
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8280694484710693,
      "learning_rate": 1.745926527819356e-06,
      "loss": 0.3261,
      "step": 21750
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.1539063453674316,
      "learning_rate": 1.7352349997861697e-06,
      "loss": 0.2758,
      "step": 21760
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.733229637145996,
      "learning_rate": 1.7245434717529829e-06,
      "loss": 0.2534,
      "step": 21770
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.7643077373504639,
      "learning_rate": 1.7138519437197964e-06,
      "loss": 0.2307,
      "step": 21780
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.5642534494400024,
      "learning_rate": 1.70316041568661e-06,
      "loss": 0.1471,
      "step": 21790
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.187798261642456,
      "learning_rate": 1.6924688876534234e-06,
      "loss": 0.2492,
      "step": 21800
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8656466007232666,
      "learning_rate": 1.681777359620237e-06,
      "loss": 0.2471,
      "step": 21810
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3159266710281372,
      "learning_rate": 1.6710858315870507e-06,
      "loss": 0.2878,
      "step": 21820
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.889041006565094,
      "learning_rate": 1.6603943035538638e-06,
      "loss": 0.2269,
      "step": 21830
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.3955446481704712,
      "learning_rate": 1.6497027755206774e-06,
      "loss": 0.254,
      "step": 21840
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.8664612770080566,
      "learning_rate": 1.639011247487491e-06,
      "loss": 0.2326,
      "step": 21850
    },
    {
      "epoch": 0.93,
      "grad_norm": 1.5808659791946411,
      "learning_rate": 1.6283197194543044e-06,
      "loss": 0.3063,
      "step": 21860
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6093440651893616,
      "learning_rate": 1.617628191421118e-06,
      "loss": 0.2184,
      "step": 21870
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8137856721878052,
      "learning_rate": 1.6069366633879317e-06,
      "loss": 0.3486,
      "step": 21880
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.8647249937057495,
      "learning_rate": 1.5962451353547448e-06,
      "loss": 0.3085,
      "step": 21890
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.465756416320801,
      "learning_rate": 1.5855536073215583e-06,
      "loss": 0.307,
      "step": 21900
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4112558364868164,
      "learning_rate": 1.5748620792883719e-06,
      "loss": 0.2264,
      "step": 21910
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4886609315872192,
      "learning_rate": 1.5641705512551854e-06,
      "loss": 0.2729,
      "step": 21920
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.457504391670227,
      "learning_rate": 1.553479023221999e-06,
      "loss": 0.2378,
      "step": 21930
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.6736258268356323,
      "learning_rate": 1.5427874951888125e-06,
      "loss": 0.2531,
      "step": 21940
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.362846851348877,
      "learning_rate": 1.532095967155626e-06,
      "loss": 0.2944,
      "step": 21950
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.0059071779251099,
      "learning_rate": 1.5214044391224395e-06,
      "loss": 0.2921,
      "step": 21960
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.0759291648864746,
      "learning_rate": 1.5107129110892528e-06,
      "loss": 0.2817,
      "step": 21970
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9795758724212646,
      "learning_rate": 1.5000213830560664e-06,
      "loss": 0.2538,
      "step": 21980
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4475533962249756,
      "learning_rate": 1.48932985502288e-06,
      "loss": 0.2686,
      "step": 21990
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.1567258834838867,
      "learning_rate": 1.4786383269896934e-06,
      "loss": 0.2389,
      "step": 22000
    },
    {
      "epoch": 0.94,
      "eval_loss": 0.2790828049182892,
      "eval_runtime": 724.4251,
      "eval_samples_per_second": 3.624,
      "eval_steps_per_second": 3.624,
      "step": 22000
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5999431610107422,
      "learning_rate": 1.467946798956507e-06,
      "loss": 0.3205,
      "step": 22010
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9483052492141724,
      "learning_rate": 1.4572552709233205e-06,
      "loss": 0.2001,
      "step": 22020
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.2124141454696655,
      "learning_rate": 1.4465637428901338e-06,
      "loss": 0.2631,
      "step": 22030
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8838882446289062,
      "learning_rate": 1.4358722148569474e-06,
      "loss": 0.1662,
      "step": 22040
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.524784803390503,
      "learning_rate": 1.4251806868237609e-06,
      "loss": 0.3362,
      "step": 22050
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.4386473894119263,
      "learning_rate": 1.4144891587905744e-06,
      "loss": 0.2521,
      "step": 22060
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2594827115535736,
      "learning_rate": 1.403797630757388e-06,
      "loss": 0.1854,
      "step": 22070
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.8535635471343994,
      "learning_rate": 1.3931061027242015e-06,
      "loss": 0.2486,
      "step": 22080
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9966391324996948,
      "learning_rate": 1.3824145746910148e-06,
      "loss": 0.2159,
      "step": 22090
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3952689170837402,
      "learning_rate": 1.3717230466578283e-06,
      "loss": 0.3162,
      "step": 22100
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.4136238098144531,
      "learning_rate": 1.3610315186246419e-06,
      "loss": 0.3393,
      "step": 22110
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.8699064254760742,
      "learning_rate": 1.3503399905914554e-06,
      "loss": 0.2544,
      "step": 22120
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.9326954483985901,
      "learning_rate": 1.339648462558269e-06,
      "loss": 0.1856,
      "step": 22130
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.7431181073188782,
      "learning_rate": 1.3289569345250825e-06,
      "loss": 0.2573,
      "step": 22140
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1046411991119385,
      "learning_rate": 1.3182654064918958e-06,
      "loss": 0.3372,
      "step": 22150
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3589459657669067,
      "learning_rate": 1.3075738784587093e-06,
      "loss": 0.3095,
      "step": 22160
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1034075021743774,
      "learning_rate": 1.2968823504255228e-06,
      "loss": 0.294,
      "step": 22170
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3154797554016113,
      "learning_rate": 1.2861908223923364e-06,
      "loss": 0.2669,
      "step": 22180
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8680416345596313,
      "learning_rate": 1.27549929435915e-06,
      "loss": 0.2504,
      "step": 22190
    },
    {
      "epoch": 0.95,
      "grad_norm": 2.3109214305877686,
      "learning_rate": 1.2648077663259634e-06,
      "loss": 0.3184,
      "step": 22200
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6549698114395142,
      "learning_rate": 1.2541162382927767e-06,
      "loss": 0.2282,
      "step": 22210
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.445590615272522,
      "learning_rate": 1.2434247102595903e-06,
      "loss": 0.271,
      "step": 22220
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9672601222991943,
      "learning_rate": 1.2327331822264038e-06,
      "loss": 0.2618,
      "step": 22230
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.7102802991867065,
      "learning_rate": 1.2220416541932173e-06,
      "loss": 0.2621,
      "step": 22240
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.3086854219436646,
      "learning_rate": 1.2113501261600309e-06,
      "loss": 0.2745,
      "step": 22250
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2410564422607422,
      "learning_rate": 1.2006585981268444e-06,
      "loss": 0.1917,
      "step": 22260
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2337359189987183,
      "learning_rate": 1.1899670700936577e-06,
      "loss": 0.2482,
      "step": 22270
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.387920618057251,
      "learning_rate": 1.1792755420604713e-06,
      "loss": 0.3209,
      "step": 22280
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9336069822311401,
      "learning_rate": 1.1685840140272848e-06,
      "loss": 0.2476,
      "step": 22290
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.9803212881088257,
      "learning_rate": 1.1578924859940983e-06,
      "loss": 0.2862,
      "step": 22300
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.1266090869903564,
      "learning_rate": 1.1472009579609118e-06,
      "loss": 0.2583,
      "step": 22310
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5653033256530762,
      "learning_rate": 1.1365094299277254e-06,
      "loss": 0.2952,
      "step": 22320
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.2785611152648926,
      "learning_rate": 1.1258179018945387e-06,
      "loss": 0.2455,
      "step": 22330
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7480692863464355,
      "learning_rate": 1.1151263738613522e-06,
      "loss": 0.263,
      "step": 22340
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.329643726348877,
      "learning_rate": 1.1044348458281658e-06,
      "loss": 0.2225,
      "step": 22350
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6382306218147278,
      "learning_rate": 1.0937433177949793e-06,
      "loss": 0.2343,
      "step": 22360
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.3482942581176758,
      "learning_rate": 1.0830517897617928e-06,
      "loss": 0.2546,
      "step": 22370
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.127150058746338,
      "learning_rate": 1.0723602617286064e-06,
      "loss": 0.2927,
      "step": 22380
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2876274585723877,
      "learning_rate": 1.0616687336954197e-06,
      "loss": 0.198,
      "step": 22390
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.0270116329193115,
      "learning_rate": 1.0509772056622332e-06,
      "loss": 0.2177,
      "step": 22400
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6095372438430786,
      "learning_rate": 1.0402856776290467e-06,
      "loss": 0.2604,
      "step": 22410
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.6216388940811157,
      "learning_rate": 1.0295941495958603e-06,
      "loss": 0.3594,
      "step": 22420
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.2309913635253906,
      "learning_rate": 1.0189026215626738e-06,
      "loss": 0.3009,
      "step": 22430
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.828995704650879,
      "learning_rate": 1.0082110935294873e-06,
      "loss": 0.2458,
      "step": 22440
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6236904859542847,
      "learning_rate": 9.975195654963006e-07,
      "loss": 0.1909,
      "step": 22450
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.7757722735404968,
      "learning_rate": 9.868280374631142e-07,
      "loss": 0.2854,
      "step": 22460
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4019246101379395,
      "learning_rate": 9.76136509429928e-07,
      "loss": 0.2194,
      "step": 22470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.857464075088501,
      "learning_rate": 9.654449813967412e-07,
      "loss": 0.299,
      "step": 22480
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4681865870952606,
      "learning_rate": 9.547534533635548e-07,
      "loss": 0.3267,
      "step": 22490
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.4117002487182617,
      "learning_rate": 9.440619253303683e-07,
      "loss": 0.2352,
      "step": 22500
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.11879825592041,
      "learning_rate": 9.333703972971817e-07,
      "loss": 0.3414,
      "step": 22510
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4448137283325195,
      "learning_rate": 9.226788692639953e-07,
      "loss": 0.251,
      "step": 22520
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.4640058279037476,
      "learning_rate": 9.119873412308088e-07,
      "loss": 0.317,
      "step": 22530
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7470991611480713,
      "learning_rate": 9.012958131976222e-07,
      "loss": 0.2621,
      "step": 22540
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8217755556106567,
      "learning_rate": 8.906042851644358e-07,
      "loss": 0.2494,
      "step": 22550
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.7996078729629517,
      "learning_rate": 8.799127571312493e-07,
      "loss": 0.2841,
      "step": 22560
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.7845285534858704,
      "learning_rate": 8.692212290980627e-07,
      "loss": 0.2683,
      "step": 22570
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.0026544332504272,
      "learning_rate": 8.585297010648762e-07,
      "loss": 0.176,
      "step": 22580
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2288891077041626,
      "learning_rate": 8.478381730316898e-07,
      "loss": 0.2756,
      "step": 22590
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2142707109451294,
      "learning_rate": 8.371466449985032e-07,
      "loss": 0.2914,
      "step": 22600
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1383628845214844,
      "learning_rate": 8.264551169653167e-07,
      "loss": 0.2024,
      "step": 22610
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2964327335357666,
      "learning_rate": 8.157635889321303e-07,
      "loss": 0.2433,
      "step": 22620
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.4137028455734253,
      "learning_rate": 8.050720608989437e-07,
      "loss": 0.2321,
      "step": 22630
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.202142357826233,
      "learning_rate": 7.943805328657572e-07,
      "loss": 0.2713,
      "step": 22640
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5144953727722168,
      "learning_rate": 7.836890048325707e-07,
      "loss": 0.3424,
      "step": 22650
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.8610458374023438,
      "learning_rate": 7.729974767993842e-07,
      "loss": 0.1841,
      "step": 22660
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.913175642490387,
      "learning_rate": 7.623059487661977e-07,
      "loss": 0.2066,
      "step": 22670
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.7265264987945557,
      "learning_rate": 7.516144207330111e-07,
      "loss": 0.2493,
      "step": 22680
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.8632051944732666,
      "learning_rate": 7.409228926998247e-07,
      "loss": 0.2732,
      "step": 22690
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2868374586105347,
      "learning_rate": 7.302313646666382e-07,
      "loss": 0.2384,
      "step": 22700
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.4176280498504639,
      "learning_rate": 7.195398366334517e-07,
      "loss": 0.2517,
      "step": 22710
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.1039644479751587,
      "learning_rate": 7.088483086002651e-07,
      "loss": 0.3014,
      "step": 22720
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.9344006776809692,
      "learning_rate": 6.981567805670787e-07,
      "loss": 0.2638,
      "step": 22730
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.47554904222488403,
      "learning_rate": 6.874652525338922e-07,
      "loss": 0.234,
      "step": 22740
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6080747842788696,
      "learning_rate": 6.767737245007056e-07,
      "loss": 0.2876,
      "step": 22750
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.6010981798171997,
      "learning_rate": 6.660821964675192e-07,
      "loss": 0.2913,
      "step": 22760
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.5034180879592896,
      "learning_rate": 6.553906684343327e-07,
      "loss": 0.3332,
      "step": 22770
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.4725924730300903,
      "learning_rate": 6.446991404011462e-07,
      "loss": 0.2651,
      "step": 22780
    },
    {
      "epoch": 0.97,
      "grad_norm": 1.2503138780593872,
      "learning_rate": 6.340076123679597e-07,
      "loss": 0.2438,
      "step": 22790
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5897363424301147,
      "learning_rate": 6.233160843347732e-07,
      "loss": 0.2721,
      "step": 22800
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5393739938735962,
      "learning_rate": 6.126245563015867e-07,
      "loss": 0.2865,
      "step": 22810
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4124879837036133,
      "learning_rate": 6.019330282684001e-07,
      "loss": 0.215,
      "step": 22820
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6697592735290527,
      "learning_rate": 5.912415002352137e-07,
      "loss": 0.2511,
      "step": 22830
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.617903232574463,
      "learning_rate": 5.805499722020272e-07,
      "loss": 0.2906,
      "step": 22840
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.8759445548057556,
      "learning_rate": 5.698584441688406e-07,
      "loss": 0.2929,
      "step": 22850
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.219130277633667,
      "learning_rate": 5.591669161356542e-07,
      "loss": 0.2687,
      "step": 22860
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.112059473991394,
      "learning_rate": 5.484753881024677e-07,
      "loss": 0.2255,
      "step": 22870
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.20653150975704193,
      "learning_rate": 5.377838600692811e-07,
      "loss": 0.2314,
      "step": 22880
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4944056272506714,
      "learning_rate": 5.270923320360946e-07,
      "loss": 0.3304,
      "step": 22890
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.662356972694397,
      "learning_rate": 5.164008040029082e-07,
      "loss": 0.2719,
      "step": 22900
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.1120405197143555,
      "learning_rate": 5.057092759697216e-07,
      "loss": 0.175,
      "step": 22910
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8215795755386353,
      "learning_rate": 4.950177479365351e-07,
      "loss": 0.2781,
      "step": 22920
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3401250839233398,
      "learning_rate": 4.843262199033487e-07,
      "loss": 0.3103,
      "step": 22930
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7737079858779907,
      "learning_rate": 4.736346918701621e-07,
      "loss": 0.2868,
      "step": 22940
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.5475813150405884,
      "learning_rate": 4.629431638369756e-07,
      "loss": 0.209,
      "step": 22950
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.4251315593719482,
      "learning_rate": 4.522516358037891e-07,
      "loss": 0.2128,
      "step": 22960
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.3046938180923462,
      "learning_rate": 4.415601077706026e-07,
      "loss": 0.2188,
      "step": 22970
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.8033145666122437,
      "learning_rate": 4.308685797374161e-07,
      "loss": 0.259,
      "step": 22980
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0816758871078491,
      "learning_rate": 4.201770517042296e-07,
      "loss": 0.2765,
      "step": 22990
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.0958846807479858,
      "learning_rate": 4.0948552367104307e-07,
      "loss": 0.2095,
      "step": 23000
    },
    {
      "epoch": 0.98,
      "eval_loss": 0.27883201837539673,
      "eval_runtime": 723.7825,
      "eval_samples_per_second": 3.627,
      "eval_steps_per_second": 3.627,
      "step": 23000
    }
  ],
  "logging_steps": 10,
  "max_steps": 23383,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "total_flos": 1.86661421973504e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
